{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 80\n",
    "\n",
    "optimizer = 'Adadelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /home/samarth/emotion_recognition-master/code/utilities/../../data/ses\n",
      "path_to_features              /home/samarth/emotion_recognition-master/code/utilities/../../data/fea\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <class 'numpy.int8'>, 2: <class 'numpy.int16'>, 4: <class 'numpy.i\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2.5,\n",
       " 'd': 2.5,\n",
       " 'emo_evo': [['neu'], ['neu'], ['neu'], ['neu']],\n",
       " 'emotion': 'neu',\n",
       " 'end': 8.2357,\n",
       " 'id': 'Ses01F_impro01_F000',\n",
       " 'mocap_hand': array([[        nan,         nan,         nan, ...,  -46.42036 ,\n",
       "         -162.607345,  -80.458935],\n",
       "        [        nan,         nan,         nan, ...,  -46.42206 ,\n",
       "         -162.644865,  -80.503155],\n",
       "        [        nan,         nan,         nan, ...,  -46.41771 ,\n",
       "         -162.64734 ,  -80.53003 ],\n",
       "        ..., \n",
       "        [        nan,         nan,         nan, ...,  -46.27356 ,\n",
       "         -162.49055 ,  -79.90838 ],\n",
       "        [        nan,         nan,         nan, ...,  -46.29963 ,\n",
       "         -162.48961 ,  -79.8289  ],\n",
       "        [        nan,         nan,         nan, ...,  -46.28651 ,\n",
       "         -162.55255 ,  -79.82458 ]]),\n",
       " 'mocap_head': array([[ -1.29297700e+01,  -1.35274400e+01,  -1.97916150e+01,\n",
       "          -2.23723750e+01,  -1.35425840e+02,  -3.02012850e+01],\n",
       "        [ -1.29120500e+01,  -1.35292750e+01,  -1.97787800e+01,\n",
       "          -2.23489800e+01,  -1.35347355e+02,  -3.01226100e+01],\n",
       "        [ -1.28972200e+01,  -1.35326750e+01,  -1.98088150e+01,\n",
       "          -2.22805200e+01,  -1.35282850e+02,  -3.00640450e+01],\n",
       "        ..., \n",
       "        [ -2.15942000e+00,  -1.41580000e+01,  -2.72382500e+01,\n",
       "           7.73500000e-02,  -1.22854210e+02,  -3.82914000e+00],\n",
       "        [ -2.16062000e+00,  -1.41573900e+01,  -2.72045700e+01,\n",
       "           2.56000000e-03,  -1.22859770e+02,  -3.83808000e+00],\n",
       "        [ -2.14601000e+00,  -1.41542700e+01,  -2.72353200e+01,\n",
       "          -2.24300000e-02,  -1.22916710e+02,  -3.85828000e+00]]),\n",
       " 'mocap_rot': array([[ -28.166955,   33.83828 ,  -54.437235, ...,  -45.552485,\n",
       "           52.78455 ,  129.792845],\n",
       "        [ -28.16234 ,   33.891575,  -54.37245 , ...,  -45.564395,\n",
       "           52.978755,  129.856305],\n",
       "        [ -28.19076 ,   33.97728 ,  -54.39008 , ...,  -45.58896 ,\n",
       "           53.056005,  129.88101 ],\n",
       "        ..., \n",
       "        [ -28.12114 ,   34.79247 ,  -56.04058 , ...,  -45.36128 ,\n",
       "           52.5758  ,  129.79436 ],\n",
       "        [ -28.11692 ,   34.77052 ,  -56.0277  , ...,  -45.34806 ,\n",
       "           52.53871 ,  129.78537 ],\n",
       "        [ -28.0848  ,   34.75438 ,  -56.03502 , ...,  -45.33584 ,\n",
       "           52.48602 ,  129.75684 ]]),\n",
       " 'signal': array([-165, -163, -125, ..., -104, -137, -146], dtype=int16),\n",
       " 'start': 6.2901,\n",
       " 'transcription': 'Excuse me.',\n",
       " 'v': 2.5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train2.append( x_mocap )\n",
    "    \n",
    "x_train2 = np.array(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train2.reshape(-1,200,189,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv2D, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution2D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_conv(nb_class, optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, padding=\"same\", strides=(2, 2), input_shape=(200, 189,...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_conv(nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.5867 - acc: 0.3014 - val_loss: 1.3666 - val_acc: 0.3644\n",
      "Epoch 2/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3787 - acc: 0.3171 - val_loss: 1.3584 - val_acc: 0.3694\n",
      "Epoch 3/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3778 - acc: 0.3212 - val_loss: 1.3646 - val_acc: 0.3694\n",
      "Epoch 4/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3719 - acc: 0.3265 - val_loss: 1.3650 - val_acc: 0.3694\n",
      "Epoch 5/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3729 - acc: 0.3293 - val_loss: 1.3709 - val_acc: 0.3694\n",
      "Epoch 6/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3641 - acc: 0.3285 - val_loss: 1.3625 - val_acc: 0.3694\n",
      "Epoch 7/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3600 - acc: 0.3346 - val_loss: 1.3681 - val_acc: 0.3694\n",
      "Epoch 8/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3599 - acc: 0.3356 - val_loss: 1.3599 - val_acc: 0.3694\n",
      "Epoch 9/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3552 - acc: 0.3298 - val_loss: 1.3736 - val_acc: 0.3674\n",
      "Epoch 10/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3573 - acc: 0.3303 - val_loss: 1.3456 - val_acc: 0.3988\n",
      "Epoch 11/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3466 - acc: 0.3404 - val_loss: 1.3295 - val_acc: 0.3968\n",
      "Epoch 12/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3361 - acc: 0.3463 - val_loss: 1.3242 - val_acc: 0.4211\n",
      "Epoch 13/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3300 - acc: 0.3501 - val_loss: 1.2832 - val_acc: 0.4190\n",
      "Epoch 14/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3158 - acc: 0.3777 - val_loss: 1.2657 - val_acc: 0.4261\n",
      "Epoch 15/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3004 - acc: 0.3739 - val_loss: 1.2559 - val_acc: 0.4545\n",
      "Epoch 16/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2928 - acc: 0.3716 - val_loss: 1.2352 - val_acc: 0.4534\n",
      "Epoch 17/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2748 - acc: 0.3794 - val_loss: 1.2239 - val_acc: 0.4717\n",
      "Epoch 18/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2774 - acc: 0.3830 - val_loss: 1.2213 - val_acc: 0.4777\n",
      "Epoch 19/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2614 - acc: 0.3934 - val_loss: 1.4188 - val_acc: 0.3553\n",
      "Epoch 20/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2600 - acc: 0.3924 - val_loss: 1.2254 - val_acc: 0.4990\n",
      "Epoch 21/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2416 - acc: 0.4073 - val_loss: 1.1946 - val_acc: 0.4929\n",
      "Epoch 22/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2371 - acc: 0.4065 - val_loss: 1.2047 - val_acc: 0.4109\n",
      "Epoch 23/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2331 - acc: 0.4058 - val_loss: 1.2547 - val_acc: 0.5111\n",
      "Epoch 24/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2192 - acc: 0.4192 - val_loss: 1.4193 - val_acc: 0.4717\n",
      "Epoch 25/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2193 - acc: 0.4174 - val_loss: 1.2946 - val_acc: 0.3978\n",
      "Epoch 26/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2104 - acc: 0.4288 - val_loss: 1.3893 - val_acc: 0.4585\n",
      "Epoch 27/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1994 - acc: 0.4298 - val_loss: 1.3151 - val_acc: 0.4109\n",
      "Epoch 28/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2023 - acc: 0.4291 - val_loss: 1.2289 - val_acc: 0.4484\n",
      "Epoch 29/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1964 - acc: 0.4306 - val_loss: 1.6286 - val_acc: 0.4200\n",
      "Epoch 30/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1920 - acc: 0.4440 - val_loss: 1.4865 - val_acc: 0.4474\n",
      "Epoch 31/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1914 - acc: 0.4311 - val_loss: 1.4587 - val_acc: 0.4038\n",
      "Epoch 32/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1783 - acc: 0.4397 - val_loss: 1.3250 - val_acc: 0.3957\n",
      "Epoch 33/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1749 - acc: 0.4433 - val_loss: 1.2618 - val_acc: 0.4332\n",
      "Epoch 34/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1692 - acc: 0.4483 - val_loss: 1.3344 - val_acc: 0.5071\n",
      "Epoch 35/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1724 - acc: 0.4405 - val_loss: 1.2875 - val_acc: 0.3998\n",
      "Epoch 36/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1714 - acc: 0.4471 - val_loss: 1.2510 - val_acc: 0.4332\n",
      "Epoch 37/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1706 - acc: 0.4422 - val_loss: 1.2184 - val_acc: 0.4474\n",
      "Epoch 38/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1573 - acc: 0.4602 - val_loss: 1.3173 - val_acc: 0.4858\n",
      "Epoch 39/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1560 - acc: 0.4625 - val_loss: 1.3541 - val_acc: 0.4393\n",
      "Epoch 40/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1510 - acc: 0.4569 - val_loss: 1.2061 - val_acc: 0.5152\n",
      "Epoch 41/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1631 - acc: 0.4610 - val_loss: 1.5473 - val_acc: 0.4352\n",
      "Epoch 42/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1510 - acc: 0.4592 - val_loss: 1.6288 - val_acc: 0.4413\n",
      "Epoch 43/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1477 - acc: 0.4618 - val_loss: 1.5382 - val_acc: 0.4038\n",
      "Epoch 44/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1355 - acc: 0.4729 - val_loss: 1.2370 - val_acc: 0.4474\n",
      "Epoch 45/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1387 - acc: 0.4770 - val_loss: 1.2427 - val_acc: 0.4170\n",
      "Epoch 46/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1391 - acc: 0.4602 - val_loss: 1.5301 - val_acc: 0.4494\n",
      "Epoch 47/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1271 - acc: 0.4787 - val_loss: 1.2900 - val_acc: 0.4312\n",
      "Epoch 48/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1350 - acc: 0.4699 - val_loss: 1.2886 - val_acc: 0.4514\n",
      "Epoch 49/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1259 - acc: 0.4828 - val_loss: 1.6279 - val_acc: 0.3887\n",
      "Epoch 50/50\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1261 - acc: 0.4714 - val_loss: 1.4503 - val_acc: 0.4453\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=50, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train2.reshape(-1,200,189,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(200, 189)))\n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_simple_lstm(nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(197440000,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3 = []\n",
    "sig_avg = []\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_sig = ses_mod['signal']\n",
    "    x_sig = np.array(x_sig, dtype=np.float64)\n",
    "    if(x_sig.size<40000):\n",
    "        z = np.zeros((40000-x_sig.size), dtype=np.float64)\n",
    "        x_sig = np.concatenate((x_sig, z), axis=0)\n",
    "    x_sig = np.array_split(x_sig, 40000)\n",
    "    #x_sig[np.isnan(x_sig)]=0\n",
    "    for spl in x_sig:\n",
    "        x_train3.append(np.mean(spl, axis=0))\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print (counter)\n",
    "x_train3 = np.array(x_train3)\n",
    "x_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-165.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_all = {}\n",
    "sig_all['signal'] = x_train3\n",
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'signal_200_2.pickle', 'wb') as handle:\n",
    "    pickle.dump(sig_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3 = x_train3.reshape(-1,200,200,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 200, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_proc_raw = {}\n",
    "sig_proc_raw['signal'] = x_train3\n",
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'raw_sig.pickle', 'wb') as handle:\n",
    "    pickle.dump(sig_proc_raw, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(1000,10)))\n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 1000, 512)         1071104   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,435,012\n",
      "Trainable params: 3,435,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm(nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 261s 66ms/step - loss: 1.3721 - acc: 0.3328 - val_loss: 1.3846 - val_acc: 0.3694\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 260s 66ms/step - loss: 1.3831 - acc: 0.3402 - val_loss: 1.3815 - val_acc: 0.3694\n",
      "Epoch 3/30\n",
      "1728/3948 [============>.................] - ETA: 2:14 - loss: 1.3813 - acc: 0.3374"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2dfd038e51a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train3, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train3, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_conv2(nb_class, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 200, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 50, 50, 64)        640       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 13, 13, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,865,924\n",
      "Trainable params: 1,865,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2), input_shape=(100, 100,...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_conv2(nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train3 = x_train3.reshape(-1,100,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_33_input to have shape (None, 100, 100, 1) but got array with shape (4936, 200, 200, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-2dfd038e51a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train3, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1412\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1415\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    151\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_33_input to have shape (None, 100, 100, 1) but got array with shape (4936, 200, 200, 1)"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train3, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   2.85714286],\n",
       "        [  21.71428571],\n",
       "        [ -58.57142857],\n",
       "        ..., \n",
       "        [  -0.57142857],\n",
       "        [  49.42857143],\n",
       "        [ 226.85714286]],\n",
       "\n",
       "       [[  -2.14285714],\n",
       "        [-154.14285714],\n",
       "        [  13.28571429],\n",
       "        ..., \n",
       "        [-121.14285714],\n",
       "        [-120.71428571],\n",
       "        [ -26.14285714]],\n",
       "\n",
       "       [[  35.        ],\n",
       "        [ 100.71428571],\n",
       "        [  61.85714286],\n",
       "        ..., \n",
       "        [  63.14285714],\n",
       "        [  -3.42857143],\n",
       "        [-207.42857143]],\n",
       "\n",
       "       ..., \n",
       "       [[ -14.33333333],\n",
       "        [ -14.66666667],\n",
       "        [  -3.16666667],\n",
       "        ..., \n",
       "        [  -2.66666667],\n",
       "        [  11.66666667],\n",
       "        [  11.83333333]],\n",
       "\n",
       "       [[  -4.33333333],\n",
       "        [ -13.16666667],\n",
       "        [ -17.33333333],\n",
       "        ..., \n",
       "        [  26.33333333],\n",
       "        [  23.5       ],\n",
       "        [  23.16666667]],\n",
       "\n",
       "       [[  36.66666667],\n",
       "        [  44.33333333],\n",
       "        [  27.83333333],\n",
       "        ..., \n",
       "        [ -21.        ],\n",
       "        [ -13.        ],\n",
       "        [ -23.5       ]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
