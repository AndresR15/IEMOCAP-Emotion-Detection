{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 80\n",
    "\n",
    "optimizer = 'Adadelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /home/samarth/emotion_recognition-master/code/utilities/../../data/ses\n",
      "path_to_features              /home/samarth/emotion_recognition-master/code/utilities/../../data/fea\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <class 'numpy.int8'>, 2: <class 'numpy.int16'>, 4: <class 'numpy.i\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mocap_head(path_to_mocap_head, filename, start,end, params=Constants()):\n",
    "    f = open(path_to_mocap_head + filename, 'r').read()\n",
    "    f = np.array(f.split('\\n'))\n",
    "    mocap_head = []\n",
    "    mocap_head_avg = []\n",
    "    f = f[2:]\n",
    "    counter = 0\n",
    "    for data in f:\n",
    "        counter+=1\n",
    "        data2 = data.split(' ')\n",
    "        if(len(data2)<2):\n",
    "            continue\n",
    "        if(float(data2[1])>start and float(data2[1])<end):\n",
    "            mocap_head_avg.append(np.array(data2[2:]).astype(np.float))\n",
    "            \n",
    "    mocap_head_avg = np.array_split(np.array(mocap_head_avg), 200)\n",
    "    for spl in mocap_head_avg:\n",
    "        mocap_head.append(np.mean(spl, axis=0))\n",
    "    return np.array(mocap_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mocap_rot(path_to_mocap_rot, filename, start,end, params=Constants()):\n",
    "    f = open(path_to_mocap_rot + filename, 'r').read()\n",
    "    f = np.array(f.split('\\n'))\n",
    "    mocap_rot = []\n",
    "    mocap_rot_avg = []\n",
    "    f = f[2:]\n",
    "    counter = 0\n",
    "    for data in f:\n",
    "        counter+=1\n",
    "        data2 = data.split(' ')\n",
    "        if(len(data2)<2):\n",
    "            continue\n",
    "        if(float(data2[1])>start and float(data2[1])<end):\n",
    "            mocap_rot_avg.append(np.array(data2[2:]).astype(np.float))\n",
    "            \n",
    "    mocap_rot_avg = np.array_split(np.array(mocap_rot_avg), 200)\n",
    "    for spl in mocap_rot_avg:\n",
    "        mocap_rot.append(np.mean(spl, axis=0))\n",
    "    return np.array(mocap_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iemocap_mocap_head(params=Constants()):\n",
    "    data = []\n",
    "    ids = {}\n",
    "    for session in params.sessions:\n",
    "        path_to_wav = params.path_to_data + session + '/dialog/wav/'\n",
    "        path_to_emotions = params.path_to_data + session + '/dialog/EmoEvaluation/'\n",
    "        path_to_transcriptions = params.path_to_data + session + '/dialog/transcriptions/'\n",
    "        path_to_mocap_head = params.path_to_data + session + '/dialog/MOCAP_head/'\n",
    "\n",
    "        files2 = os.listdir(path_to_wav)\n",
    "        #print (files2.sort())\n",
    "        files = []\n",
    "        for f in files2:\n",
    "            if f.endswith(\".wav\"):\n",
    "                if f[0] == '.':\n",
    "                    files.append(f[2:-4])\n",
    "                else:\n",
    "                    files.append(f[:-4])\n",
    "                    \n",
    "        #files = os.listdir(path_to_wav)\n",
    "        #files = [f[:-4] for f in files if f.endswith(\".wav\")]\n",
    "        for f in files:       \n",
    "            print(f)\n",
    "            if (f== 'Ses05M_script01_1b'):\n",
    "                continue\n",
    "            transcriptions = get_transcriptions(path_to_transcriptions, f + '.txt')\n",
    "            emotions = get_emotions(path_to_emotions, f + '.txt')\n",
    "\n",
    "            for ie, e in enumerate(emotions):\n",
    "                e.pop(\"left\", None)\n",
    "                e.pop(\"right\", None)\n",
    "                e['transcription'] = transcriptions[e['id']]\n",
    "                e['mocap_head'] = get_mocap_head(path_to_mocap_head, f + '.txt', e['start'], e['end'])\n",
    "                if e['emotion'] in params.available_emotions:\n",
    "                    if e['id'] not in ids:\n",
    "                        data.append(e)\n",
    "                        ids[e['id']] = 1\n",
    "\n",
    "                        \n",
    "    sort_key = get_field(data, \"id\")\n",
    "    return np.array(data)[np.argsort(sort_key)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_impro02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_script03_2\n",
      "Ses01M_script01_2\n",
      "Ses01F_impro03\n",
      "Ses01F_impro05\n",
      "Ses01M_script02_2\n",
      "Ses01M_impro06\n",
      "Ses01F_script03_2\n",
      "Ses01F_script01_3\n",
      "Ses01M_impro01\n",
      "Ses01M_impro03\n",
      "Ses01M_impro04\n",
      "Ses01F_script01_2\n",
      "Ses01F_script03_1\n",
      "Ses01F_impro07\n",
      "Ses01M_impro02\n",
      "Ses01F_script02_2\n",
      "Ses01F_script01_2\n",
      "Ses01F_script02_2\n",
      "Ses01M_script02_2\n",
      "Ses01M_script01_3\n",
      "Ses01M_script03_2\n",
      "Ses01F_impro01\n",
      "Ses01M_script02_1\n",
      "Ses01F_impro07\n",
      "Ses01M_script02_1\n",
      "Ses01M_impro04\n",
      "Ses01M_script01_2\n",
      "Ses01F_impro01\n",
      "Ses01M_script03_1\n",
      "Ses01M_script01_3\n",
      "Ses01F_impro02\n",
      "Ses01M_impro06\n",
      "Ses01M_impro05\n",
      "Ses01M_script03_2\n",
      "Ses01F_script02_1\n",
      "Ses01M_impro05\n",
      "Ses01F_impro04\n",
      "Ses01F_script01_1\n",
      "Ses01F_impro04\n",
      "Ses01F_impro03\n",
      "Ses01M_script01_1\n",
      "Ses01F_script01_1\n",
      "Ses01M_script01_1\n",
      "Ses01M_impro07\n",
      "Ses01F_script02_1\n",
      "Ses01M_impro02\n",
      "Ses01F_impro05\n",
      "Ses01M_impro03\n",
      "Ses01F_impro06\n",
      "Ses01M_impro07\n",
      "Ses01M_impro01\n",
      "Ses01F_impro06\n",
      "Ses01F_script01_3\n",
      "Ses01F_script03_1\n",
      "Ses01M_script03_1\n",
      "Ses02M_impro07\n",
      "Ses02F_impro07\n",
      "Ses02F_impro04\n",
      "Ses02F_impro02\n",
      "Ses02F_script02_1\n",
      "Ses02M_impro08\n",
      "Ses02M_impro04\n",
      "Ses02M_impro02\n",
      "Ses02F_impro04\n",
      "Ses02F_script03_1\n",
      "Ses02M_script01_2\n",
      "Ses02M_script02_1\n",
      "Ses02M_script02_2\n",
      "Ses02M_script01_2\n",
      "Ses02F_impro02\n",
      "Ses02F_impro01\n",
      "Ses02M_impro03\n",
      "Ses02F_impro08\n",
      "Ses02F_script03_2\n",
      "Ses02M_impro05\n",
      "Ses02M_script01_1\n",
      "Ses02M_impro03\n",
      "Ses02M_script03_1\n",
      "Ses02F_script03_1\n",
      "Ses02M_impro05\n",
      "Ses02F_script01_2\n",
      "Ses02M_impro07\n",
      "Ses02F_script01_3\n",
      "Ses02M_script01_3\n",
      "Ses02F_script02_2\n",
      "Ses02M_impro02\n",
      "Ses02M_impro06\n",
      "Ses02M_script03_1\n",
      "Ses02F_script03_2\n",
      "Ses02F_script01_2\n",
      "Ses02M_impro01\n",
      "Ses02M_script01_1\n",
      "Ses02M_script02_1\n",
      "Ses02F_impro03\n",
      "Ses02F_script01_1\n",
      "Ses02F_impro07\n",
      "Ses02M_script03_2\n",
      "Ses02F_script02_2\n",
      "Ses02F_impro06\n",
      "Ses02M_impro04\n",
      "Ses02M_impro08\n",
      "Ses02M_impro01\n",
      "Ses02F_impro05\n",
      "Ses02M_script03_2\n",
      "Ses02M_script01_3\n",
      "Ses02F_impro01\n",
      "Ses02M_impro06\n",
      "Ses02F_script02_1\n",
      "Ses02F_impro05\n",
      "Ses02F_impro08\n",
      "Ses02F_impro06\n",
      "Ses02F_impro03\n",
      "Ses02F_script01_1\n",
      "Ses02M_script02_2\n",
      "Ses02F_script01_3\n",
      "Ses03F_impro07\n",
      "Ses03F_script03_2\n",
      "Ses03M_impro05a\n",
      "Ses03F_script01_2\n",
      "Ses03M_impro08b\n",
      "Ses03M_impro06\n",
      "Ses03F_script03_1\n",
      "Ses03M_impro01\n",
      "Ses03M_impro07\n",
      "Ses03M_script01_3\n",
      "Ses03M_script01_2\n",
      "Ses03M_impro01\n",
      "Ses03M_impro05b\n",
      "Ses03F_impro08\n",
      "Ses03F_script02_1\n",
      "Ses03F_script03_2\n",
      "Ses03F_script03_1\n",
      "Ses03F_script02_1\n",
      "Ses03M_script01_1\n",
      "Ses03F_impro03\n",
      "Ses03M_script02_1\n",
      "Ses03M_impro06\n",
      "Ses03M_script01_1\n",
      "Ses03M_script03_1\n",
      "Ses03M_impro08a\n",
      "Ses03F_impro02\n",
      "Ses03F_impro08\n",
      "Ses03F_script02_2\n",
      "Ses03M_impro05b\n",
      "Ses03M_script01_2\n",
      "Ses03M_impro02\n",
      "Ses03F_impro02\n",
      "Ses03F_impro07\n",
      "Ses03M_script02_2\n",
      "Ses03F_impro06\n",
      "Ses03M_impro07\n",
      "Ses03M_impro02\n",
      "Ses03F_impro06\n",
      "Ses03F_impro03\n",
      "Ses03M_impro08b\n",
      "Ses03M_script03_1\n",
      "Ses03F_impro04\n",
      "Ses03M_impro04\n",
      "Ses03M_script01_3\n",
      "Ses03M_impro08a\n",
      "Ses03M_script03_2\n",
      "Ses03F_impro01\n",
      "Ses03F_script02_2\n",
      "Ses03M_impro04\n",
      "Ses03M_script02_2\n",
      "Ses03M_impro03\n",
      "Ses03M_script03_2\n",
      "Ses03F_script01_2\n",
      "Ses03F_impro01\n",
      "Ses03F_impro05\n",
      "Ses03F_impro04\n",
      "Ses03F_script01_1\n",
      "Ses03M_script02_1\n",
      "Ses03F_script01_3\n",
      "Ses03F_script01_3\n",
      "Ses03M_impro05a\n",
      "Ses03F_script01_1\n",
      "Ses03F_impro05\n",
      "Ses03M_impro03\n",
      "Ses04M_impro02\n",
      "Ses04M_script03_1\n",
      "Ses04M_impro06\n",
      "Ses04F_script01_2\n",
      "Ses04M_impro04\n",
      "Ses04M_impro03\n",
      "Ses04M_script01_3\n",
      "Ses04F_impro08\n",
      "Ses04M_impro01\n",
      "Ses04M_script01_2\n",
      "Ses04F_script02_2\n",
      "Ses04M_script03_1\n",
      "Ses04M_script01_3\n",
      "Ses04F_impro07\n",
      "Ses04F_script01_1\n",
      "Ses04F_impro06\n",
      "Ses04M_script02_1\n",
      "Ses04F_impro02\n",
      "Ses04F_script01_2\n",
      "Ses04M_script02_2\n",
      "Ses04M_impro02\n",
      "Ses04F_script01_1\n",
      "Ses04F_impro04\n",
      "Ses04M_impro08\n",
      "Ses04F_script03_1\n",
      "Ses04M_impro05\n",
      "Ses04F_script03_1\n",
      "Ses04F_script02_1\n",
      "Ses04M_impro04\n",
      "Ses04M_impro06\n",
      "Ses04F_script03_2\n",
      "Ses04F_impro05\n",
      "Ses04F_script02_2\n",
      "Ses04M_script02_1\n",
      "Ses04M_script01_2\n",
      "Ses04F_script01_3\n",
      "Ses04F_script01_3\n",
      "Ses04F_impro08\n",
      "Ses04M_impro08\n",
      "Ses04M_script03_2\n",
      "Ses04F_impro06\n",
      "Ses04M_script02_2\n",
      "Ses04M_impro03\n",
      "Ses04F_script03_2\n",
      "Ses04M_impro07\n",
      "Ses04F_impro01\n",
      "Ses04F_impro04\n",
      "Ses04F_script02_1\n",
      "Ses04M_impro07\n",
      "Ses04M_impro01\n",
      "Ses04F_impro05\n",
      "Ses04M_impro05\n",
      "Ses04F_impro03\n",
      "Ses04F_impro07\n",
      "Ses04M_script01_1\n",
      "Ses04F_impro03\n",
      "Ses04F_impro01\n",
      "Ses04M_script03_2\n",
      "Ses04F_impro02\n",
      "Ses04M_script01_1\n",
      "Ses05M_script01_2\n",
      "Ses05F_impro04\n",
      "Ses05F_impro04\n",
      "Ses05F_script01_1\n",
      "Ses05M_impro06\n",
      "Ses05M_script03_2\n",
      "Ses05F_script03_2\n",
      "Ses05M_impro03\n",
      "Ses05F_script03_2\n",
      "Ses05M_script03_1\n",
      "Ses05M_impro02\n",
      "Ses05F_impro08\n",
      "Ses05M_impro07\n",
      "Ses05M_script01_3\n",
      "Ses05F_impro07\n",
      "Ses05M_impro08\n",
      "Ses05F_script02_1\n",
      "Ses05M_script03_1\n",
      "Ses05M_impro03\n",
      "Ses05F_impro03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses05M_impro01\n",
      "Ses05F_impro02\n",
      "Ses05F_impro01\n",
      "Ses05F_impro08\n",
      "Ses05F_script01_3\n",
      "Ses05M_impro04\n",
      "Ses05F_impro06\n",
      "Ses05M_script01_1b\n",
      "Ses05F_impro05\n",
      "Ses05M_script01_1\n",
      "Ses05F_impro03\n",
      "Ses05F_script02_2\n",
      "Ses05M_script01_1\n",
      "Ses05F_script01_1\n",
      "Ses05M_impro06\n",
      "Ses05F_impro05\n",
      "Ses05M_impro04\n",
      "Ses05F_script03_1\n",
      "Ses05M_impro08\n",
      "Ses05M_impro02\n",
      "Ses05M_script01_3\n",
      "Ses05F_script02_1\n",
      "Ses05F_script01_2\n",
      "Ses05M_script01_2\n",
      "Ses05M_script02_1\n",
      "Ses05F_impro07\n",
      "Ses05M_impro07\n",
      "Ses05F_script03_1\n",
      "Ses05F_script01_2\n",
      "Ses05M_script02_1\n",
      "Ses05F_script02_2\n",
      "Ses05M_script02_2\n",
      "Ses05F_impro01\n",
      "Ses05M_script02_2\n",
      "Ses05M_impro01\n",
      "Ses05F_impro06\n",
      "Ses05F_impro02\n",
      "Ses05M_script03_2\n",
      "Ses05F_script01_3\n",
      "Ses05M_impro05\n",
      "Ses05M_impro05\n",
      "Ses05M_script01_1b\n"
     ]
    }
   ],
   "source": [
    "data = read_iemocap_mocap_head(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'hear.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4912"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2.5,\n",
       " 'd': 2.5,\n",
       " 'emo_evo': [['neu'], ['neu'], ['neu'], ['neu', 'ang']],\n",
       " 'emotion': 'neu',\n",
       " 'end': 11.3925,\n",
       " 'id': 'Ses01F_impro01_F001',\n",
       " 'mocap_head': array([[ -3.01623500e+00,  -1.53231875e+01,  -2.58177725e+01,\n",
       "          -3.50085000e+00,  -1.25055738e+02,  -6.09216000e+00],\n",
       "        [ -3.03349750e+00,  -1.53290150e+01,  -2.58318275e+01,\n",
       "          -3.48152000e+00,  -1.25053363e+02,  -6.11257000e+00],\n",
       "        [ -3.05529000e+00,  -1.53076150e+01,  -2.58582975e+01,\n",
       "          -3.46259250e+00,  -1.25137442e+02,  -6.16912500e+00],\n",
       "        [ -3.09448500e+00,  -1.52989275e+01,  -2.58030975e+01,\n",
       "          -3.51556750e+00,  -1.25170455e+02,  -6.24870500e+00],\n",
       "        [ -3.15129000e+00,  -1.52903750e+01,  -2.57879075e+01,\n",
       "          -3.57438250e+00,  -1.25319537e+02,  -6.41077000e+00],\n",
       "        [ -3.17681000e+00,  -1.52697200e+01,  -2.57643500e+01,\n",
       "          -3.58836000e+00,  -1.25421822e+02,  -6.54454500e+00],\n",
       "        [ -3.21464000e+00,  -1.52530050e+01,  -2.57842175e+01,\n",
       "          -3.59895000e+00,  -1.25605418e+02,  -6.73631750e+00],\n",
       "        [ -3.23742000e+00,  -1.52591175e+01,  -2.57879025e+01,\n",
       "          -3.66825250e+00,  -1.25804987e+02,  -6.92064250e+00],\n",
       "        [ -3.27645500e+00,  -1.52549700e+01,  -2.57816550e+01,\n",
       "          -3.69417250e+00,  -1.25964640e+02,  -7.04414750e+00],\n",
       "        [ -3.38132500e+00,  -1.52550700e+01,  -2.57847050e+01,\n",
       "          -3.67653750e+00,  -1.26172890e+02,  -7.29783500e+00],\n",
       "        [ -3.41553500e+00,  -1.52515700e+01,  -2.57145475e+01,\n",
       "          -3.80311000e+00,  -1.26333460e+02,  -7.42502250e+00],\n",
       "        [ -3.46827750e+00,  -1.52446425e+01,  -2.56601175e+01,\n",
       "          -3.95106000e+00,  -1.26604237e+02,  -7.66156500e+00],\n",
       "        [ -3.65046000e+00,  -1.52300575e+01,  -2.56304575e+01,\n",
       "          -4.02415500e+00,  -1.26730712e+02,  -8.07817500e+00],\n",
       "        [ -3.80134000e+00,  -1.52054500e+01,  -2.56403075e+01,\n",
       "          -4.08525250e+00,  -1.26805567e+02,  -8.36981500e+00],\n",
       "        [ -3.82786500e+00,  -1.51994700e+01,  -2.58058625e+01,\n",
       "          -4.02868250e+00,  -1.27211363e+02,  -8.47791000e+00],\n",
       "        [ -3.59886250e+00,  -1.51074625e+01,  -2.64511675e+01,\n",
       "          -3.29473500e+00,  -1.28108297e+02,  -8.24994500e+00],\n",
       "        [ -3.26945000e+00,  -1.48414667e+01,  -2.74102433e+01,\n",
       "          -1.80849333e+00,  -1.29458470e+02,  -8.18640667e+00],\n",
       "        [ -3.04563000e+00,  -1.44641400e+01,  -2.85261267e+01,\n",
       "           1.78276667e-01,  -1.30850390e+02,  -8.25148000e+00],\n",
       "        [ -2.78060333e+00,  -1.39710933e+01,  -2.98797000e+01,\n",
       "           2.57793333e+00,  -1.32619713e+02,  -8.18157333e+00],\n",
       "        [ -2.56172333e+00,  -1.34481867e+01,  -3.13090033e+01,\n",
       "           5.23067000e+00,  -1.34760810e+02,  -8.01998667e+00],\n",
       "        [ -2.37674667e+00,  -1.29981733e+01,  -3.27922967e+01,\n",
       "           7.99738000e+00,  -1.37015603e+02,  -7.69374000e+00],\n",
       "        [ -2.13367333e+00,  -1.26439167e+01,  -3.41737700e+01,\n",
       "           1.06516500e+01,  -1.39246400e+02,  -7.03432667e+00],\n",
       "        [ -1.83187667e+00,  -1.24452600e+01,  -3.55756500e+01,\n",
       "           1.31467833e+01,  -1.41541133e+02,  -6.08186333e+00],\n",
       "        [ -1.45798333e+00,  -1.24357200e+01,  -3.68437533e+01,\n",
       "           1.52956433e+01,  -1.43675740e+02,  -5.01768333e+00],\n",
       "        [ -8.82890000e-01,  -1.25679967e+01,  -3.80225467e+01,\n",
       "           1.70483133e+01,  -1.45524560e+02,  -3.70996667e+00],\n",
       "        [ -2.27053333e-01,  -1.28784100e+01,  -3.89999333e+01,\n",
       "           1.81851800e+01,  -1.47093130e+02,  -2.24495667e+00],\n",
       "        [  4.72136667e-01,  -1.33165800e+01,  -3.97258133e+01,\n",
       "           1.88580267e+01,  -1.48276423e+02,  -8.30246667e-01],\n",
       "        [  1.11158667e+00,  -1.37404333e+01,  -4.01955933e+01,\n",
       "           1.92040933e+01,  -1.48977013e+02,   4.67950000e-01],\n",
       "        [  1.54040000e+00,  -1.41691400e+01,  -4.03300133e+01,\n",
       "           1.91793800e+01,  -1.49018403e+02,   1.38064000e+00],\n",
       "        [  1.70743667e+00,  -1.47230200e+01,  -4.01647700e+01,\n",
       "           1.89117833e+01,  -1.48280330e+02,   1.87910667e+00],\n",
       "        [  1.59107667e+00,  -1.54384667e+01,  -3.97029967e+01,\n",
       "           1.83068800e+01,  -1.46889193e+02,   1.77049333e+00],\n",
       "        [  1.45325667e+00,  -1.62068300e+01,  -3.90697933e+01,\n",
       "           1.74536733e+01,  -1.45148110e+02,   1.36464333e+00],\n",
       "        [  1.24038667e+00,  -1.69928000e+01,  -3.81219433e+01,\n",
       "           1.62365833e+01,  -1.42966347e+02,   7.10100000e-01],\n",
       "        [  9.60820000e-01,  -1.76763300e+01,  -3.68825400e+01,\n",
       "           1.47025367e+01,  -1.40383143e+02,  -1.30723333e-01],\n",
       "        [  6.29023333e-01,  -1.82005100e+01,  -3.55048533e+01,\n",
       "           1.29497333e+01,  -1.37676340e+02,  -1.04623667e+00],\n",
       "        [  2.37556667e-01,  -1.85333900e+01,  -3.40428700e+01,\n",
       "           1.11676833e+01,  -1.34993193e+02,  -1.95899667e+00],\n",
       "        [ -1.24466667e-01,  -1.86565633e+01,  -3.25558833e+01,\n",
       "           9.38409667e+00,  -1.32459223e+02,  -2.76584333e+00],\n",
       "        [ -4.89230000e-01,  -1.86654367e+01,  -3.10688733e+01,\n",
       "           7.62165333e+00,  -1.30128257e+02,  -3.57712333e+00],\n",
       "        [ -7.49063333e-01,  -1.85222200e+01,  -2.96815267e+01,\n",
       "           6.02009333e+00,  -1.27935033e+02,  -4.25209000e+00],\n",
       "        [ -9.87460000e-01,  -1.82541033e+01,  -2.83758900e+01,\n",
       "           4.48063333e+00,  -1.26030503e+02,  -4.75216000e+00],\n",
       "        [ -1.12380667e+00,  -1.79111333e+01,  -2.72211833e+01,\n",
       "           2.98080667e+00,  -1.24371750e+02,  -4.98750333e+00],\n",
       "        [ -1.21459667e+00,  -1.74695033e+01,  -2.61332567e+01,\n",
       "           1.52414667e+00,  -1.22989963e+02,  -5.23100000e+00],\n",
       "        [ -1.39764000e+00,  -1.69913533e+01,  -2.50472400e+01,\n",
       "           1.25270000e-01,  -1.21819770e+02,  -5.57749667e+00],\n",
       "        [ -1.47444000e+00,  -1.65141300e+01,  -2.40419867e+01,\n",
       "          -1.34797667e+00,  -1.21079477e+02,  -5.67108667e+00],\n",
       "        [ -1.33334000e+00,  -1.61344467e+01,  -2.32595400e+01,\n",
       "          -2.86846667e+00,  -1.20853637e+02,  -5.34981667e+00],\n",
       "        [ -1.13821000e+00,  -1.58800267e+01,  -2.25656767e+01,\n",
       "          -4.48764667e+00,  -1.20946510e+02,  -4.78055333e+00],\n",
       "        [ -8.39480000e-01,  -1.57489367e+01,  -2.19896033e+01,\n",
       "          -6.09455000e+00,  -1.21487560e+02,  -4.06179000e+00],\n",
       "        [ -5.31170000e-01,  -1.57195467e+01,  -2.14723867e+01,\n",
       "          -7.67887333e+00,  -1.22127493e+02,  -3.23077667e+00],\n",
       "        [ -2.61826667e-01,  -1.57021500e+01,  -2.12201200e+01,\n",
       "          -9.05123333e+00,  -1.23117827e+02,  -2.63355000e+00],\n",
       "        [ -4.16433333e-02,  -1.56943700e+01,  -2.09787467e+01,\n",
       "          -1.03391233e+01,  -1.24188530e+02,  -2.21178667e+00]]),\n",
       " 'start': 10.01,\n",
       " 'transcription': 'Yeah.',\n",
       " 'v': 2.5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 200, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "for ses_mod in data:\n",
    "    x = ses_mod['mocap_head']\n",
    "    x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    x_normed = x_normed - 0.5\n",
    "    x_normed[np.isnan(x)]=0\n",
    "    x_train2.append( x_normed )\n",
    "    \n",
    "x_train2 = np.array(x_train2)\n",
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       ,  0.30999731,  0.47602887, -0.46676503, -0.47426847,\n",
       "        -0.49371681],\n",
       "       [-0.49839752,  0.30906637,  0.47766798, -0.46579917, -0.46885793,\n",
       "        -0.49082548],\n",
       "       [-0.49705638,  0.30734147,  0.47383232, -0.46297283, -0.46441113,\n",
       "        -0.4886732 ],\n",
       "       ..., \n",
       "       [ 0.47400213, -0.00990041, -0.47495422,  0.46006412,  0.39238546,\n",
       "         0.47546626],\n",
       "       [ 0.47389361, -0.00959095, -0.47065307,  0.45697644,  0.39200217,\n",
       "         0.47513772],\n",
       "       [ 0.47521485, -0.0080081 , -0.47458004,  0.45594473,  0.38807688,\n",
       "         0.47439536]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.34857534, -0.31906291, -0.13973628, -0.26088676, -0.33896537,\n",
       "        -0.26562003],\n",
       "       [-0.3532934 , -0.31933028, -0.13991004, -0.25999571, -0.33886791,\n",
       "        -0.26878929],\n",
       "       [-0.35128522, -0.31951476, -0.13999976, -0.25997566, -0.3389048 ,\n",
       "        -0.26744871],\n",
       "       ..., \n",
       "       [ 0.18948048,  0.5       ,  0.5       , -0.14309488,  0.5       ,\n",
       "         0.31672145],\n",
       "       [ 0.18948048,  0.5       ,  0.5       , -0.14309488,  0.5       ,\n",
       "         0.31672145],\n",
       "       [ 0.18948048,  0.5       ,  0.5       , -0.14309488,  0.5       ,\n",
       "         0.31672145]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 1200)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = x_train2.reshape(-1,1200)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv2D, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution2D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple2(nb_class, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512  , input_shape=(1200,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple2(nb_class, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128  , input_shape=(200,6) ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               69120     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 77,636\n",
      "Trainable params: 77,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple2(nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3929 samples, validate on 983 samples\n",
      "Epoch 1/15\n",
      "3929/3929 [==============================] - 19s 5ms/step - loss: 1.3708 - acc: 0.3197 - val_loss: 1.3620 - val_acc: 0.3642\n",
      "Epoch 2/15\n",
      "3929/3929 [==============================] - 17s 4ms/step - loss: 1.3629 - acc: 0.3299 - val_loss: 1.3431 - val_acc: 0.3672\n",
      "Epoch 3/15\n",
      "3929/3929 [==============================] - 17s 4ms/step - loss: 1.3586 - acc: 0.3339 - val_loss: 1.3513 - val_acc: 0.3632\n",
      "Epoch 4/15\n",
      "3929/3929 [==============================] - 18s 4ms/step - loss: 1.3576 - acc: 0.3329 - val_loss: 1.3516 - val_acc: 0.3713\n",
      "Epoch 5/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3587 - acc: 0.3365 - val_loss: 1.3415 - val_acc: 0.3622\n",
      "Epoch 6/15\n",
      "3929/3929 [==============================] - 17s 4ms/step - loss: 1.3547 - acc: 0.3365 - val_loss: 1.3441 - val_acc: 0.3622\n",
      "Epoch 7/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3528 - acc: 0.3395 - val_loss: 1.3681 - val_acc: 0.3510\n",
      "Epoch 8/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3478 - acc: 0.3433 - val_loss: 1.3611 - val_acc: 0.3489\n",
      "Epoch 9/15\n",
      "3929/3929 [==============================] - 17s 4ms/step - loss: 1.3491 - acc: 0.3428 - val_loss: 1.3487 - val_acc: 0.3662\n",
      "Epoch 10/15\n",
      "3929/3929 [==============================] - 18s 4ms/step - loss: 1.3443 - acc: 0.3393 - val_loss: 1.3668 - val_acc: 0.3388\n",
      "Epoch 11/15\n",
      "3929/3929 [==============================] - 17s 4ms/step - loss: 1.3434 - acc: 0.3449 - val_loss: 1.3422 - val_acc: 0.3733\n",
      "Epoch 12/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3402 - acc: 0.3512 - val_loss: 1.3454 - val_acc: 0.3489\n",
      "Epoch 13/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3425 - acc: 0.3398 - val_loss: 1.3532 - val_acc: 0.3489\n",
      "Epoch 14/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3379 - acc: 0.3512 - val_loss: 1.3359 - val_acc: 0.3652\n",
      "Epoch 15/15\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.3382 - acc: 0.3477 - val_loss: 1.3446 - val_acc: 0.3550\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=15, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n",
      "1041\n",
      "1704\n",
      "1077\n"
     ]
    }
   ],
   "source": [
    "x1=0\n",
    "x2=0\n",
    "x3=0\n",
    "x4=0\n",
    "'ang' 'exc' 'neu' 'sad'\n",
    "for ses_mod in data:\n",
    "    if (ses_mod['emotion'] == 'ang'):\n",
    "        x1+=1\n",
    "    elif (ses_mod['emotion'] == 'exc'):\n",
    "        x2+=1\n",
    "    elif (ses_mod['emotion'] == 'neu'):\n",
    "        x3+=1\n",
    "    else:\n",
    "        x4+=1\n",
    "        \n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print(x4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iemocap_mocap_rot(params=Constants()):\n",
    "    data = []\n",
    "    ids = {}\n",
    "    for session in params.sessions:\n",
    "        path_to_wav = params.path_to_data + session + '/dialog/wav/'\n",
    "        path_to_emotions = params.path_to_data + session + '/dialog/EmoEvaluation/'\n",
    "        path_to_transcriptions = params.path_to_data + session + '/dialog/transcriptions/'\n",
    "        path_to_mocap_rot = params.path_to_data + session + '/dialog/MOCAP_rotated/'\n",
    "\n",
    "        files2 = os.listdir(path_to_wav)\n",
    "        #print (files2.sort())\n",
    "        files = []\n",
    "        for f in files2:\n",
    "            if f.endswith(\".wav\"):\n",
    "                if f[0] == '.':\n",
    "                    files.append(f[2:-4])\n",
    "                else:\n",
    "                    files.append(f[:-4])\n",
    "                    \n",
    "        #files = os.listdir(path_to_wav)\n",
    "        #files = [f[:-4] for f in files if f.endswith(\".wav\")]\n",
    "        for f in files:       \n",
    "            print(f)\n",
    "            if (f== 'Ses05M_script01_1b'):\n",
    "                continue\n",
    "            transcriptions = get_transcriptions(path_to_transcriptions, f + '.txt')\n",
    "            emotions = get_emotions(path_to_emotions, f + '.txt')\n",
    "\n",
    "            for ie, e in enumerate(emotions):\n",
    "                e.pop(\"left\", None)\n",
    "                e.pop(\"right\", None)\n",
    "                e['transcription'] = transcriptions[e['id']]\n",
    "                e['mocap_rot'] = get_mocap_rot(path_to_mocap_rot, f + '.txt', e['start'], e['end'])\n",
    "                if e['emotion'] in params.available_emotions:\n",
    "                    if e['id'] not in ids:\n",
    "                        data.append(e)\n",
    "                        ids[e['id']] = 1\n",
    "\n",
    "                        \n",
    "    sort_key = get_field(data, \"id\")\n",
    "    return np.array(data)[np.argsort(sort_key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_impro02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_script03_2\n",
      "Ses01M_script01_2\n",
      "Ses01F_impro03\n",
      "Ses01F_impro05\n",
      "Ses01M_script02_2\n",
      "Ses01M_impro06\n",
      "Ses01F_script03_2\n",
      "Ses01F_script01_3\n",
      "Ses01M_impro01\n",
      "Ses01M_impro03\n"
     ]
    }
   ],
   "source": [
    "data = read_iemocap_mocap_rot(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'rotate.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2.5,\n",
       " 'd': 2.5,\n",
       " 'emo_evo': [['neu'], ['neu'], ['neu'], ['neu']],\n",
       " 'emotion': 'neu',\n",
       " 'end': 8.2357,\n",
       " 'id': 'Ses01F_impro01_F000',\n",
       " 'mocap_rot': array([[ -28.166955,   33.83828 ,  -54.437235, ...,  -45.552485,\n",
       "           52.78455 ,  129.792845],\n",
       "        [ -28.16234 ,   33.891575,  -54.37245 , ...,  -45.564395,\n",
       "           52.978755,  129.856305],\n",
       "        [ -28.19076 ,   33.97728 ,  -54.39008 , ...,  -45.58896 ,\n",
       "           53.056005,  129.88101 ],\n",
       "        ..., \n",
       "        [ -28.12114 ,   34.79247 ,  -56.04058 , ...,  -45.36128 ,\n",
       "           52.5758  ,  129.79436 ],\n",
       "        [ -28.11692 ,   34.77052 ,  -56.0277  , ...,  -45.34806 ,\n",
       "           52.53871 ,  129.78537 ],\n",
       "        [ -28.0848  ,   34.75438 ,  -56.03502 , ...,  -45.33584 ,\n",
       "           52.48602 ,  129.75684 ]]),\n",
       " 'start': 6.2901,\n",
       " 'transcription': 'Excuse me.',\n",
       " 'v': 2.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 200, 165)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x = ses_mod['mocap_rot']\n",
    "    x[np.isnan(x)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_train2.append( x )\n",
    "    \n",
    "x_train2 = np.array(x_train2)\n",
    "x_train2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -28.32791,   34.75257,  -56.31461, ...,  -45.34444,   52.31502,\n",
       "         129.84094],\n",
       "       [ -28.33381,   34.77408,  -56.32875, ...,  -45.33795,   52.43037,\n",
       "         129.80971],\n",
       "       [ -28.32203,   34.74413,  -56.33002, ...,  -45.35648,   52.33263,\n",
       "         129.83345],\n",
       "       ..., \n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ],\n",
       "       [   0.     ,    0.     ,    0.     , ...,    0.     ,    0.     ,\n",
       "           0.     ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train2.reshape(-1,200,165,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv2D, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution2D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_conv(nb_feat, nb_class, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 165, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 100, 83, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 25, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), padding=\"same\", input_shape=(200, 165,...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_conv(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3929 samples, validate on 983 samples\n",
      "Epoch 1/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.7202 - acc: 0.3199 - val_loss: 1.3724 - val_acc: 0.3815\n",
      "Epoch 2/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3640 - acc: 0.3370 - val_loss: 1.3672 - val_acc: 0.3815\n",
      "Epoch 3/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3515 - acc: 0.3352 - val_loss: 1.3394 - val_acc: 0.3937\n",
      "Epoch 4/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3124 - acc: 0.3635 - val_loss: 1.2267 - val_acc: 0.4924\n",
      "Epoch 5/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2617 - acc: 0.3920 - val_loss: 1.5080 - val_acc: 0.2645\n",
      "Epoch 6/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2457 - acc: 0.4052 - val_loss: 1.2667 - val_acc: 0.5209\n",
      "Epoch 7/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2403 - acc: 0.4009 - val_loss: 1.3404 - val_acc: 0.4893\n",
      "Epoch 8/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2049 - acc: 0.4154 - val_loss: 1.8127 - val_acc: 0.4039\n",
      "Epoch 9/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1965 - acc: 0.4151 - val_loss: 1.4233 - val_acc: 0.4405\n",
      "Epoch 10/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1873 - acc: 0.4215 - val_loss: 1.4601 - val_acc: 0.4924\n",
      "Epoch 11/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1770 - acc: 0.4352 - val_loss: 1.5010 - val_acc: 0.4659\n",
      "Epoch 12/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1636 - acc: 0.4566 - val_loss: 1.5172 - val_acc: 0.4130\n",
      "Epoch 13/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1647 - acc: 0.4513 - val_loss: 1.2783 - val_acc: 0.4283\n",
      "Epoch 14/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1488 - acc: 0.4614 - val_loss: 1.3995 - val_acc: 0.4527\n",
      "Epoch 15/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1167 - acc: 0.4884 - val_loss: 1.4492 - val_acc: 0.4476\n",
      "Epoch 16/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1125 - acc: 0.4991 - val_loss: 1.4735 - val_acc: 0.4191\n",
      "Epoch 17/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0975 - acc: 0.4933 - val_loss: 1.5336 - val_acc: 0.4730\n",
      "Epoch 18/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0877 - acc: 0.5024 - val_loss: 1.5970 - val_acc: 0.4395\n",
      "Epoch 19/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0738 - acc: 0.5103 - val_loss: 1.7700 - val_acc: 0.4364\n",
      "Epoch 20/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0813 - acc: 0.4948 - val_loss: 1.5748 - val_acc: 0.4069\n",
      "Epoch 21/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0613 - acc: 0.5225 - val_loss: 1.8563 - val_acc: 0.4639\n",
      "Epoch 22/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0616 - acc: 0.5213 - val_loss: 1.7629 - val_acc: 0.4008\n",
      "Epoch 23/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0389 - acc: 0.5403 - val_loss: 1.6352 - val_acc: 0.4486\n",
      "Epoch 24/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0548 - acc: 0.5202 - val_loss: 1.6289 - val_acc: 0.4700\n",
      "Epoch 25/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0315 - acc: 0.5492 - val_loss: 1.7230 - val_acc: 0.4395\n",
      "Epoch 26/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0273 - acc: 0.5401 - val_loss: 1.6511 - val_acc: 0.4405\n",
      "Epoch 27/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0068 - acc: 0.5551 - val_loss: 1.7013 - val_acc: 0.4395\n",
      "Epoch 28/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 0.9965 - acc: 0.5643 - val_loss: 1.5268 - val_acc: 0.4730\n",
      "Epoch 29/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.0089 - acc: 0.5462 - val_loss: 1.7868 - val_acc: 0.4629\n",
      "Epoch 30/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 0.9873 - acc: 0.5635 - val_loss: 1.6644 - val_acc: 0.4334\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_conv(nb_feat, nb_class, optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 165, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), padding=\"same\", input_shape=(200, 165,...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 100, 83, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 50, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 25, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18304)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              18744320  \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 19,137,348\n",
      "Trainable params: 19,137,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_conv(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3929 samples, validate on 983 samples\n",
      "Epoch 1/30\n",
      "3929/3929 [==============================] - 8s 2ms/step - loss: 12.1091 - acc: 0.2400 - val_loss: 13.6914 - val_acc: 0.1506\n",
      "Epoch 2/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 12.2529 - acc: 0.2398 - val_loss: 13.6832 - val_acc: 0.1506\n",
      "Epoch 3/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 9.0340 - acc: 0.2558 - val_loss: 1.3659 - val_acc: 0.3795\n",
      "Epoch 4/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3770 - acc: 0.3217 - val_loss: 1.3747 - val_acc: 0.2625\n",
      "Epoch 5/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3691 - acc: 0.3215 - val_loss: 1.3524 - val_acc: 0.3754\n",
      "Epoch 6/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3506 - acc: 0.3286 - val_loss: 1.3537 - val_acc: 0.3499\n",
      "Epoch 7/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3310 - acc: 0.3528 - val_loss: 1.3042 - val_acc: 0.3835\n",
      "Epoch 8/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.3117 - acc: 0.3734 - val_loss: 1.2534 - val_acc: 0.3937\n",
      "Epoch 9/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2892 - acc: 0.3813 - val_loss: 1.2987 - val_acc: 0.3927\n",
      "Epoch 10/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2762 - acc: 0.3774 - val_loss: 1.2156 - val_acc: 0.5107\n",
      "Epoch 11/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2557 - acc: 0.3889 - val_loss: 1.2395 - val_acc: 0.4517\n",
      "Epoch 12/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2392 - acc: 0.4065 - val_loss: 1.3930 - val_acc: 0.4425\n",
      "Epoch 13/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2222 - acc: 0.4266 - val_loss: 1.2374 - val_acc: 0.4395\n",
      "Epoch 14/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2168 - acc: 0.4161 - val_loss: 1.2455 - val_acc: 0.3876\n",
      "Epoch 15/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2073 - acc: 0.4268 - val_loss: 1.7257 - val_acc: 0.3856\n",
      "Epoch 16/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1962 - acc: 0.4378 - val_loss: 1.2712 - val_acc: 0.4212\n",
      "Epoch 17/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.2012 - acc: 0.4299 - val_loss: 1.3129 - val_acc: 0.3845\n",
      "Epoch 18/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1888 - acc: 0.4426 - val_loss: 1.3161 - val_acc: 0.3784\n",
      "Epoch 19/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1821 - acc: 0.4403 - val_loss: 1.8570 - val_acc: 0.3316\n",
      "Epoch 20/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1778 - acc: 0.4459 - val_loss: 1.7164 - val_acc: 0.3642\n",
      "Epoch 21/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1617 - acc: 0.4640 - val_loss: 1.6466 - val_acc: 0.3652\n",
      "Epoch 22/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1679 - acc: 0.4492 - val_loss: 1.5656 - val_acc: 0.3601\n",
      "Epoch 23/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1551 - acc: 0.4564 - val_loss: 1.4238 - val_acc: 0.3693\n",
      "Epoch 24/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1495 - acc: 0.4632 - val_loss: 1.4774 - val_acc: 0.3957\n",
      "Epoch 25/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1442 - acc: 0.4726 - val_loss: 1.2710 - val_acc: 0.4415\n",
      "Epoch 26/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1443 - acc: 0.4734 - val_loss: 1.9121 - val_acc: 0.3774\n",
      "Epoch 27/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1274 - acc: 0.4836 - val_loss: 1.6366 - val_acc: 0.3805\n",
      "Epoch 28/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1283 - acc: 0.4775 - val_loss: 2.2697 - val_acc: 0.3306\n",
      "Epoch 29/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1271 - acc: 0.4831 - val_loss: 1.3677 - val_acc: 0.4090\n",
      "Epoch 30/30\n",
      "3929/3929 [==============================] - 7s 2ms/step - loss: 1.1220 - acc: 0.4879 - val_loss: 1.7585 - val_acc: 0.3652\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 200, 165)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x = ses_mod['mocap_rot']\n",
    "    x[np.isnan(x)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_train2.append( x )\n",
    "    \n",
    "x_train2 = np.array(x_train2)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(200, 165)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 200, 512)          1388544   \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 200, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,309,636\n",
      "Trainable params: 2,309,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3929 samples, validate on 983 samples\n",
      "Epoch 1/30\n",
      "3929/3929 [==============================] - 48s 12ms/step - loss: 1.3810 - acc: 0.3230 - val_loss: 1.4957 - val_acc: 0.3011\n",
      "Epoch 2/30\n",
      "3929/3929 [==============================] - 47s 12ms/step - loss: 1.3457 - acc: 0.3469 - val_loss: 1.3447 - val_acc: 0.3571\n",
      "Epoch 3/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.3259 - acc: 0.3584 - val_loss: 1.3362 - val_acc: 0.3001\n",
      "Epoch 4/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.3191 - acc: 0.3678 - val_loss: 1.3040 - val_acc: 0.4385\n",
      "Epoch 5/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.3018 - acc: 0.3719 - val_loss: 1.2553 - val_acc: 0.4537\n",
      "Epoch 6/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2891 - acc: 0.3894 - val_loss: 1.2662 - val_acc: 0.3469\n",
      "Epoch 7/30\n",
      "3929/3929 [==============================] - 47s 12ms/step - loss: 1.2872 - acc: 0.3836 - val_loss: 1.2973 - val_acc: 0.3795\n",
      "Epoch 8/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2629 - acc: 0.4021 - val_loss: 1.2701 - val_acc: 0.4252\n",
      "Epoch 9/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2590 - acc: 0.4047 - val_loss: 1.2343 - val_acc: 0.4415\n",
      "Epoch 10/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2544 - acc: 0.4075 - val_loss: 1.5236 - val_acc: 0.3001\n",
      "Epoch 11/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2374 - acc: 0.4126 - val_loss: 2.0628 - val_acc: 0.2970\n",
      "Epoch 12/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2436 - acc: 0.4144 - val_loss: 1.3600 - val_acc: 0.4049\n",
      "Epoch 13/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2394 - acc: 0.4113 - val_loss: 1.2101 - val_acc: 0.4975\n",
      "Epoch 14/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2120 - acc: 0.4268 - val_loss: 1.2502 - val_acc: 0.4110\n",
      "Epoch 15/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2215 - acc: 0.4337 - val_loss: 1.2361 - val_acc: 0.4242\n",
      "Epoch 16/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2185 - acc: 0.4337 - val_loss: 1.1966 - val_acc: 0.5086\n",
      "Epoch 17/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.2123 - acc: 0.4312 - val_loss: 1.2002 - val_acc: 0.4517\n",
      "Epoch 18/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1959 - acc: 0.4421 - val_loss: 1.3230 - val_acc: 0.3896\n",
      "Epoch 19/30\n",
      "3929/3929 [==============================] - 47s 12ms/step - loss: 1.1934 - acc: 0.4487 - val_loss: 1.2416 - val_acc: 0.3774\n",
      "Epoch 20/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1877 - acc: 0.4505 - val_loss: 1.1671 - val_acc: 0.4832\n",
      "Epoch 21/30\n",
      "3929/3929 [==============================] - 47s 12ms/step - loss: 1.1886 - acc: 0.4464 - val_loss: 1.2545 - val_acc: 0.4425\n",
      "Epoch 22/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1788 - acc: 0.4408 - val_loss: 1.2378 - val_acc: 0.4527\n",
      "Epoch 23/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1892 - acc: 0.4477 - val_loss: 1.2662 - val_acc: 0.3896\n",
      "Epoch 24/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1572 - acc: 0.4614 - val_loss: 1.3206 - val_acc: 0.3744\n",
      "Epoch 25/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1897 - acc: 0.4467 - val_loss: 1.2639 - val_acc: 0.3703\n",
      "Epoch 26/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1805 - acc: 0.4533 - val_loss: 1.2991 - val_acc: 0.3886\n",
      "Epoch 27/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1671 - acc: 0.4637 - val_loss: 1.1649 - val_acc: 0.4883\n",
      "Epoch 28/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1893 - acc: 0.4541 - val_loss: 1.6176 - val_acc: 0.3204\n",
      "Epoch 29/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1754 - acc: 0.4497 - val_loss: 1.4800 - val_acc: 0.3489\n",
      "Epoch 30/30\n",
      "3929/3929 [==============================] - 46s 12ms/step - loss: 1.1583 - acc: 0.4637 - val_loss: 1.2981 - val_acc: 0.3733\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'hear.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 200, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x = ses_mod['mocap_head']\n",
    "    x[np.isnan(x)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_train2.append( x )\n",
    "    \n",
    "x_train2 = np.array(x_train2)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4912, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=False, input_shape=(200, 6)))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 256)               269312    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 302,724\n",
      "Trainable params: 302,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3929 samples, validate on 983 samples\n",
      "Epoch 1/30\n",
      "3929/3929 [==============================] - 20s 5ms/step - loss: 1.3281 - acc: 0.3772 - val_loss: 1.3734 - val_acc: 0.3683\n",
      "Epoch 2/30\n",
      "3929/3929 [==============================] - 19s 5ms/step - loss: 1.2252 - acc: 0.4510 - val_loss: 1.3857 - val_acc: 0.3672\n",
      "Epoch 3/30\n",
      "3929/3929 [==============================] - 19s 5ms/step - loss: 1.1676 - acc: 0.4859 - val_loss: 1.3795 - val_acc: 0.3876\n",
      "Epoch 4/30\n",
      "3929/3929 [==============================] - 18s 5ms/step - loss: 1.1152 - acc: 0.5230 - val_loss: 1.3831 - val_acc: 0.3866\n",
      "Epoch 5/30\n",
      "3929/3929 [==============================] - 19s 5ms/step - loss: 1.0691 - acc: 0.5498 - val_loss: 1.4030 - val_acc: 0.3561\n",
      "Epoch 6/30\n",
      "3929/3929 [==============================] - 19s 5ms/step - loss: 1.0198 - acc: 0.5874 - val_loss: 1.4385 - val_acc: 0.3357\n",
      "Epoch 7/30\n",
      "3929/3929 [==============================] - 20s 5ms/step - loss: 0.9739 - acc: 0.6052 - val_loss: 1.4689 - val_acc: 0.3499\n",
      "Epoch 8/30\n",
      " 384/3929 [=>............................] - ETA: 15s - loss: 0.9119 - acc: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-702d9285ba09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train2, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_avi = params.path_to_data + 'Session1' + '/dialog/MOCAP_hand/Ses01F_impro01.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mocap_hand(path_to_mocap_hand, filename, start,end, params=Constants()):\n",
    "    f = open(path_to_mocap_hand + filename, 'r').read()\n",
    "    f = np.array(f.split('\\n'))\n",
    "    mocap_hand = []\n",
    "    mocap_hand_avg = []\n",
    "    f = f[2:]\n",
    "    counter = 0\n",
    "    for data in f:\n",
    "        counter+=1\n",
    "        data2 = data.split(' ')\n",
    "        if(len(data2)<2):\n",
    "            continue\n",
    "        if(float(data2[1])>start and float(data2[1])<end):\n",
    "            mocap_hand_avg.append(np.array(data2[2:]).astype(np.float))\n",
    "            \n",
    "    mocap_hand_avg = np.array_split(np.array(mocap_hand_avg), 200)\n",
    "    for spl in mocap_hand_avg:\n",
    "        mocap_hand.append(np.mean(spl, axis=0))\n",
    "    return np.array(mocap_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iemocap_mocap_hand(params=Constants()):\n",
    "    data = []\n",
    "    ids = {}\n",
    "    for session in params.sessions:\n",
    "        path_to_wav = params.path_to_data + session + '/dialog/wav/'\n",
    "        path_to_emotions = params.path_to_data + session + '/dialog/EmoEvaluation/'\n",
    "        path_to_transcriptions = params.path_to_data + session + '/dialog/transcriptions/'\n",
    "        path_to_mocap_hand = params.path_to_data + session + '/dialog/MOCAP_hand/'\n",
    "\n",
    "        files2 = os.listdir(path_to_wav)\n",
    "        #print (files2.sort())\n",
    "        files = []\n",
    "        for f in files2:\n",
    "            if f.endswith(\".wav\"):\n",
    "                if f[0] == '.':\n",
    "                    files.append(f[2:-4])\n",
    "                else:\n",
    "                    files.append(f[:-4])\n",
    "                    \n",
    "        #files = os.listdir(path_to_wav)\n",
    "        #files = [f[:-4] for f in files if f.endswith(\".wav\")]\n",
    "        for f in files:       \n",
    "            print(f)\n",
    "            mocap_f = f\n",
    "            if (f== 'Ses05M_script01_1b'):\n",
    "                mocap_f = 'Ses05M_script01_1' \n",
    "            transcriptions = get_transcriptions(path_to_transcriptions, f + '.txt')\n",
    "            emotions = get_emotions(path_to_emotions, f + '.txt')\n",
    "\n",
    "            for ie, e in enumerate(emotions):\n",
    "                e.pop(\"left\", None)\n",
    "                e.pop(\"right\", None)\n",
    "                e['transcription'] = transcriptions[e['id']]\n",
    "                e['mocap_hand'] = get_mocap_hand(path_to_mocap_hand, mocap_f + '.txt', e['start'], e['end'])\n",
    "                if e['emotion'] in params.available_emotions:\n",
    "                    if e['id'] not in ids:\n",
    "                        data.append(e)\n",
    "                        ids[e['id']] = 1\n",
    "\n",
    "                        \n",
    "    sort_key = get_field(data, \"id\")\n",
    "    return np.array(data)[np.argsort(sort_key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_impro02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses01F_script03_2\n",
      "Ses01M_script01_2\n",
      "Ses01F_impro03\n",
      "Ses01F_impro05\n",
      "Ses01M_script02_2\n",
      "Ses01M_impro06\n",
      "Ses01F_script03_2\n",
      "Ses01F_script01_3\n",
      "Ses01M_impro01\n",
      "Ses01M_impro03\n",
      "Ses01M_impro04\n",
      "Ses01F_script01_2\n",
      "Ses01F_script03_1\n",
      "Ses01F_impro07\n",
      "Ses01M_impro02\n",
      "Ses01F_script02_2\n",
      "Ses01F_script01_2\n",
      "Ses01F_script02_2\n",
      "Ses01M_script02_2\n",
      "Ses01M_script01_3\n",
      "Ses01M_script03_2\n",
      "Ses01F_impro01\n",
      "Ses01M_script02_1\n",
      "Ses01F_impro07\n",
      "Ses01M_script02_1\n",
      "Ses01M_impro04\n",
      "Ses01M_script01_2\n",
      "Ses01F_impro01\n",
      "Ses01M_script03_1\n",
      "Ses01M_script01_3\n",
      "Ses01F_impro02\n",
      "Ses01M_impro06\n",
      "Ses01M_impro05\n",
      "Ses01M_script03_2\n",
      "Ses01F_script02_1\n",
      "Ses01M_impro05\n",
      "Ses01F_impro04\n",
      "Ses01F_script01_1\n",
      "Ses01F_impro04\n",
      "Ses01F_impro03\n",
      "Ses01M_script01_1\n",
      "Ses01F_script01_1\n",
      "Ses01M_script01_1\n",
      "Ses01M_impro07\n",
      "Ses01F_script02_1\n",
      "Ses01M_impro02\n",
      "Ses01F_impro05\n",
      "Ses01M_impro03\n",
      "Ses01F_impro06\n",
      "Ses01M_impro07\n",
      "Ses01M_impro01\n",
      "Ses01F_impro06\n",
      "Ses01F_script01_3\n",
      "Ses01F_script03_1\n",
      "Ses01M_script03_1\n",
      "Ses02M_impro07\n",
      "Ses02F_impro07\n",
      "Ses02F_impro04\n",
      "Ses02F_impro02\n",
      "Ses02F_script02_1\n",
      "Ses02M_impro08\n",
      "Ses02M_impro04\n",
      "Ses02M_impro02\n",
      "Ses02F_impro04\n",
      "Ses02F_script03_1\n",
      "Ses02M_script01_2\n",
      "Ses02M_script02_1\n",
      "Ses02M_script02_2\n",
      "Ses02M_script01_2\n",
      "Ses02F_impro02\n",
      "Ses02F_impro01\n",
      "Ses02M_impro03\n",
      "Ses02F_impro08\n",
      "Ses02F_script03_2\n",
      "Ses02M_impro05\n",
      "Ses02M_script01_1\n",
      "Ses02M_impro03\n",
      "Ses02M_script03_1\n",
      "Ses02F_script03_1\n",
      "Ses02M_impro05\n",
      "Ses02F_script01_2\n",
      "Ses02M_impro07\n",
      "Ses02F_script01_3\n",
      "Ses02M_script01_3\n",
      "Ses02F_script02_2\n",
      "Ses02M_impro02\n",
      "Ses02M_impro06\n",
      "Ses02M_script03_1\n",
      "Ses02F_script03_2\n",
      "Ses02F_script01_2\n",
      "Ses02M_impro01\n",
      "Ses02M_script01_1\n",
      "Ses02M_script02_1\n",
      "Ses02F_impro03\n",
      "Ses02F_script01_1\n",
      "Ses02F_impro07\n",
      "Ses02M_script03_2\n",
      "Ses02F_script02_2\n",
      "Ses02F_impro06\n",
      "Ses02M_impro04\n",
      "Ses02M_impro08\n",
      "Ses02M_impro01\n",
      "Ses02F_impro05\n",
      "Ses02M_script03_2\n",
      "Ses02M_script01_3\n",
      "Ses02F_impro01\n",
      "Ses02M_impro06\n",
      "Ses02F_script02_1\n",
      "Ses02F_impro05\n",
      "Ses02F_impro08\n",
      "Ses02F_impro06\n",
      "Ses02F_impro03\n",
      "Ses02F_script01_1\n",
      "Ses02M_script02_2\n",
      "Ses02F_script01_3\n",
      "Ses03F_impro07\n",
      "Ses03F_script03_2\n",
      "Ses03M_impro05a\n",
      "Ses03F_script01_2\n",
      "Ses03M_impro08b\n",
      "Ses03M_impro06\n",
      "Ses03F_script03_1\n",
      "Ses03M_impro01\n",
      "Ses03M_impro07\n",
      "Ses03M_script01_3\n",
      "Ses03M_script01_2\n",
      "Ses03M_impro01\n",
      "Ses03M_impro05b\n",
      "Ses03F_impro08\n",
      "Ses03F_script02_1\n",
      "Ses03F_script03_2\n",
      "Ses03F_script03_1\n",
      "Ses03F_script02_1\n",
      "Ses03M_script01_1\n",
      "Ses03F_impro03\n",
      "Ses03M_script02_1\n",
      "Ses03M_impro06\n",
      "Ses03M_script01_1\n",
      "Ses03M_script03_1\n",
      "Ses03M_impro08a\n",
      "Ses03F_impro02\n",
      "Ses03F_impro08\n",
      "Ses03F_script02_2\n",
      "Ses03M_impro05b\n",
      "Ses03M_script01_2\n",
      "Ses03M_impro02\n",
      "Ses03F_impro02\n",
      "Ses03F_impro07\n",
      "Ses03M_script02_2\n",
      "Ses03F_impro06\n",
      "Ses03M_impro07\n",
      "Ses03M_impro02\n",
      "Ses03F_impro06\n",
      "Ses03F_impro03\n",
      "Ses03M_impro08b\n",
      "Ses03M_script03_1\n",
      "Ses03F_impro04\n",
      "Ses03M_impro04\n",
      "Ses03M_script01_3\n",
      "Ses03M_impro08a\n",
      "Ses03M_script03_2\n",
      "Ses03F_impro01\n",
      "Ses03F_script02_2\n",
      "Ses03M_impro04\n",
      "Ses03M_script02_2\n",
      "Ses03M_impro03\n",
      "Ses03M_script03_2\n",
      "Ses03F_script01_2\n",
      "Ses03F_impro01\n",
      "Ses03F_impro05\n",
      "Ses03F_impro04\n",
      "Ses03F_script01_1\n",
      "Ses03M_script02_1\n",
      "Ses03F_script01_3\n",
      "Ses03F_script01_3\n",
      "Ses03M_impro05a\n",
      "Ses03F_script01_1\n",
      "Ses03F_impro05\n",
      "Ses03M_impro03\n",
      "Ses04M_impro02\n",
      "Ses04M_script03_1\n",
      "Ses04M_impro06\n",
      "Ses04F_script01_2\n",
      "Ses04M_impro04\n",
      "Ses04M_impro03\n",
      "Ses04M_script01_3\n",
      "Ses04F_impro08\n",
      "Ses04M_impro01\n",
      "Ses04M_script01_2\n",
      "Ses04F_script02_2\n",
      "Ses04M_script03_1\n",
      "Ses04M_script01_3\n",
      "Ses04F_impro07\n",
      "Ses04F_script01_1\n",
      "Ses04F_impro06\n",
      "Ses04M_script02_1\n",
      "Ses04F_impro02\n",
      "Ses04F_script01_2\n",
      "Ses04M_script02_2\n",
      "Ses04M_impro02\n",
      "Ses04F_script01_1\n",
      "Ses04F_impro04\n",
      "Ses04M_impro08\n",
      "Ses04F_script03_1\n",
      "Ses04M_impro05\n",
      "Ses04F_script03_1\n",
      "Ses04F_script02_1\n",
      "Ses04M_impro04\n",
      "Ses04M_impro06\n",
      "Ses04F_script03_2\n",
      "Ses04F_impro05\n",
      "Ses04F_script02_2\n",
      "Ses04M_script02_1\n",
      "Ses04M_script01_2\n",
      "Ses04F_script01_3\n",
      "Ses04F_script01_3\n",
      "Ses04F_impro08\n",
      "Ses04M_impro08\n",
      "Ses04M_script03_2\n",
      "Ses04F_impro06\n",
      "Ses04M_script02_2\n",
      "Ses04M_impro03\n",
      "Ses04F_script03_2\n",
      "Ses04M_impro07\n",
      "Ses04F_impro01\n",
      "Ses04F_impro04\n",
      "Ses04F_script02_1\n",
      "Ses04M_impro07\n",
      "Ses04M_impro01\n",
      "Ses04F_impro05\n",
      "Ses04M_impro05\n",
      "Ses04F_impro03\n",
      "Ses04F_impro07\n",
      "Ses04M_script01_1\n",
      "Ses04F_impro03\n",
      "Ses04F_impro01\n",
      "Ses04M_script03_2\n",
      "Ses04F_impro02\n",
      "Ses04M_script01_1\n",
      "Ses05M_script01_2\n",
      "Ses05F_impro04\n",
      "Ses05F_impro04\n",
      "Ses05F_script01_1\n",
      "Ses05M_impro06\n",
      "Ses05M_script03_2\n",
      "Ses05F_script03_2\n",
      "Ses05M_impro03\n",
      "Ses05F_script03_2\n",
      "Ses05M_script03_1\n",
      "Ses05M_impro02\n",
      "Ses05F_impro08\n",
      "Ses05M_impro07\n",
      "Ses05M_script01_3\n",
      "Ses05F_impro07\n",
      "Ses05M_impro08\n",
      "Ses05F_script02_1\n",
      "Ses05M_script03_1\n",
      "Ses05M_impro03\n",
      "Ses05F_impro03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ses05M_impro01\n",
      "Ses05F_impro02\n",
      "Ses05F_impro01\n",
      "Ses05F_impro08\n",
      "Ses05F_script01_3\n",
      "Ses05M_impro04\n",
      "Ses05F_impro06\n",
      "Ses05M_script01_1b\n",
      "Ses05F_impro05\n",
      "Ses05M_script01_1\n",
      "Ses05F_impro03\n",
      "Ses05F_script02_2\n",
      "Ses05M_script01_1\n",
      "Ses05F_script01_1\n",
      "Ses05M_impro06\n",
      "Ses05F_impro05\n",
      "Ses05M_impro04\n",
      "Ses05F_script03_1\n",
      "Ses05M_impro08\n",
      "Ses05M_impro02\n",
      "Ses05M_script01_3\n",
      "Ses05F_script02_1\n",
      "Ses05F_script01_2\n",
      "Ses05M_script01_2\n",
      "Ses05M_script02_1\n",
      "Ses05F_impro07\n",
      "Ses05M_impro07\n",
      "Ses05F_script03_1\n",
      "Ses05F_script01_2\n",
      "Ses05M_script02_1\n",
      "Ses05F_script02_2\n",
      "Ses05M_script02_2\n",
      "Ses05F_impro01\n",
      "Ses05M_script02_2\n",
      "Ses05M_impro01\n",
      "Ses05F_impro06\n",
      "Ses05F_impro02\n",
      "Ses05M_script03_2\n",
      "Ses05F_script01_3\n",
      "Ses05M_impro05\n",
      "Ses05M_impro05\n",
      "Ses05M_script01_1b\n"
     ]
    }
   ],
   "source": [
    "data = read_iemocap_mocap_hand(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'hand.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data:\n",
    "    x = ses_mod['mocap_head']\n",
    "    if(x.shape != (200,18)):\n",
    "        x = np.zeros((200,18))\n",
    "        \n",
    "    x[np.isnan(x)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_train2.append( x )\n",
    "    \n",
    "x_train2 = np.array(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 18)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_feat, nb_class, optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=False, input_shape=(200, 18)))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 256)               281600    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 315,012\n",
      "Trainable params: 315,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/10\n",
      "3948/3948 [==============================] - 21s 5ms/step - loss: 1.3584 - acc: 0.3417 - val_loss: 1.3945 - val_acc: 0.3107\n",
      "Epoch 2/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.3046 - acc: 0.3956 - val_loss: 1.3989 - val_acc: 0.3229\n",
      "Epoch 3/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2893 - acc: 0.4195 - val_loss: 1.4139 - val_acc: 0.3138\n",
      "Epoch 4/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2725 - acc: 0.4387 - val_loss: 1.4213 - val_acc: 0.3229\n",
      "Epoch 5/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2571 - acc: 0.4582 - val_loss: 1.4367 - val_acc: 0.2885\n",
      "Epoch 6/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2431 - acc: 0.4633 - val_loss: 1.4211 - val_acc: 0.2743\n",
      "Epoch 7/10\n",
      "3948/3948 [==============================] - 18s 5ms/step - loss: 1.2377 - acc: 0.4650 - val_loss: 1.4204 - val_acc: 0.3067\n",
      "Epoch 8/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2384 - acc: 0.4714 - val_loss: 1.4463 - val_acc: 0.3036\n",
      "Epoch 9/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2282 - acc: 0.4775 - val_loss: 1.4451 - val_acc: 0.3431\n",
      "Epoch 10/10\n",
      "3948/3948 [==============================] - 19s 5ms/step - loss: 1.2287 - acc: 0.4716 - val_loss: 1.4877 - val_acc: 0.2976\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=10, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
