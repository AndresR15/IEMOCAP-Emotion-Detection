{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 80\n",
    "\n",
    "optimizer = 'Adadelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /home/samarth/emotion_recognition-master/code/utilities/../../data/ses\n",
      "path_to_features              /home/samarth/emotion_recognition-master/code/utilities/../../data/fea\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <class 'numpy.int8'>, 2: <class 'numpy.int16'>, 4: <class 'numpy.i\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2.5,\n",
       " 'd': 2.5,\n",
       " 'emo_evo': [['neu'], ['neu'], ['neu'], ['neu']],\n",
       " 'emotion': 'neu',\n",
       " 'end': 8.2357,\n",
       " 'id': 'Ses01F_impro01_F000',\n",
       " 'mocap_hand': array([[        nan,         nan,         nan, ...,  -46.42036 ,\n",
       "         -162.607345,  -80.458935],\n",
       "        [        nan,         nan,         nan, ...,  -46.42206 ,\n",
       "         -162.644865,  -80.503155],\n",
       "        [        nan,         nan,         nan, ...,  -46.41771 ,\n",
       "         -162.64734 ,  -80.53003 ],\n",
       "        ..., \n",
       "        [        nan,         nan,         nan, ...,  -46.27356 ,\n",
       "         -162.49055 ,  -79.90838 ],\n",
       "        [        nan,         nan,         nan, ...,  -46.29963 ,\n",
       "         -162.48961 ,  -79.8289  ],\n",
       "        [        nan,         nan,         nan, ...,  -46.28651 ,\n",
       "         -162.55255 ,  -79.82458 ]]),\n",
       " 'mocap_head': array([[ -1.29297700e+01,  -1.35274400e+01,  -1.97916150e+01,\n",
       "          -2.23723750e+01,  -1.35425840e+02,  -3.02012850e+01],\n",
       "        [ -1.29120500e+01,  -1.35292750e+01,  -1.97787800e+01,\n",
       "          -2.23489800e+01,  -1.35347355e+02,  -3.01226100e+01],\n",
       "        [ -1.28972200e+01,  -1.35326750e+01,  -1.98088150e+01,\n",
       "          -2.22805200e+01,  -1.35282850e+02,  -3.00640450e+01],\n",
       "        ..., \n",
       "        [ -2.15942000e+00,  -1.41580000e+01,  -2.72382500e+01,\n",
       "           7.73500000e-02,  -1.22854210e+02,  -3.82914000e+00],\n",
       "        [ -2.16062000e+00,  -1.41573900e+01,  -2.72045700e+01,\n",
       "           2.56000000e-03,  -1.22859770e+02,  -3.83808000e+00],\n",
       "        [ -2.14601000e+00,  -1.41542700e+01,  -2.72353200e+01,\n",
       "          -2.24300000e-02,  -1.22916710e+02,  -3.85828000e+00]]),\n",
       " 'mocap_rot': array([[ -28.166955,   33.83828 ,  -54.437235, ...,  -45.552485,\n",
       "           52.78455 ,  129.792845],\n",
       "        [ -28.16234 ,   33.891575,  -54.37245 , ...,  -45.564395,\n",
       "           52.978755,  129.856305],\n",
       "        [ -28.19076 ,   33.97728 ,  -54.39008 , ...,  -45.58896 ,\n",
       "           53.056005,  129.88101 ],\n",
       "        ..., \n",
       "        [ -28.12114 ,   34.79247 ,  -56.04058 , ...,  -45.36128 ,\n",
       "           52.5758  ,  129.79436 ],\n",
       "        [ -28.11692 ,   34.77052 ,  -56.0277  , ...,  -45.34806 ,\n",
       "           52.53871 ,  129.78537 ],\n",
       "        [ -28.0848  ,   34.75438 ,  -56.03502 , ...,  -45.33584 ,\n",
       "           52.48602 ,  129.75684 ]]),\n",
       " 'signal': array([-165, -163, -125, ..., -104, -137, -146], dtype=int16),\n",
       " 'start': 6.2901,\n",
       " 'transcription': 'Excuse me.',\n",
       " 'v': 2.5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "x_train2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calc_feat.calculate_features(x_head, params.framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=78)\n",
    "    x_train2.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train2 = np.array(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 78, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train2 = x_train2.reshape(-1,78,34)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(78, nb_feat)))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    #model.add(Activation('tanh'))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 78, 512)           1120256   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 78, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,041,348\n",
      "Trainable params: 2,041,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3948/3948 [==============================] - 18s 5ms/step - loss: 1.3680 - acc: 0.3490 - val_loss: 1.3603 - val_acc: 0.3887\n",
      "Epoch 2/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.3523 - acc: 0.3642 - val_loss: 1.3160 - val_acc: 0.4130\n",
      "Epoch 3/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.3483 - acc: 0.3627 - val_loss: 1.3495 - val_acc: 0.3887\n",
      "Epoch 4/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.3200 - acc: 0.3815 - val_loss: 1.2090 - val_acc: 0.4585\n",
      "Epoch 5/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.2535 - acc: 0.4060 - val_loss: 1.2801 - val_acc: 0.4130\n",
      "Epoch 6/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.2205 - acc: 0.4258 - val_loss: 1.2153 - val_acc: 0.4211\n",
      "Epoch 7/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1975 - acc: 0.4276 - val_loss: 1.2665 - val_acc: 0.4190\n",
      "Epoch 8/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1806 - acc: 0.4162 - val_loss: 1.1562 - val_acc: 0.4534\n",
      "Epoch 9/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1634 - acc: 0.4506 - val_loss: 1.1906 - val_acc: 0.4514\n",
      "Epoch 10/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1655 - acc: 0.4359 - val_loss: 1.1632 - val_acc: 0.4575\n",
      "Epoch 11/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1582 - acc: 0.4559 - val_loss: 1.1476 - val_acc: 0.4858\n",
      "Epoch 12/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1417 - acc: 0.4630 - val_loss: 1.1864 - val_acc: 0.4393\n",
      "Epoch 13/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1271 - acc: 0.4650 - val_loss: 1.1646 - val_acc: 0.4474\n",
      "Epoch 14/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1338 - acc: 0.4696 - val_loss: 1.1483 - val_acc: 0.4777\n",
      "Epoch 15/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1204 - acc: 0.4805 - val_loss: 1.3282 - val_acc: 0.3877\n",
      "Epoch 16/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1219 - acc: 0.4772 - val_loss: 1.2242 - val_acc: 0.4069\n",
      "Epoch 17/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1101 - acc: 0.4802 - val_loss: 1.1552 - val_acc: 0.4565\n",
      "Epoch 18/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.1067 - acc: 0.4767 - val_loss: 1.1343 - val_acc: 0.4818\n",
      "Epoch 19/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0905 - acc: 0.4927 - val_loss: 1.1730 - val_acc: 0.4828\n",
      "Epoch 20/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0891 - acc: 0.4914 - val_loss: 1.1230 - val_acc: 0.4939\n",
      "Epoch 21/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0825 - acc: 0.4944 - val_loss: 1.2580 - val_acc: 0.4575\n",
      "Epoch 22/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0908 - acc: 0.4904 - val_loss: 1.1801 - val_acc: 0.4757\n",
      "Epoch 23/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0813 - acc: 0.4911 - val_loss: 1.1436 - val_acc: 0.4939\n",
      "Epoch 24/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0578 - acc: 0.5073 - val_loss: 1.1472 - val_acc: 0.4879\n",
      "Epoch 25/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0593 - acc: 0.5170 - val_loss: 1.1706 - val_acc: 0.4838\n",
      "Epoch 26/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0487 - acc: 0.5119 - val_loss: 1.2060 - val_acc: 0.4433\n",
      "Epoch 27/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0496 - acc: 0.5099 - val_loss: 1.1644 - val_acc: 0.4868\n",
      "Epoch 28/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0376 - acc: 0.5268 - val_loss: 1.3695 - val_acc: 0.3877\n",
      "Epoch 29/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0358 - acc: 0.5241 - val_loss: 1.1322 - val_acc: 0.4879\n",
      "Epoch 30/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0299 - acc: 0.5266 - val_loss: 1.1505 - val_acc: 0.4990\n",
      "Epoch 31/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0152 - acc: 0.5360 - val_loss: 1.2186 - val_acc: 0.4848\n",
      "Epoch 32/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0129 - acc: 0.5294 - val_loss: 1.1009 - val_acc: 0.5061\n",
      "Epoch 33/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 1.0075 - acc: 0.5306 - val_loss: 1.2282 - val_acc: 0.4696\n",
      "Epoch 34/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9968 - acc: 0.5433 - val_loss: 1.4185 - val_acc: 0.4170\n",
      "Epoch 35/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9893 - acc: 0.5557 - val_loss: 1.1938 - val_acc: 0.4818\n",
      "Epoch 36/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9928 - acc: 0.5517 - val_loss: 1.2139 - val_acc: 0.4524\n",
      "Epoch 37/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9779 - acc: 0.5572 - val_loss: 1.1386 - val_acc: 0.4990\n",
      "Epoch 38/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9705 - acc: 0.5545 - val_loss: 1.1779 - val_acc: 0.5091\n",
      "Epoch 39/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9561 - acc: 0.5780 - val_loss: 1.1934 - val_acc: 0.4929\n",
      "Epoch 40/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9560 - acc: 0.5659 - val_loss: 1.1626 - val_acc: 0.4868\n",
      "Epoch 41/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9529 - acc: 0.5735 - val_loss: 1.1948 - val_acc: 0.4828\n",
      "Epoch 42/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9381 - acc: 0.5816 - val_loss: 1.1858 - val_acc: 0.5071\n",
      "Epoch 43/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9333 - acc: 0.5881 - val_loss: 1.1108 - val_acc: 0.5162\n",
      "Epoch 44/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9101 - acc: 0.5952 - val_loss: 1.1466 - val_acc: 0.4970\n",
      "Epoch 45/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9081 - acc: 0.6001 - val_loss: 1.2005 - val_acc: 0.4990\n",
      "Epoch 46/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.9033 - acc: 0.6054 - val_loss: 1.2874 - val_acc: 0.5000\n",
      "Epoch 47/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8778 - acc: 0.6201 - val_loss: 1.1955 - val_acc: 0.4848\n",
      "Epoch 48/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8770 - acc: 0.6071 - val_loss: 1.1831 - val_acc: 0.5152\n",
      "Epoch 49/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8529 - acc: 0.6312 - val_loss: 1.3834 - val_acc: 0.4585\n",
      "Epoch 50/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8446 - acc: 0.6358 - val_loss: 1.2848 - val_acc: 0.4868\n",
      "Epoch 51/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8353 - acc: 0.6345 - val_loss: 1.2685 - val_acc: 0.4949\n",
      "Epoch 52/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8265 - acc: 0.6322 - val_loss: 1.2342 - val_acc: 0.5020\n",
      "Epoch 53/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.8017 - acc: 0.6555 - val_loss: 1.2090 - val_acc: 0.5162\n",
      "Epoch 54/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7921 - acc: 0.6626 - val_loss: 1.2917 - val_acc: 0.5091\n",
      "Epoch 55/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7891 - acc: 0.6606 - val_loss: 1.4098 - val_acc: 0.4666\n",
      "Epoch 56/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7716 - acc: 0.6657 - val_loss: 1.3136 - val_acc: 0.5091\n",
      "Epoch 57/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7644 - acc: 0.6657 - val_loss: 1.4095 - val_acc: 0.4858\n",
      "Epoch 58/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7234 - acc: 0.6978 - val_loss: 1.4659 - val_acc: 0.4626\n",
      "Epoch 59/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7215 - acc: 0.6930 - val_loss: 1.4404 - val_acc: 0.4757\n",
      "Epoch 60/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.7035 - acc: 0.7014 - val_loss: 1.3669 - val_acc: 0.4879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6951 - acc: 0.7042 - val_loss: 1.4149 - val_acc: 0.4889\n",
      "Epoch 62/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6676 - acc: 0.7092 - val_loss: 1.4754 - val_acc: 0.4899\n",
      "Epoch 63/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6406 - acc: 0.7307 - val_loss: 1.4893 - val_acc: 0.5091\n",
      "Epoch 64/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6287 - acc: 0.7325 - val_loss: 1.5491 - val_acc: 0.5121\n",
      "Epoch 65/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6143 - acc: 0.7414 - val_loss: 1.7757 - val_acc: 0.4949\n",
      "Epoch 66/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.6086 - acc: 0.7444 - val_loss: 1.6182 - val_acc: 0.4787\n",
      "Epoch 67/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.5877 - acc: 0.7556 - val_loss: 1.5716 - val_acc: 0.5010\n",
      "Epoch 68/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.5767 - acc: 0.7604 - val_loss: 1.6911 - val_acc: 0.4696\n",
      "Epoch 69/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.5689 - acc: 0.7619 - val_loss: 1.7423 - val_acc: 0.4777\n",
      "Epoch 70/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.5481 - acc: 0.7708 - val_loss: 1.6515 - val_acc: 0.5152\n",
      "Epoch 71/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.5091 - acc: 0.7905 - val_loss: 1.7611 - val_acc: 0.4960\n",
      "Epoch 72/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4885 - acc: 0.7918 - val_loss: 1.7983 - val_acc: 0.4990\n",
      "Epoch 73/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4818 - acc: 0.7933 - val_loss: 1.8321 - val_acc: 0.4787\n",
      "Epoch 74/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4548 - acc: 0.8070 - val_loss: 1.9953 - val_acc: 0.4929\n",
      "Epoch 75/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4777 - acc: 0.7953 - val_loss: 1.8130 - val_acc: 0.4909\n",
      "Epoch 76/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4371 - acc: 0.8189 - val_loss: 2.1169 - val_acc: 0.4737\n",
      "Epoch 77/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4217 - acc: 0.8202 - val_loss: 2.0439 - val_acc: 0.4646\n",
      "Epoch 78/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4039 - acc: 0.8326 - val_loss: 2.0664 - val_acc: 0.4939\n",
      "Epoch 79/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.4108 - acc: 0.8333 - val_loss: 2.0589 - val_acc: 0.4980\n",
      "Epoch 80/80\n",
      "3948/3948 [==============================] - 18s 4ms/step - loss: 0.3647 - acc: 0.8445 - val_loss: 2.2454 - val_acc: 0.4453\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import stFeatureExtraction\n",
    "\n",
    "    \n",
    "def calculate_features2(frames, freq, options):\n",
    "    window_sec = 0.02\n",
    "    window_n = int(freq * window_sec)\n",
    "    use_derivatives = False\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "    #print (st_f.shape)\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        if use_derivatives:\n",
    "            deriv_st_f = np.zeros((st_f.shape[0]*3, i1 - i0), dtype=float)\n",
    "        else:\n",
    "            deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "            if use_derivatives:\n",
    "                if st_f.shape[1] >= 2:\n",
    "                    deriv_st_f[st_f.shape[0]:st_f.shape[0]*2, i - i0] = (st_f[:, i_right] - st_f[:, i_left]) / 2.\n",
    "                    deriv_st_f[st_f.shape[0]*2:st_f.shape[0]*3, i - i0] = \\\n",
    "                        st_f[:, i] - 0.5*(st_f[:, i_left] + st_f[:, i_right])\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        if use_derivatives:\n",
    "            deriv_st_f[st_f.shape[0]:st_f.shape[0]*2, 0] = st_f[:, 1] - st_f[:, 0]\n",
    "            deriv_st_f[st_f.shape[0]*2:st_f.shape[0]*3, 0] = np.zeros(st_f.shape[0])\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        if use_derivatives:\n",
    "            deriv_st_f[st_f.shape[0]:st_f.shape[0]*2, 0] = np.zeros(st_f.shape[0])\n",
    "            deriv_st_f[st_f.shape[0]*2:st_f.shape[0]*3, 0] = np.zeros(st_f.shape[0])\n",
    "        return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 10, 34, 50)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sig2 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_sig = ses_mod['signal']\n",
    "    sig_avg = np.array_split(np.array(x_sig), 10)\n",
    "    sig_feat = []\n",
    "    for spl in sig_avg:\n",
    "        #print(spl.shape)\n",
    "        #print (x_sig.shape)\n",
    "        st_features = calculate_features2(spl, params.framerate, None)\n",
    "        st_features, _ = pad_sequence_into_array(st_features, maxlen=50)\n",
    "        sig_feat.append( st_features ) \n",
    "    #st_features = calc_feat.calculate_features(x_sig, params.framerate, None)\n",
    "    #st_features, _ = pad_sequence_into_array(st_features, maxlen=78)\n",
    "    #x_train2.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    x_train_sig2.append(np.array(sig_feat))\n",
    "    #break\n",
    "    \n",
    "x_train_sig2 = np.array(x_train_sig2)\n",
    "x_train_sig2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 50, 340)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train3 = x_train2.reshape(-1,50,340)\n",
    "x_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm2(nb_feat, nb_class, optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(50,340)))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 50, 512)           1746944   \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,668,036\n",
      "Trainable params: 2,668,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm2(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3948/3948 [==============================] - 14s 3ms/step - loss: 1.3609 - acc: 0.3341 - val_loss: 1.3501 - val_acc: 0.3684\n",
      "Epoch 2/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3502 - acc: 0.3485 - val_loss: 1.3456 - val_acc: 0.3745\n",
      "Epoch 3/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3461 - acc: 0.3503 - val_loss: 1.3467 - val_acc: 0.3887\n",
      "Epoch 4/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3426 - acc: 0.3536 - val_loss: 1.3462 - val_acc: 0.3704\n",
      "Epoch 5/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3407 - acc: 0.3620 - val_loss: 1.3484 - val_acc: 0.3856\n",
      "Epoch 6/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3368 - acc: 0.3655 - val_loss: 1.3463 - val_acc: 0.3745\n",
      "Epoch 7/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3341 - acc: 0.3658 - val_loss: 1.3400 - val_acc: 0.3897\n",
      "Epoch 8/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3304 - acc: 0.3703 - val_loss: 1.3374 - val_acc: 0.3765\n",
      "Epoch 9/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3270 - acc: 0.3731 - val_loss: 1.3371 - val_acc: 0.3978\n",
      "Epoch 10/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3225 - acc: 0.3802 - val_loss: 1.3338 - val_acc: 0.3937\n",
      "Epoch 11/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3189 - acc: 0.3774 - val_loss: 1.3300 - val_acc: 0.4018\n",
      "Epoch 12/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3136 - acc: 0.3855 - val_loss: 1.3295 - val_acc: 0.4059\n",
      "Epoch 13/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3062 - acc: 0.3868 - val_loss: 1.3258 - val_acc: 0.3957\n",
      "Epoch 14/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3012 - acc: 0.3893 - val_loss: 1.3239 - val_acc: 0.3866\n",
      "Epoch 15/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2948 - acc: 0.3929 - val_loss: 1.3134 - val_acc: 0.3968\n",
      "Epoch 16/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2831 - acc: 0.3949 - val_loss: 1.2852 - val_acc: 0.4383\n",
      "Epoch 17/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2678 - acc: 0.4111 - val_loss: 1.2822 - val_acc: 0.4130\n",
      "Epoch 18/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2668 - acc: 0.4055 - val_loss: 1.3732 - val_acc: 0.3381\n",
      "Epoch 19/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2637 - acc: 0.4015 - val_loss: 1.2681 - val_acc: 0.4190\n",
      "Epoch 20/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2412 - acc: 0.4131 - val_loss: 1.2428 - val_acc: 0.4322\n",
      "Epoch 21/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2366 - acc: 0.4222 - val_loss: 1.3738 - val_acc: 0.3836\n",
      "Epoch 22/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2437 - acc: 0.4263 - val_loss: 1.2912 - val_acc: 0.3887\n",
      "Epoch 23/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2384 - acc: 0.4248 - val_loss: 1.2514 - val_acc: 0.4342\n",
      "Epoch 24/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2208 - acc: 0.4291 - val_loss: 1.2939 - val_acc: 0.3846\n",
      "Epoch 25/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2092 - acc: 0.4369 - val_loss: 1.3174 - val_acc: 0.3745\n",
      "Epoch 26/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2064 - acc: 0.4382 - val_loss: 1.3188 - val_acc: 0.3806\n",
      "Epoch 27/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2133 - acc: 0.4329 - val_loss: 1.2957 - val_acc: 0.3947\n",
      "Epoch 28/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2011 - acc: 0.4268 - val_loss: 1.2641 - val_acc: 0.4089\n",
      "Epoch 29/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2006 - acc: 0.4400 - val_loss: 1.2472 - val_acc: 0.4443\n",
      "Epoch 30/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1884 - acc: 0.4435 - val_loss: 1.2211 - val_acc: 0.4534\n",
      "Epoch 31/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2037 - acc: 0.4336 - val_loss: 1.2599 - val_acc: 0.4211\n",
      "Epoch 32/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1846 - acc: 0.4466 - val_loss: 1.2300 - val_acc: 0.4443\n",
      "Epoch 33/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1767 - acc: 0.4420 - val_loss: 1.2567 - val_acc: 0.4332\n",
      "Epoch 34/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1761 - acc: 0.4478 - val_loss: 1.1983 - val_acc: 0.4565\n",
      "Epoch 35/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1863 - acc: 0.4415 - val_loss: 1.3214 - val_acc: 0.3775\n",
      "Epoch 36/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1840 - acc: 0.4357 - val_loss: 1.2110 - val_acc: 0.4484\n",
      "Epoch 37/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1723 - acc: 0.4506 - val_loss: 1.3270 - val_acc: 0.3897\n",
      "Epoch 38/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1770 - acc: 0.4559 - val_loss: 1.2168 - val_acc: 0.4393\n",
      "Epoch 39/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1715 - acc: 0.4640 - val_loss: 1.1959 - val_acc: 0.4686\n",
      "Epoch 40/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1651 - acc: 0.4618 - val_loss: 1.1974 - val_acc: 0.4453\n",
      "Epoch 41/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1649 - acc: 0.4511 - val_loss: 1.1885 - val_acc: 0.4565\n",
      "Epoch 42/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1618 - acc: 0.4668 - val_loss: 1.2115 - val_acc: 0.4160\n",
      "Epoch 43/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1711 - acc: 0.4511 - val_loss: 1.2030 - val_acc: 0.4362\n",
      "Epoch 44/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1679 - acc: 0.4643 - val_loss: 1.2527 - val_acc: 0.4059\n",
      "Epoch 45/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1602 - acc: 0.4661 - val_loss: 1.2435 - val_acc: 0.4130\n",
      "Epoch 46/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1606 - acc: 0.4701 - val_loss: 1.1835 - val_acc: 0.4565\n",
      "Epoch 47/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1585 - acc: 0.4704 - val_loss: 1.2351 - val_acc: 0.4372\n",
      "Epoch 48/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1520 - acc: 0.4661 - val_loss: 1.1793 - val_acc: 0.4545\n",
      "Epoch 49/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1550 - acc: 0.4612 - val_loss: 1.2592 - val_acc: 0.3866\n",
      "Epoch 50/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1459 - acc: 0.4635 - val_loss: 1.2676 - val_acc: 0.4170\n",
      "Epoch 51/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1539 - acc: 0.4734 - val_loss: 1.2055 - val_acc: 0.4545\n",
      "Epoch 52/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1514 - acc: 0.4625 - val_loss: 1.2145 - val_acc: 0.4160\n",
      "Epoch 53/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1583 - acc: 0.4709 - val_loss: 1.2495 - val_acc: 0.4190\n",
      "Epoch 54/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1469 - acc: 0.4747 - val_loss: 1.2520 - val_acc: 0.4271\n",
      "Epoch 55/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1405 - acc: 0.4749 - val_loss: 1.2004 - val_acc: 0.4545\n",
      "Epoch 56/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1512 - acc: 0.4711 - val_loss: 1.2010 - val_acc: 0.4322\n",
      "Epoch 57/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1424 - acc: 0.4739 - val_loss: 1.3371 - val_acc: 0.3846\n",
      "Epoch 58/80\n",
      "1216/3948 [========>.....................] - ETA: 7s - loss: 1.1319 - acc: 0.4836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-fc4067e04c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train3, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train3, Y, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv2D, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution2D, GRU, MaxPooling1D\n",
    "\n",
    "\n",
    "def build_simple_lstm3(nb_feat, nb_class, optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(50,340)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(512)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_16 (LSTM)               (None, 50, 512)           1746944   \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,668,036\n",
      "Trainable params: 2,668,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm2(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3948/3948 [==============================] - 14s 4ms/step - loss: 1.3621 - acc: 0.3338 - val_loss: 1.3588 - val_acc: 0.3796\n",
      "Epoch 2/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3503 - acc: 0.3523 - val_loss: 1.3544 - val_acc: 0.3735\n",
      "Epoch 3/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3457 - acc: 0.3539 - val_loss: 1.3456 - val_acc: 0.3725\n",
      "Epoch 4/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3412 - acc: 0.3627 - val_loss: 1.3421 - val_acc: 0.3937\n",
      "Epoch 5/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3372 - acc: 0.3683 - val_loss: 1.3368 - val_acc: 0.3785\n",
      "Epoch 6/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3333 - acc: 0.3685 - val_loss: 1.3458 - val_acc: 0.3968\n",
      "Epoch 7/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3279 - acc: 0.3678 - val_loss: 1.3373 - val_acc: 0.3745\n",
      "Epoch 8/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3247 - acc: 0.3749 - val_loss: 1.3234 - val_acc: 0.3775\n",
      "Epoch 9/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3183 - acc: 0.3741 - val_loss: 1.3257 - val_acc: 0.4150\n",
      "Epoch 10/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3158 - acc: 0.3706 - val_loss: 1.3301 - val_acc: 0.4150\n",
      "Epoch 11/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.3037 - acc: 0.3883 - val_loss: 1.3242 - val_acc: 0.3765\n",
      "Epoch 12/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2956 - acc: 0.3901 - val_loss: 1.3410 - val_acc: 0.3704\n",
      "Epoch 13/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2873 - acc: 0.3969 - val_loss: 1.3173 - val_acc: 0.3826\n",
      "Epoch 14/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2777 - acc: 0.4015 - val_loss: 1.2810 - val_acc: 0.4251\n",
      "Epoch 15/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2628 - acc: 0.4093 - val_loss: 1.2438 - val_acc: 0.4474\n",
      "Epoch 16/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2531 - acc: 0.4103 - val_loss: 1.2966 - val_acc: 0.3816\n",
      "Epoch 17/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2546 - acc: 0.4113 - val_loss: 1.2443 - val_acc: 0.4352\n",
      "Epoch 18/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2361 - acc: 0.4182 - val_loss: 1.2537 - val_acc: 0.4332\n",
      "Epoch 19/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2367 - acc: 0.4197 - val_loss: 1.2154 - val_acc: 0.4575\n",
      "Epoch 20/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2351 - acc: 0.4207 - val_loss: 1.2224 - val_acc: 0.4403\n",
      "Epoch 21/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2194 - acc: 0.4319 - val_loss: 1.2424 - val_acc: 0.4332\n",
      "Epoch 22/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2171 - acc: 0.4402 - val_loss: 1.2497 - val_acc: 0.4352\n",
      "Epoch 23/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2191 - acc: 0.4314 - val_loss: 1.3543 - val_acc: 0.3603\n",
      "Epoch 24/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2068 - acc: 0.4374 - val_loss: 1.3480 - val_acc: 0.3694\n",
      "Epoch 25/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2029 - acc: 0.4336 - val_loss: 1.3067 - val_acc: 0.3998\n",
      "Epoch 26/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.2028 - acc: 0.4263 - val_loss: 1.2164 - val_acc: 0.4696\n",
      "Epoch 27/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1987 - acc: 0.4390 - val_loss: 1.2072 - val_acc: 0.4605\n",
      "Epoch 28/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1902 - acc: 0.4379 - val_loss: 1.2478 - val_acc: 0.4251\n",
      "Epoch 29/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1944 - acc: 0.4433 - val_loss: 1.2312 - val_acc: 0.4332\n",
      "Epoch 30/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1782 - acc: 0.4615 - val_loss: 1.2298 - val_acc: 0.4200\n",
      "Epoch 31/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1896 - acc: 0.4488 - val_loss: 1.3210 - val_acc: 0.3806\n",
      "Epoch 32/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1814 - acc: 0.4539 - val_loss: 1.2029 - val_acc: 0.4393\n",
      "Epoch 33/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1769 - acc: 0.4577 - val_loss: 1.1855 - val_acc: 0.4605\n",
      "Epoch 34/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1775 - acc: 0.4536 - val_loss: 1.2458 - val_acc: 0.4038\n",
      "Epoch 35/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1797 - acc: 0.4526 - val_loss: 1.1963 - val_acc: 0.4595\n",
      "Epoch 36/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1679 - acc: 0.4559 - val_loss: 1.3608 - val_acc: 0.3745\n",
      "Epoch 37/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1706 - acc: 0.4552 - val_loss: 1.2111 - val_acc: 0.4423\n",
      "Epoch 38/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1667 - acc: 0.4534 - val_loss: 1.1801 - val_acc: 0.4585\n",
      "Epoch 39/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1769 - acc: 0.4531 - val_loss: 1.2488 - val_acc: 0.4413\n",
      "Epoch 40/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1544 - acc: 0.4732 - val_loss: 1.3175 - val_acc: 0.4038\n",
      "Epoch 41/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1663 - acc: 0.4554 - val_loss: 1.2189 - val_acc: 0.4524\n",
      "Epoch 42/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1519 - acc: 0.4650 - val_loss: 1.2078 - val_acc: 0.4595\n",
      "Epoch 43/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1597 - acc: 0.4663 - val_loss: 1.1916 - val_acc: 0.4453\n",
      "Epoch 44/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1638 - acc: 0.4676 - val_loss: 1.1859 - val_acc: 0.4636\n",
      "Epoch 45/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1569 - acc: 0.4678 - val_loss: 1.2201 - val_acc: 0.4595\n",
      "Epoch 46/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1621 - acc: 0.4572 - val_loss: 1.2178 - val_acc: 0.4545\n",
      "Epoch 47/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1503 - acc: 0.4699 - val_loss: 1.2323 - val_acc: 0.4160\n",
      "Epoch 48/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1526 - acc: 0.4737 - val_loss: 1.1773 - val_acc: 0.4686\n",
      "Epoch 49/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1460 - acc: 0.4721 - val_loss: 1.1753 - val_acc: 0.4696\n",
      "Epoch 50/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1510 - acc: 0.4605 - val_loss: 1.2063 - val_acc: 0.4605\n",
      "Epoch 51/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1504 - acc: 0.4810 - val_loss: 1.1716 - val_acc: 0.4605\n",
      "Epoch 52/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1431 - acc: 0.4691 - val_loss: 1.2196 - val_acc: 0.4514\n",
      "Epoch 53/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1402 - acc: 0.4757 - val_loss: 1.2354 - val_acc: 0.4180\n",
      "Epoch 54/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1392 - acc: 0.4840 - val_loss: 1.1925 - val_acc: 0.4534\n",
      "Epoch 55/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1304 - acc: 0.4800 - val_loss: 1.2393 - val_acc: 0.4231\n",
      "Epoch 56/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1401 - acc: 0.4737 - val_loss: 1.2770 - val_acc: 0.4200\n",
      "Epoch 57/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1318 - acc: 0.4820 - val_loss: 1.2199 - val_acc: 0.4342\n",
      "Epoch 58/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1315 - acc: 0.4767 - val_loss: 1.2332 - val_acc: 0.4261\n",
      "Epoch 59/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1239 - acc: 0.4813 - val_loss: 1.2012 - val_acc: 0.4636\n",
      "Epoch 60/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1332 - acc: 0.4780 - val_loss: 1.2128 - val_acc: 0.4342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1247 - acc: 0.4899 - val_loss: 1.2518 - val_acc: 0.4211\n",
      "Epoch 62/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1393 - acc: 0.4868 - val_loss: 1.2819 - val_acc: 0.4332\n",
      "Epoch 63/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1279 - acc: 0.4785 - val_loss: 1.2472 - val_acc: 0.4352\n",
      "Epoch 64/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1347 - acc: 0.4739 - val_loss: 1.1984 - val_acc: 0.4595\n",
      "Epoch 65/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1237 - acc: 0.4833 - val_loss: 1.1776 - val_acc: 0.4666\n",
      "Epoch 66/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1244 - acc: 0.4830 - val_loss: 1.2235 - val_acc: 0.4332\n",
      "Epoch 67/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1173 - acc: 0.4894 - val_loss: 1.2429 - val_acc: 0.4150\n",
      "Epoch 68/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1067 - acc: 0.5003 - val_loss: 1.2643 - val_acc: 0.4241\n",
      "Epoch 69/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1235 - acc: 0.4848 - val_loss: 1.2088 - val_acc: 0.4524\n",
      "Epoch 70/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1180 - acc: 0.4886 - val_loss: 1.2053 - val_acc: 0.4494\n",
      "Epoch 71/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1121 - acc: 0.4899 - val_loss: 1.3065 - val_acc: 0.4281\n",
      "Epoch 72/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1157 - acc: 0.4932 - val_loss: 1.2405 - val_acc: 0.4595\n",
      "Epoch 73/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1254 - acc: 0.4851 - val_loss: 1.1766 - val_acc: 0.4565\n",
      "Epoch 74/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1025 - acc: 0.4985 - val_loss: 1.2185 - val_acc: 0.4383\n",
      "Epoch 75/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1091 - acc: 0.5003 - val_loss: 1.2450 - val_acc: 0.4211\n",
      "Epoch 76/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1036 - acc: 0.5030 - val_loss: 1.1816 - val_acc: 0.4565\n",
      "Epoch 77/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.0943 - acc: 0.5061 - val_loss: 1.2824 - val_acc: 0.4221\n",
      "Epoch 78/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.1041 - acc: 0.4919 - val_loss: 1.4029 - val_acc: 0.3796\n",
      "Epoch 79/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.0934 - acc: 0.5058 - val_loss: 1.5027 - val_acc: 0.3381\n",
      "Epoch 80/80\n",
      "3948/3948 [==============================] - 12s 3ms/step - loss: 1.0981 - acc: 0.4992 - val_loss: 1.1697 - val_acc: 0.4777\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train3, Y, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 400, 34)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train4 = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calculate_features2(x_head, params.framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=400)\n",
    "    x_train4.append( st_features )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    #break\n",
    "    \n",
    "x_train4 = np.array(x_train4)\n",
    "x_train4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train5 = x_train4.reshape(-1,34,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm3(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(34,400)))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(512)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_class))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_44 (LSTM)               (None, 34, 512)           1869824   \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 34, 256)           787456    \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 34, 512)           131584    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 17408)             0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               4456704   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,246,596\n",
      "Trainable params: 7,246,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_lstm3(nb_feat, nb_class)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 1.3787 - acc: 0.3278 - val_loss: 1.3441 - val_acc: 0.3117\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.3199 - acc: 0.3678 - val_loss: 1.2145 - val_acc: 0.4069\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.2445 - acc: 0.4159 - val_loss: 1.1953 - val_acc: 0.4575\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.1836 - acc: 0.4481 - val_loss: 1.2331 - val_acc: 0.3725\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.1585 - acc: 0.4688 - val_loss: 1.2312 - val_acc: 0.4423\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.1202 - acc: 0.4699 - val_loss: 1.3524 - val_acc: 0.3755\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.1161 - acc: 0.4818 - val_loss: 1.1818 - val_acc: 0.4443\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.0802 - acc: 0.5063 - val_loss: 1.2228 - val_acc: 0.4322\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.0550 - acc: 0.5243 - val_loss: 1.2502 - val_acc: 0.4514\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 1.0388 - acc: 0.5352 - val_loss: 1.1802 - val_acc: 0.4646\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.9983 - acc: 0.5514 - val_loss: 1.2079 - val_acc: 0.4828\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.9592 - acc: 0.5679 - val_loss: 1.2319 - val_acc: 0.4514\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.9221 - acc: 0.5899 - val_loss: 1.2086 - val_acc: 0.4514\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.9039 - acc: 0.6006 - val_loss: 1.2730 - val_acc: 0.4312\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.8590 - acc: 0.6264 - val_loss: 1.4240 - val_acc: 0.4372\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.8114 - acc: 0.6543 - val_loss: 1.3791 - val_acc: 0.4423\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.7753 - acc: 0.6669 - val_loss: 1.4390 - val_acc: 0.4362\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 10s 2ms/step - loss: 0.7052 - acc: 0.7057 - val_loss: 1.4310 - val_acc: 0.4605\n",
      "Epoch 19/30\n",
      " 384/3948 [=>............................] - ETA: 7s - loss: 0.5486 - acc: 0.7708"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-e55c768e37d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train5, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train5, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "\n",
    "for ses_mod in data2:\n",
    "    text.append(ses_mod['transcription'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(text)\n",
    "x_train_text = []\n",
    "\n",
    "x_train_text = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2736 unique tokens\n",
      "/home/samarth/emotion_recognition-master/code/utilities/../../data/sessions/../glove.42B.300d.txt\n",
      "G Word embeddings: 1917494\n",
      "G Null word embeddings: 90\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = params.path_to_data + '../glove.42B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,514,448\n",
      "Trainable params: 7,514,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:33: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(LSTM(512, return_sequences=True, input_shape=(78, nb_feat)))\n",
    "\n",
    "model_speech.add(LSTM(256, return_sequences=False))\n",
    "\n",
    "model_speech.add(Dense(512))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adadelta' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 33s 8ms/step - loss: 1.3603 - acc: 0.3490 - val_loss: 1.3286 - val_acc: 0.3897\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 1.3350 - acc: 0.3680 - val_loss: 1.3343 - val_acc: 0.3877\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 1.2788 - acc: 0.3967 - val_loss: 1.1852 - val_acc: 0.4960\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 1.1708 - acc: 0.4742 - val_loss: 1.0295 - val_acc: 0.5891\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 1.0439 - acc: 0.5491 - val_loss: 0.9774 - val_acc: 0.6093\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.8913 - acc: 0.6345 - val_loss: 1.0757 - val_acc: 0.5719\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.7926 - acc: 0.6849 - val_loss: 0.9587 - val_acc: 0.6103\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.6760 - acc: 0.7340 - val_loss: 0.9288 - val_acc: 0.6589\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.5469 - acc: 0.7888 - val_loss: 0.9193 - val_acc: 0.6721\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.5031 - acc: 0.8002 - val_loss: 0.9914 - val_acc: 0.6650\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.4200 - acc: 0.8387 - val_loss: 1.2043 - val_acc: 0.6285\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.3849 - acc: 0.8521 - val_loss: 1.1551 - val_acc: 0.6346\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.3271 - acc: 0.8804 - val_loss: 1.2807 - val_acc: 0.6609\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.3029 - acc: 0.8822 - val_loss: 1.1924 - val_acc: 0.6852\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.2728 - acc: 0.8949 - val_loss: 1.2722 - val_acc: 0.6670\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.2569 - acc: 0.8992 - val_loss: 1.2726 - val_acc: 0.6650\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.2287 - acc: 0.9129 - val_loss: 1.4091 - val_acc: 0.6660\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.2227 - acc: 0.9182 - val_loss: 1.3720 - val_acc: 0.6802\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.2188 - acc: 0.9195 - val_loss: 1.3667 - val_acc: 0.6903\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.1991 - acc: 0.9281 - val_loss: 1.4750 - val_acc: 0.6559\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.1918 - acc: 0.9283 - val_loss: 1.6266 - val_acc: 0.6589\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 23s 6ms/step - loss: 0.1806 - acc: 0.9331 - val_loss: 1.6062 - val_acc: 0.6700\n",
      "Epoch 23/30\n",
      "1472/3948 [==========>...................] - ETA: 13s - loss: 0.1530 - acc: 0.9395"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cba6199c6aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train2], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train2], Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_2 (Merge)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,707,888\n",
      "Trainable params: 5,707,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_text2 = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text2.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text2.add(LSTM(512, return_sequences=True))\n",
    "model_text2.add(Dropout(0.2))\n",
    "model_text2.add(LSTM(256, return_sequences=False))\n",
    "model_text2.add(Dropout(0.2))\n",
    "model_text2.add(Dense(512))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(LSTM(512, return_sequences=True, input_shape=(78, nb_feat)))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(LSTM(256, return_sequences=False))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(512))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text2, model_speech], mode='concat'))\n",
    "model_combined.add(Dropout(0.2))\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adadelta' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 146s 37ms/step - loss: 1.3477 - acc: 0.3513 - val_loss: 1.3413 - val_acc: 0.3360\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 144s 37ms/step - loss: 1.2763 - acc: 0.4108 - val_loss: 1.1672 - val_acc: 0.5040\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 144s 37ms/step - loss: 1.1915 - acc: 0.4770 - val_loss: 1.2037 - val_acc: 0.4524\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 144s 37ms/step - loss: 1.1174 - acc: 0.5228 - val_loss: 1.0894 - val_acc: 0.5304\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 145s 37ms/step - loss: 1.0456 - acc: 0.5522 - val_loss: 0.9770 - val_acc: 0.5860\n",
      "Epoch 6/30\n",
      "1856/3948 [=============>................] - ETA: 1:10 - loss: 1.0037 - acc: 0.5738"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cba6199c6aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train2], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train2], Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_26 (Flatten)         (None, 2652)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1024)              2716672   \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 3,373,828\n",
      "Trainable params: 3,373,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(78, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(256))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dense(4))\n",
    "model_speech.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_speech.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "model_speech.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3948/3948 [==============================] - 2s 548us/step - loss: 2.1281 - acc: 0.2910 - val_loss: 1.3566 - val_acc: 0.3715\n",
      "Epoch 2/80\n",
      "3948/3948 [==============================] - 1s 153us/step - loss: 1.4061 - acc: 0.3311 - val_loss: 1.2927 - val_acc: 0.3877\n",
      "Epoch 3/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.2936 - acc: 0.3827 - val_loss: 1.2349 - val_acc: 0.4646\n",
      "Epoch 4/80\n",
      "3948/3948 [==============================] - 1s 147us/step - loss: 1.2313 - acc: 0.4126 - val_loss: 1.2053 - val_acc: 0.4777\n",
      "Epoch 5/80\n",
      "3948/3948 [==============================] - 1s 147us/step - loss: 1.2042 - acc: 0.4230 - val_loss: 1.1938 - val_acc: 0.4575\n",
      "Epoch 6/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.1894 - acc: 0.4367 - val_loss: 1.2200 - val_acc: 0.4545\n",
      "Epoch 7/80\n",
      "3948/3948 [==============================] - 1s 147us/step - loss: 1.1742 - acc: 0.4387 - val_loss: 1.2022 - val_acc: 0.4676\n",
      "Epoch 8/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.1396 - acc: 0.4656 - val_loss: 1.1838 - val_acc: 0.4585\n",
      "Epoch 9/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.1528 - acc: 0.4536 - val_loss: 1.1751 - val_acc: 0.4767\n",
      "Epoch 10/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.1355 - acc: 0.4699 - val_loss: 1.1880 - val_acc: 0.4615\n",
      "Epoch 11/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.1152 - acc: 0.4800 - val_loss: 1.1438 - val_acc: 0.4949\n",
      "Epoch 12/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.1157 - acc: 0.4749 - val_loss: 1.1472 - val_acc: 0.4899\n",
      "Epoch 13/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.1113 - acc: 0.4813 - val_loss: 1.1820 - val_acc: 0.4980\n",
      "Epoch 14/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0981 - acc: 0.4861 - val_loss: 1.1850 - val_acc: 0.4656\n",
      "Epoch 15/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 1.0989 - acc: 0.4889 - val_loss: 1.1693 - val_acc: 0.4777\n",
      "Epoch 16/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.0889 - acc: 0.4916 - val_loss: 1.1834 - val_acc: 0.4646\n",
      "Epoch 17/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.0910 - acc: 0.4980 - val_loss: 1.1653 - val_acc: 0.4727\n",
      "Epoch 18/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0769 - acc: 0.5109 - val_loss: 1.1562 - val_acc: 0.4939\n",
      "Epoch 19/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0789 - acc: 0.4967 - val_loss: 1.1894 - val_acc: 0.4737\n",
      "Epoch 20/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.0700 - acc: 0.5048 - val_loss: 1.2063 - val_acc: 0.4291\n",
      "Epoch 21/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0600 - acc: 0.5073 - val_loss: 1.1969 - val_acc: 0.4636\n",
      "Epoch 22/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 1.0519 - acc: 0.5132 - val_loss: 1.2084 - val_acc: 0.4302\n",
      "Epoch 23/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 1.0596 - acc: 0.4957 - val_loss: 1.1318 - val_acc: 0.5071\n",
      "Epoch 24/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0731 - acc: 0.4992 - val_loss: 1.1903 - val_acc: 0.4706\n",
      "Epoch 25/80\n",
      "3948/3948 [==============================] - 1s 151us/step - loss: 1.0656 - acc: 0.5119 - val_loss: 1.1831 - val_acc: 0.4818\n",
      "Epoch 26/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0613 - acc: 0.5160 - val_loss: 1.2142 - val_acc: 0.4281\n",
      "Epoch 27/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 1.0512 - acc: 0.5081 - val_loss: 1.2146 - val_acc: 0.4484\n",
      "Epoch 28/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.0387 - acc: 0.5284 - val_loss: 1.1732 - val_acc: 0.4858\n",
      "Epoch 29/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0302 - acc: 0.5152 - val_loss: 1.2457 - val_acc: 0.4433\n",
      "Epoch 30/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 1.0300 - acc: 0.5230 - val_loss: 1.2447 - val_acc: 0.4626\n",
      "Epoch 31/80\n",
      "3948/3948 [==============================] - 1s 153us/step - loss: 1.0297 - acc: 0.5388 - val_loss: 1.1924 - val_acc: 0.4696\n",
      "Epoch 32/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 1.0168 - acc: 0.5400 - val_loss: 1.1593 - val_acc: 0.5172\n",
      "Epoch 33/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 1.0066 - acc: 0.5418 - val_loss: 1.1870 - val_acc: 0.4848\n",
      "Epoch 34/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.9955 - acc: 0.5524 - val_loss: 1.1898 - val_acc: 0.4929\n",
      "Epoch 35/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9913 - acc: 0.5491 - val_loss: 1.1980 - val_acc: 0.5020\n",
      "Epoch 36/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.9672 - acc: 0.5707 - val_loss: 1.1692 - val_acc: 0.5152\n",
      "Epoch 37/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9601 - acc: 0.5590 - val_loss: 1.1728 - val_acc: 0.4838\n",
      "Epoch 38/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.9857 - acc: 0.5514 - val_loss: 1.1856 - val_acc: 0.4939\n",
      "Epoch 39/80\n",
      "3948/3948 [==============================] - 1s 153us/step - loss: 0.9766 - acc: 0.5646 - val_loss: 1.1509 - val_acc: 0.5111\n",
      "Epoch 40/80\n",
      "3948/3948 [==============================] - 1s 151us/step - loss: 0.9895 - acc: 0.5484 - val_loss: 1.1678 - val_acc: 0.5030\n",
      "Epoch 41/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9860 - acc: 0.5507 - val_loss: 1.1898 - val_acc: 0.4717\n",
      "Epoch 42/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.9733 - acc: 0.5547 - val_loss: 1.1756 - val_acc: 0.4818\n",
      "Epoch 43/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9606 - acc: 0.5646 - val_loss: 1.2423 - val_acc: 0.4423\n",
      "Epoch 44/80\n",
      "3948/3948 [==============================] - 1s 152us/step - loss: 0.9545 - acc: 0.5691 - val_loss: 1.2259 - val_acc: 0.4848\n",
      "Epoch 45/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.9334 - acc: 0.5790 - val_loss: 1.2063 - val_acc: 0.4929\n",
      "Epoch 46/80\n",
      "3948/3948 [==============================] - 1s 154us/step - loss: 0.9332 - acc: 0.5821 - val_loss: 1.2232 - val_acc: 0.4646\n",
      "Epoch 47/80\n",
      "3948/3948 [==============================] - 1s 152us/step - loss: 0.9212 - acc: 0.5864 - val_loss: 1.3237 - val_acc: 0.4838\n",
      "Epoch 48/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9512 - acc: 0.5666 - val_loss: 1.1900 - val_acc: 0.4818\n",
      "Epoch 49/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.9391 - acc: 0.5821 - val_loss: 1.2058 - val_acc: 0.4889\n",
      "Epoch 50/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9263 - acc: 0.5767 - val_loss: 1.1964 - val_acc: 0.4990\n",
      "Epoch 51/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9306 - acc: 0.5826 - val_loss: 1.2277 - val_acc: 0.4757\n",
      "Epoch 52/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9388 - acc: 0.5742 - val_loss: 1.1903 - val_acc: 0.4949\n",
      "Epoch 53/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9494 - acc: 0.5798 - val_loss: 1.2276 - val_acc: 0.4747\n",
      "Epoch 54/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.9217 - acc: 0.5942 - val_loss: 1.2058 - val_acc: 0.5010\n",
      "Epoch 55/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9309 - acc: 0.5874 - val_loss: 1.2341 - val_acc: 0.4737\n",
      "Epoch 56/80\n",
      "3948/3948 [==============================] - 1s 152us/step - loss: 0.9063 - acc: 0.6018 - val_loss: 1.2401 - val_acc: 0.4848\n",
      "Epoch 57/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8818 - acc: 0.6097 - val_loss: 1.3244 - val_acc: 0.4666\n",
      "Epoch 58/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8937 - acc: 0.5988 - val_loss: 1.2056 - val_acc: 0.4919\n",
      "Epoch 59/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9109 - acc: 0.5919 - val_loss: 1.3095 - val_acc: 0.4838\n",
      "Epoch 60/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.8847 - acc: 0.6107 - val_loss: 1.2424 - val_acc: 0.4909\n",
      "Epoch 61/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8926 - acc: 0.6001 - val_loss: 1.2439 - val_acc: 0.5172\n",
      "Epoch 62/80\n",
      "3948/3948 [==============================] - 1s 147us/step - loss: 0.8781 - acc: 0.6152 - val_loss: 1.2457 - val_acc: 0.4696\n",
      "Epoch 63/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.9057 - acc: 0.6023 - val_loss: 1.2641 - val_acc: 0.4798\n",
      "Epoch 64/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.8912 - acc: 0.5993 - val_loss: 1.3544 - val_acc: 0.4777\n",
      "Epoch 65/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8939 - acc: 0.5957 - val_loss: 1.3199 - val_acc: 0.4990\n",
      "Epoch 66/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8585 - acc: 0.6155 - val_loss: 1.2324 - val_acc: 0.5223\n",
      "Epoch 67/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8561 - acc: 0.6201 - val_loss: 1.3131 - val_acc: 0.4717\n",
      "Epoch 68/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.8517 - acc: 0.6216 - val_loss: 1.3107 - val_acc: 0.5253\n",
      "Epoch 69/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8567 - acc: 0.6183 - val_loss: 1.3199 - val_acc: 0.4787\n",
      "Epoch 70/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8643 - acc: 0.6203 - val_loss: 1.2493 - val_acc: 0.5162\n",
      "Epoch 71/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8542 - acc: 0.6208 - val_loss: 1.3173 - val_acc: 0.4747\n",
      "Epoch 72/80\n",
      "3948/3948 [==============================] - 1s 151us/step - loss: 0.8590 - acc: 0.6170 - val_loss: 1.2759 - val_acc: 0.5111\n",
      "Epoch 73/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8449 - acc: 0.6140 - val_loss: 1.3538 - val_acc: 0.4828\n",
      "Epoch 74/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8393 - acc: 0.6277 - val_loss: 1.2501 - val_acc: 0.4919\n",
      "Epoch 75/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.8396 - acc: 0.6188 - val_loss: 1.3077 - val_acc: 0.5142\n",
      "Epoch 76/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8451 - acc: 0.6190 - val_loss: 1.3128 - val_acc: 0.5121\n",
      "Epoch 77/80\n",
      "3948/3948 [==============================] - 1s 150us/step - loss: 0.8480 - acc: 0.6170 - val_loss: 1.4091 - val_acc: 0.5010\n",
      "Epoch 78/80\n",
      "3948/3948 [==============================] - 1s 148us/step - loss: 0.8266 - acc: 0.6325 - val_loss: 1.2921 - val_acc: 0.4848\n",
      "Epoch 79/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8635 - acc: 0.6028 - val_loss: 1.3243 - val_acc: 0.5121\n",
      "Epoch 80/80\n",
      "3948/3948 [==============================] - 1s 149us/step - loss: 0.8379 - acc: 0.6294 - val_loss: 1.2941 - val_acc: 0.4706\n"
     ]
    }
   ],
   "source": [
    "hist = model_speech.fit(x_train2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:37: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 2652)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1024)              2716672   \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 3,372,800\n",
      "Trainable params: 3,372,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 4,456,160\n",
      "Non-trainable params: 821,100\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_5 (Merge)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 8,782,416\n",
      "Trainable params: 7,961,316\n",
      "Non-trainable params: 821,100\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(78, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 7s 2ms/step - loss: 1.9704 - acc: 0.3009 - val_loss: 1.3321 - val_acc: 0.3957\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 1.3356 - acc: 0.3627 - val_loss: 1.2091 - val_acc: 0.4717\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 1.1706 - acc: 0.4742 - val_loss: 1.1535 - val_acc: 0.4727\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 1.0260 - acc: 0.5537 - val_loss: 1.0815 - val_acc: 0.5263\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.8625 - acc: 0.6408 - val_loss: 0.9700 - val_acc: 0.6255\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.7373 - acc: 0.6988 - val_loss: 0.8648 - val_acc: 0.6599\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.6145 - acc: 0.7523 - val_loss: 0.9981 - val_acc: 0.6447\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.5427 - acc: 0.7842 - val_loss: 1.0844 - val_acc: 0.6417\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.4368 - acc: 0.8328 - val_loss: 1.0351 - val_acc: 0.6468\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.4053 - acc: 0.8457 - val_loss: 1.3228 - val_acc: 0.6306\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3726 - acc: 0.8599 - val_loss: 1.2202 - val_acc: 0.6316\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3485 - acc: 0.8690 - val_loss: 1.2923 - val_acc: 0.6559\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3000 - acc: 0.8873 - val_loss: 1.3051 - val_acc: 0.6488\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2667 - acc: 0.8989 - val_loss: 1.3216 - val_acc: 0.6559\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2708 - acc: 0.9017 - val_loss: 1.5749 - val_acc: 0.6468\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2505 - acc: 0.9083 - val_loss: 1.3582 - val_acc: 0.6589\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2379 - acc: 0.9113 - val_loss: 1.4452 - val_acc: 0.6619\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2400 - acc: 0.9121 - val_loss: 1.3886 - val_acc: 0.6751\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1975 - acc: 0.9248 - val_loss: 1.4208 - val_acc: 0.6589\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2204 - acc: 0.9217 - val_loss: 1.3789 - val_acc: 0.6842\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2103 - acc: 0.9212 - val_loss: 1.4365 - val_acc: 0.6609\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1931 - acc: 0.9288 - val_loss: 1.4200 - val_acc: 0.6711\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2000 - acc: 0.9250 - val_loss: 1.4879 - val_acc: 0.6690\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1801 - acc: 0.9309 - val_loss: 1.6736 - val_acc: 0.6569\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1918 - acc: 0.9283 - val_loss: 1.5855 - val_acc: 0.6690\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1968 - acc: 0.9263 - val_loss: 2.1412 - val_acc: 0.6326\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1849 - acc: 0.9311 - val_loss: 1.7122 - val_acc: 0.6660\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1884 - acc: 0.9336 - val_loss: 1.6000 - val_acc: 0.6528\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1588 - acc: 0.9407 - val_loss: 1.8136 - val_acc: 0.6559\n",
      "Epoch 30/30\n",
      "3328/3948 [========================>.....] - ETA: 0s - loss: 0.1397 - acc: 0.9444"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-cba6199c6aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train2], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train2], Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 189, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mocap = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    #x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "    #x_normed = x_normed - 0.5\n",
    "    #x_normed[np.isnan(x)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train_mocap.append( x_mocap )\n",
    "    \n",
    "x_train_mocap = np.array(x_train_mocap)\n",
    "x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n",
    "x_train_mocap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, padding=\"same\", strides=(2, 2), input_shape=(200, 189,...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_22 (Flatten)         (None, 2652)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1024)              2716672   \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 3,372,800\n",
      "Trainable params: 3,372,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_7 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 10,501,648\n",
      "Trainable params: 10,501,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:57: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "\n",
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(78, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 16s 4ms/step - loss: 2.7012 - acc: 0.3040 - val_loss: 1.3486 - val_acc: 0.3856\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 1.3046 - acc: 0.3777 - val_loss: 1.2629 - val_acc: 0.3745\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 1.0833 - acc: 0.5086 - val_loss: 1.0089 - val_acc: 0.5881\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.8703 - acc: 0.6380 - val_loss: 0.9212 - val_acc: 0.6447\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.6944 - acc: 0.7214 - val_loss: 0.9552 - val_acc: 0.6528oss - ETA: 1s - loss: 0.6922 - ac\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.5642 - acc: 0.7844 - val_loss: 1.0067 - val_acc: 0.6680\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.4611 - acc: 0.8260 - val_loss: 1.0795 - val_acc: 0.6933\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3785 - acc: 0.8604 - val_loss: 1.0637 - val_acc: 0.6883c: 0.86\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3377 - acc: 0.8756 - val_loss: 1.2927 - val_acc: 0.6680:  - ETA: 3s - loss: 0.34\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3169 - acc: 0.8779 - val_loss: 1.1352 - val_acc: 0.6781\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2829 - acc: 0.8964 - val_loss: 1.3624 - val_acc: 0.6903\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2561 - acc: 0.9037 - val_loss: 1.4923 - val_acc: 0.67612574\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2295 - acc: 0.9154 - val_loss: 1.4805 - val_acc: 0.6802\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2237 - acc: 0.9184 - val_loss: 1.4188 - val_acc: 0.6903 loss:\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2010 - acc: 0.9238 - val_loss: 1.4767 - val_acc: 0.6842 - a\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1837 - acc: 0.9314 - val_loss: 1.3422 - val_acc: 0.6872\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1688 - acc: 0.9362 - val_loss: 1.4476 - val_acc: 0.6721\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1820 - acc: 0.9298 - val_loss: 1.4653 - val_acc: 0.6974\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1845 - acc: 0.9364 - val_loss: 1.4321 - val_acc: 0.6549\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1592 - acc: 0.9395 - val_loss: 1.4044 - val_acc: 0.6893\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1504 - acc: 0.9410 - val_loss: 1.5546 - val_acc: 0.6903- loss:\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1485 - acc: 0.9415 - val_loss: 1.6379 - val_acc: 0.6923\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1287 - acc: 0.9501 - val_loss: 1.8783 - val_acc: 0.6852\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1279 - acc: 0.9478 - val_loss: 1.6585 - val_acc: 0.67918 - acc: 0. - ETA: 3s - loss: 0.1 - ETA: 0s - loss: 0.1236 - acc: 0.9\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1325 - acc: 0.9504 - val_loss: 1.7579 - val_acc: 0.6903\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1313 - acc: 0.9509 - val_loss: 1.7758 - val_acc: 0.6974\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1206 - acc: 0.9521 - val_loss: 1.9872 - val_acc: 0.6802\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1080 - acc: 0.9580 - val_loss: 2.2550 - val_acc: 0.7004s - loss: 0.1068 - acc: 0.9\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1296 - acc: 0.9539 - val_loss: 1.8548 - val_acc: 0.6700\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1158 - acc: 0.9549 - val_loss: 2.0182 - val_acc: 0.6984\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train2,x_train_mocap], Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 10, 34, 50)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sig2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_25 (Flatten)         (None, 17000)             0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 4096)              69636096  \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 74,094,852\n",
      "Trainable params: 74,094,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(10, 34, 50)))\n",
    "model_speech.add(Dense(4096))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.25))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.25))\n",
    "model_speech.add(Dense(256))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dense(4))\n",
    "model_speech.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_speech.compile(loss='categorical_crossentropy',optimizer='adadelta' ,metrics=['acc'])\n",
    "model_speech.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3948/3948 [==============================] - 10s 3ms/step - loss: 9.6804 - acc: 0.2999 - val_loss: 3.5498 - val_acc: 0.2895\n",
      "Epoch 2/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.6456 - acc: 0.3032 - val_loss: 1.3203 - val_acc: 0.3806\n",
      "Epoch 3/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3653 - acc: 0.3422 - val_loss: 1.2881 - val_acc: 0.4059\n",
      "Epoch 4/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3274 - acc: 0.3650 - val_loss: 1.3396 - val_acc: 0.3745\n",
      "Epoch 5/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2815 - acc: 0.3875 - val_loss: 1.3551 - val_acc: 0.3917\n",
      "Epoch 6/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2341 - acc: 0.4093 - val_loss: 1.3132 - val_acc: 0.4474\n",
      "Epoch 7/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2096 - acc: 0.4177 - val_loss: 1.2791 - val_acc: 0.4180\n",
      "Epoch 8/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1927 - acc: 0.4405 - val_loss: 1.2594 - val_acc: 0.4140\n",
      "Epoch 9/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1715 - acc: 0.4483 - val_loss: 1.2370 - val_acc: 0.4879\n",
      "Epoch 10/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1605 - acc: 0.4488 - val_loss: 1.2535 - val_acc: 0.4453\n",
      "Epoch 11/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1685 - acc: 0.4463 - val_loss: 1.2015 - val_acc: 0.4737\n",
      "Epoch 12/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1458 - acc: 0.4729 - val_loss: 1.2851 - val_acc: 0.3917\n",
      "Epoch 13/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1335 - acc: 0.4802 - val_loss: 1.2451 - val_acc: 0.4393\n",
      "Epoch 14/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1165 - acc: 0.4823 - val_loss: 1.1634 - val_acc: 0.5101\n",
      "Epoch 15/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1095 - acc: 0.4802 - val_loss: 1.2823 - val_acc: 0.3846\n",
      "Epoch 16/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0938 - acc: 0.4899 - val_loss: 1.2190 - val_acc: 0.4605\n",
      "Epoch 17/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0977 - acc: 0.5056 - val_loss: 1.2037 - val_acc: 0.4423\n",
      "Epoch 18/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0759 - acc: 0.5187 - val_loss: 1.2277 - val_acc: 0.4737\n",
      "Epoch 19/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0672 - acc: 0.5213 - val_loss: 1.2939 - val_acc: 0.3715\n",
      "Epoch 20/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0363 - acc: 0.5291 - val_loss: 1.2055 - val_acc: 0.4706\n",
      "Epoch 21/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0445 - acc: 0.5319 - val_loss: 1.3989 - val_acc: 0.3988\n",
      "Epoch 22/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0278 - acc: 0.5451 - val_loss: 1.2219 - val_acc: 0.4585\n",
      "Epoch 23/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0214 - acc: 0.5438 - val_loss: 1.2169 - val_acc: 0.4200\n",
      "Epoch 24/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0034 - acc: 0.5529 - val_loss: 1.2272 - val_acc: 0.4858\n",
      "Epoch 25/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9868 - acc: 0.5661 - val_loss: 1.1933 - val_acc: 0.4848\n",
      "Epoch 26/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9682 - acc: 0.5778 - val_loss: 1.2116 - val_acc: 0.4443\n",
      "Epoch 27/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9413 - acc: 0.5909 - val_loss: 1.2196 - val_acc: 0.4474\n",
      "Epoch 28/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9392 - acc: 0.5884 - val_loss: 1.2566 - val_acc: 0.3957\n",
      "Epoch 29/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9390 - acc: 0.5912 - val_loss: 1.2323 - val_acc: 0.4494\n",
      "Epoch 30/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9017 - acc: 0.6127 - val_loss: 1.4639 - val_acc: 0.4322\n",
      "Epoch 31/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8861 - acc: 0.6254 - val_loss: 1.2982 - val_acc: 0.4737\n",
      "Epoch 32/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8796 - acc: 0.6251 - val_loss: 1.2674 - val_acc: 0.4899\n",
      "Epoch 33/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8518 - acc: 0.6444 - val_loss: 1.3397 - val_acc: 0.4534\n",
      "Epoch 34/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8467 - acc: 0.6393 - val_loss: 1.3676 - val_acc: 0.4767\n",
      "Epoch 35/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8177 - acc: 0.6479 - val_loss: 1.4387 - val_acc: 0.3775\n",
      "Epoch 36/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7859 - acc: 0.6593 - val_loss: 1.2240 - val_acc: 0.4858\n",
      "Epoch 37/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7737 - acc: 0.6722 - val_loss: 1.3771 - val_acc: 0.4403\n",
      "Epoch 38/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7589 - acc: 0.6733 - val_loss: 1.3106 - val_acc: 0.4636\n",
      "Epoch 39/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7263 - acc: 0.6872 - val_loss: 1.2999 - val_acc: 0.4787\n",
      "Epoch 40/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7082 - acc: 0.7039 - val_loss: 1.2935 - val_acc: 0.4585\n",
      "Epoch 41/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6729 - acc: 0.7158 - val_loss: 1.5620 - val_acc: 0.4605\n",
      "Epoch 42/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6548 - acc: 0.7323 - val_loss: 1.4149 - val_acc: 0.4686\n",
      "Epoch 43/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6462 - acc: 0.7427 - val_loss: 1.4734 - val_acc: 0.4737\n",
      "Epoch 44/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6268 - acc: 0.7421 - val_loss: 1.4540 - val_acc: 0.4838\n",
      "Epoch 45/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5564 - acc: 0.7675 - val_loss: 1.5705 - val_acc: 0.4696\n",
      "Epoch 46/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5821 - acc: 0.7520 - val_loss: 1.7952 - val_acc: 0.4656\n",
      "Epoch 47/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5668 - acc: 0.7662 - val_loss: 1.4941 - val_acc: 0.4626\n",
      "Epoch 48/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5230 - acc: 0.7877 - val_loss: 1.5851 - val_acc: 0.4575\n",
      "Epoch 49/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5036 - acc: 0.7898 - val_loss: 2.2125 - val_acc: 0.4696\n",
      "Epoch 50/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5140 - acc: 0.7905 - val_loss: 1.9652 - val_acc: 0.4656\n",
      "Epoch 51/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.4942 - acc: 0.8032 - val_loss: 1.9767 - val_acc: 0.4777\n",
      "Epoch 52/80\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.4149 - acc: 0.8295 - val_loss: 1.9665 - val_acc: 0.4545\n",
      "Epoch 53/80\n",
      "1216/3948 [========>.....................] - ETA: 5s - loss: 0.4104 - acc: 0.8322"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-988ce46a2193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_speech.fit(x_train_sig2, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_speech.fit(x_train_sig2, Y, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3838"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    if (ses_mod['id'][:5]==\"Ses05\"):\n",
    "        break\n",
    "    counter+=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sp = x_train2[:3838]\n",
    "xtest_sp = x_train2[3838:]\n",
    "ytrain_sp = Y[:3838]\n",
    "ytest_sp = Y[3838:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/80\n",
      "1024/3838 [=======>......................] - ETA: 0s - loss: 0.7506 - acc: 0.6641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838/3838 [==============================] - 1s 170us/step - loss: 0.7892 - acc: 0.6501 - val_loss: 1.3314 - val_acc: 0.4763\n",
      "Epoch 2/80\n",
      "3838/3838 [==============================] - 1s 160us/step - loss: 0.8223 - acc: 0.6357 - val_loss: 1.3766 - val_acc: 0.4617\n",
      "Epoch 3/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.8114 - acc: 0.6428 - val_loss: 1.3192 - val_acc: 0.4763\n",
      "Epoch 4/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.8119 - acc: 0.6428 - val_loss: 1.3778 - val_acc: 0.4727\n",
      "Epoch 5/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.8213 - acc: 0.6285 - val_loss: 1.3790 - val_acc: 0.4909\n",
      "Epoch 6/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.8291 - acc: 0.6334 - val_loss: 1.3917 - val_acc: 0.4800\n",
      "Epoch 7/80\n",
      "3838/3838 [==============================] - 1s 151us/step - loss: 0.7647 - acc: 0.6717 - val_loss: 1.4769 - val_acc: 0.4927\n",
      "Epoch 8/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7811 - acc: 0.6535 - val_loss: 1.3587 - val_acc: 0.4772\n",
      "Epoch 9/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.8026 - acc: 0.6339 - val_loss: 1.3947 - val_acc: 0.4727\n",
      "Epoch 10/80\n",
      "3838/3838 [==============================] - 1s 148us/step - loss: 0.8241 - acc: 0.6342 - val_loss: 1.3619 - val_acc: 0.4791\n",
      "Epoch 11/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.7967 - acc: 0.6415 - val_loss: 1.3967 - val_acc: 0.4690\n",
      "Epoch 12/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.8103 - acc: 0.6318 - val_loss: 1.3881 - val_acc: 0.4854\n",
      "Epoch 13/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7727 - acc: 0.6477 - val_loss: 1.3881 - val_acc: 0.4763\n",
      "Epoch 14/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7947 - acc: 0.6535 - val_loss: 1.4181 - val_acc: 0.4800\n",
      "Epoch 15/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7813 - acc: 0.6553 - val_loss: 1.3702 - val_acc: 0.5000\n",
      "Epoch 16/80\n",
      "3838/3838 [==============================] - 1s 156us/step - loss: 0.8100 - acc: 0.6410 - val_loss: 1.3777 - val_acc: 0.4900\n",
      "Epoch 17/80\n",
      "3838/3838 [==============================] - 1s 156us/step - loss: 0.7870 - acc: 0.6579 - val_loss: 1.4194 - val_acc: 0.4727\n",
      "Epoch 18/80\n",
      "3838/3838 [==============================] - 1s 159us/step - loss: 0.8168 - acc: 0.6433 - val_loss: 1.4342 - val_acc: 0.4918\n",
      "Epoch 19/80\n",
      "3838/3838 [==============================] - 1s 159us/step - loss: 0.7539 - acc: 0.6621 - val_loss: 1.4524 - val_acc: 0.4891\n",
      "Epoch 20/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.7465 - acc: 0.6704 - val_loss: 1.5000 - val_acc: 0.4791\n",
      "Epoch 21/80\n",
      "3838/3838 [==============================] - 1s 156us/step - loss: 0.7818 - acc: 0.6506 - val_loss: 1.4506 - val_acc: 0.4699\n",
      "Epoch 22/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.7651 - acc: 0.6657 - val_loss: 1.4231 - val_acc: 0.5036\n",
      "Epoch 23/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7624 - acc: 0.6662 - val_loss: 1.4329 - val_acc: 0.4991\n",
      "Epoch 24/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7358 - acc: 0.6780 - val_loss: 1.5241 - val_acc: 0.4827\n",
      "Epoch 25/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7579 - acc: 0.6681 - val_loss: 1.4324 - val_acc: 0.4991\n",
      "Epoch 26/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7559 - acc: 0.6647 - val_loss: 1.4941 - val_acc: 0.4982\n",
      "Epoch 27/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.7570 - acc: 0.6686 - val_loss: 1.4095 - val_acc: 0.4900\n",
      "Epoch 28/80\n",
      "3838/3838 [==============================] - 1s 157us/step - loss: 0.7784 - acc: 0.6576 - val_loss: 1.4673 - val_acc: 0.4854\n",
      "Epoch 29/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.7301 - acc: 0.6790 - val_loss: 1.5082 - val_acc: 0.4818\n",
      "Epoch 30/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.7929 - acc: 0.6397 - val_loss: 1.5179 - val_acc: 0.4945\n",
      "Epoch 31/80\n",
      "3838/3838 [==============================] - 1s 156us/step - loss: 0.7728 - acc: 0.6503 - val_loss: 1.4768 - val_acc: 0.4699\n",
      "Epoch 32/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.8019 - acc: 0.6292 - val_loss: 1.4901 - val_acc: 0.4836\n",
      "Epoch 33/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7997 - acc: 0.6365 - val_loss: 1.4239 - val_acc: 0.4772\n",
      "Epoch 34/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.7553 - acc: 0.6558 - val_loss: 1.4709 - val_acc: 0.4772\n",
      "Epoch 35/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7519 - acc: 0.6529 - val_loss: 1.4959 - val_acc: 0.4736\n",
      "Epoch 36/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7558 - acc: 0.6509 - val_loss: 1.4202 - val_acc: 0.4809\n",
      "Epoch 37/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7186 - acc: 0.6756 - val_loss: 1.6156 - val_acc: 0.4809\n",
      "Epoch 38/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7356 - acc: 0.6644 - val_loss: 1.5458 - val_acc: 0.4699\n",
      "Epoch 39/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.7463 - acc: 0.6683 - val_loss: 1.5844 - val_acc: 0.4718\n",
      "Epoch 40/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7634 - acc: 0.6641 - val_loss: 1.4936 - val_acc: 0.4909\n",
      "Epoch 41/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.7216 - acc: 0.6808 - val_loss: 1.5356 - val_acc: 0.4918\n",
      "Epoch 42/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7114 - acc: 0.6751 - val_loss: 1.5062 - val_acc: 0.5018\n",
      "Epoch 43/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7354 - acc: 0.6652 - val_loss: 1.7666 - val_acc: 0.4781\n",
      "Epoch 44/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.7002 - acc: 0.6897 - val_loss: 1.6947 - val_acc: 0.4781\n",
      "Epoch 45/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6942 - acc: 0.6980 - val_loss: 1.5346 - val_acc: 0.4964\n",
      "Epoch 46/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7211 - acc: 0.6746 - val_loss: 1.5898 - val_acc: 0.4927\n",
      "Epoch 47/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.6983 - acc: 0.6905 - val_loss: 1.5881 - val_acc: 0.4909\n",
      "Epoch 48/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7010 - acc: 0.6894 - val_loss: 1.6933 - val_acc: 0.4882\n",
      "Epoch 49/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.6804 - acc: 0.6993 - val_loss: 1.5340 - val_acc: 0.4918\n",
      "Epoch 50/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.7134 - acc: 0.6748 - val_loss: 1.7230 - val_acc: 0.4845\n",
      "Epoch 51/80\n",
      "3838/3838 [==============================] - 1s 147us/step - loss: 0.7302 - acc: 0.6740 - val_loss: 1.5671 - val_acc: 0.4845\n",
      "Epoch 52/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.7215 - acc: 0.6774 - val_loss: 1.5348 - val_acc: 0.4945\n",
      "Epoch 53/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7095 - acc: 0.6759 - val_loss: 1.5860 - val_acc: 0.4945\n",
      "Epoch 54/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7126 - acc: 0.6790 - val_loss: 1.6176 - val_acc: 0.5036\n",
      "Epoch 55/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.6863 - acc: 0.6829 - val_loss: 1.6843 - val_acc: 0.4954\n",
      "Epoch 56/80\n",
      "3838/3838 [==============================] - 1s 148us/step - loss: 0.6984 - acc: 0.6853 - val_loss: 1.8013 - val_acc: 0.4809\n",
      "Epoch 57/80\n",
      "3838/3838 [==============================] - 1s 149us/step - loss: 0.6939 - acc: 0.6845 - val_loss: 1.6084 - val_acc: 0.4791\n",
      "Epoch 58/80\n",
      "3838/3838 [==============================] - 1s 148us/step - loss: 0.6963 - acc: 0.6853 - val_loss: 1.7710 - val_acc: 0.4818\n",
      "Epoch 59/80\n",
      "3838/3838 [==============================] - 1s 150us/step - loss: 0.7033 - acc: 0.6821 - val_loss: 1.5581 - val_acc: 0.4863\n",
      "Epoch 60/80\n",
      "3838/3838 [==============================] - 1s 151us/step - loss: 0.7160 - acc: 0.6595 - val_loss: 1.7199 - val_acc: 0.4863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "3838/3838 [==============================] - 1s 151us/step - loss: 0.6777 - acc: 0.6899 - val_loss: 1.6439 - val_acc: 0.5009\n",
      "Epoch 62/80\n",
      "3838/3838 [==============================] - 1s 152us/step - loss: 0.6635 - acc: 0.6939 - val_loss: 1.7320 - val_acc: 0.4936\n",
      "Epoch 63/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6863 - acc: 0.6899 - val_loss: 1.6259 - val_acc: 0.4973\n",
      "Epoch 64/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6867 - acc: 0.6899 - val_loss: 1.7540 - val_acc: 0.4991\n",
      "Epoch 65/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6707 - acc: 0.6892 - val_loss: 1.8306 - val_acc: 0.4818\n",
      "Epoch 66/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.6473 - acc: 0.7095 - val_loss: 1.7406 - val_acc: 0.5036\n",
      "Epoch 67/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.6863 - acc: 0.6985 - val_loss: 1.6942 - val_acc: 0.4973\n",
      "Epoch 68/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6536 - acc: 0.7084 - val_loss: 1.6021 - val_acc: 0.4845\n",
      "Epoch 69/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.6594 - acc: 0.7071 - val_loss: 1.7635 - val_acc: 0.5000\n",
      "Epoch 70/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6748 - acc: 0.6970 - val_loss: 1.8396 - val_acc: 0.4918\n",
      "Epoch 71/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.7060 - acc: 0.6821 - val_loss: 1.7024 - val_acc: 0.4872\n",
      "Epoch 72/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.6825 - acc: 0.6985 - val_loss: 1.6537 - val_acc: 0.4772\n",
      "Epoch 73/80\n",
      "3838/3838 [==============================] - 1s 156us/step - loss: 0.6685 - acc: 0.6952 - val_loss: 1.6476 - val_acc: 0.4800\n",
      "Epoch 74/80\n",
      "3838/3838 [==============================] - 1s 154us/step - loss: 0.6568 - acc: 0.7084 - val_loss: 1.8730 - val_acc: 0.4909\n",
      "Epoch 75/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.6537 - acc: 0.7045 - val_loss: 1.7437 - val_acc: 0.4791\n",
      "Epoch 76/80\n",
      "3838/3838 [==============================] - 1s 155us/step - loss: 0.6501 - acc: 0.7061 - val_loss: 1.7801 - val_acc: 0.4909\n",
      "Epoch 77/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6445 - acc: 0.7071 - val_loss: 1.8262 - val_acc: 0.4945\n",
      "Epoch 78/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6540 - acc: 0.7084 - val_loss: 1.7377 - val_acc: 0.4818\n",
      "Epoch 79/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6550 - acc: 0.7019 - val_loss: 1.7622 - val_acc: 0.4845\n",
      "Epoch 80/80\n",
      "3838/3838 [==============================] - 1s 153us/step - loss: 0.6539 - acc: 0.7040 - val_loss: 1.7822 - val_acc: 0.4791\n"
     ]
    }
   ],
   "source": [
    "hist = model_speech.fit(xtrain_sp, ytrain_sp, \n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, shuffle = True, \n",
    "                 validation_data=(xtest_sp, ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    }
   ],
   "source": [
    "x_train_long = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calc_feat.calculate_features(x_head, params.framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=125)\n",
    "    x_train_long.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train_long = np.array(x_train_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 125, 34)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_27 (Flatten)         (None, 4250)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1024)              4353024   \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,010,180\n",
      "Trainable params: 5,010,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(125, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.5))\n",
    "model_speech.add(Dense(256))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dense(4))\n",
    "model_speech.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_speech.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "model_speech.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/125\n",
      "3948/3948 [==============================] - 3s 652us/step - loss: 2.1803 - acc: 0.2893 - val_loss: 1.3382 - val_acc: 0.3968\n",
      "Epoch 2/125\n",
      "3948/3948 [==============================] - 1s 186us/step - loss: 1.4264 - acc: 0.3546 - val_loss: 1.2773 - val_acc: 0.4200\n",
      "Epoch 3/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.2848 - acc: 0.4002 - val_loss: 1.2208 - val_acc: 0.4545\n",
      "Epoch 4/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.2313 - acc: 0.4151 - val_loss: 1.1997 - val_acc: 0.4686\n",
      "Epoch 5/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.2048 - acc: 0.4377 - val_loss: 1.2119 - val_acc: 0.4170\n",
      "Epoch 6/125\n",
      "3948/3948 [==============================] - 1s 189us/step - loss: 1.1881 - acc: 0.4372 - val_loss: 1.2104 - val_acc: 0.4484\n",
      "Epoch 7/125\n",
      "3948/3948 [==============================] - 1s 189us/step - loss: 1.1754 - acc: 0.4354 - val_loss: 1.1893 - val_acc: 0.4656\n",
      "Epoch 8/125\n",
      "3948/3948 [==============================] - 1s 189us/step - loss: 1.1569 - acc: 0.4574 - val_loss: 1.1725 - val_acc: 0.4696\n",
      "Epoch 9/125\n",
      "3948/3948 [==============================] - 1s 196us/step - loss: 1.1474 - acc: 0.4572 - val_loss: 1.2411 - val_acc: 0.4200\n",
      "Epoch 10/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 1.1381 - acc: 0.4628 - val_loss: 1.1896 - val_acc: 0.4291\n",
      "Epoch 11/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.1154 - acc: 0.4848 - val_loss: 1.1778 - val_acc: 0.4281\n",
      "Epoch 12/125\n",
      "3948/3948 [==============================] - 1s 190us/step - loss: 1.1357 - acc: 0.4618 - val_loss: 1.1709 - val_acc: 0.4676\n",
      "Epoch 13/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.1176 - acc: 0.4719 - val_loss: 1.2011 - val_acc: 0.4646\n",
      "Epoch 14/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.1187 - acc: 0.4807 - val_loss: 1.1939 - val_acc: 0.4160\n",
      "Epoch 15/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.1008 - acc: 0.4873 - val_loss: 1.1728 - val_acc: 0.4545\n",
      "Epoch 16/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.1029 - acc: 0.4901 - val_loss: 1.2000 - val_acc: 0.4575\n",
      "Epoch 17/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.0926 - acc: 0.4858 - val_loss: 1.1392 - val_acc: 0.4929\n",
      "Epoch 18/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0841 - acc: 0.5139 - val_loss: 1.2061 - val_acc: 0.4727\n",
      "Epoch 19/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.0814 - acc: 0.4972 - val_loss: 1.1800 - val_acc: 0.4929\n",
      "Epoch 20/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0740 - acc: 0.4972 - val_loss: 1.2398 - val_acc: 0.4200\n",
      "Epoch 21/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.0656 - acc: 0.5187 - val_loss: 1.1708 - val_acc: 0.4879\n",
      "Epoch 22/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 1.0625 - acc: 0.5147 - val_loss: 1.2141 - val_acc: 0.5000\n",
      "Epoch 23/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0486 - acc: 0.5170 - val_loss: 1.1500 - val_acc: 0.4980\n",
      "Epoch 24/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0440 - acc: 0.5238 - val_loss: 1.2140 - val_acc: 0.4757\n",
      "Epoch 25/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.0562 - acc: 0.5223 - val_loss: 1.2365 - val_acc: 0.4494\n",
      "Epoch 26/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 1.0701 - acc: 0.5079 - val_loss: 1.2217 - val_acc: 0.4656\n",
      "Epoch 27/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0395 - acc: 0.5205 - val_loss: 1.1702 - val_acc: 0.5071\n",
      "Epoch 28/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0334 - acc: 0.5306 - val_loss: 1.1922 - val_acc: 0.4676\n",
      "Epoch 29/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 1.0038 - acc: 0.5489 - val_loss: 1.2111 - val_acc: 0.4464\n",
      "Epoch 30/125\n",
      "3948/3948 [==============================] - 1s 190us/step - loss: 1.0002 - acc: 0.5418 - val_loss: 1.1629 - val_acc: 0.5111\n",
      "Epoch 31/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.0207 - acc: 0.5377 - val_loss: 1.1874 - val_acc: 0.4828\n",
      "Epoch 32/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0229 - acc: 0.5268 - val_loss: 1.2682 - val_acc: 0.4524\n",
      "Epoch 33/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 1.0291 - acc: 0.5306 - val_loss: 1.2246 - val_acc: 0.4960\n",
      "Epoch 34/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9974 - acc: 0.5469 - val_loss: 1.1396 - val_acc: 0.5081\n",
      "Epoch 35/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 1.0031 - acc: 0.5390 - val_loss: 1.2033 - val_acc: 0.4747\n",
      "Epoch 36/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9943 - acc: 0.5514 - val_loss: 1.1873 - val_acc: 0.4929\n",
      "Epoch 37/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 1.0119 - acc: 0.5410 - val_loss: 1.1710 - val_acc: 0.5142\n",
      "Epoch 38/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 1.0039 - acc: 0.5388 - val_loss: 1.2796 - val_acc: 0.4636\n",
      "Epoch 39/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.9826 - acc: 0.5580 - val_loss: 1.1706 - val_acc: 0.5061\n",
      "Epoch 40/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.9859 - acc: 0.5552 - val_loss: 1.2380 - val_acc: 0.4757\n",
      "Epoch 41/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.9829 - acc: 0.5540 - val_loss: 1.2114 - val_acc: 0.4747\n",
      "Epoch 42/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9531 - acc: 0.5755 - val_loss: 1.2269 - val_acc: 0.4980\n",
      "Epoch 43/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.9654 - acc: 0.5676 - val_loss: 1.2613 - val_acc: 0.4889\n",
      "Epoch 44/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.9724 - acc: 0.5491 - val_loss: 1.2533 - val_acc: 0.4545\n",
      "Epoch 45/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9730 - acc: 0.5578 - val_loss: 1.1792 - val_acc: 0.4939\n",
      "Epoch 46/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.9575 - acc: 0.5613 - val_loss: 1.2016 - val_acc: 0.4605\n",
      "Epoch 47/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.9466 - acc: 0.5641 - val_loss: 1.2214 - val_acc: 0.4686\n",
      "Epoch 48/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9541 - acc: 0.5618 - val_loss: 1.3060 - val_acc: 0.4889\n",
      "Epoch 49/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.9143 - acc: 0.5876 - val_loss: 1.2558 - val_acc: 0.4889\n",
      "Epoch 50/125\n",
      "3948/3948 [==============================] - 1s 190us/step - loss: 0.9201 - acc: 0.5826 - val_loss: 1.2383 - val_acc: 0.4919\n",
      "Epoch 51/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.9412 - acc: 0.5762 - val_loss: 1.2779 - val_acc: 0.4838\n",
      "Epoch 52/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.9258 - acc: 0.5836 - val_loss: 1.2779 - val_acc: 0.4838\n",
      "Epoch 53/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9282 - acc: 0.5831 - val_loss: 1.1716 - val_acc: 0.5273\n",
      "Epoch 54/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.9089 - acc: 0.5970 - val_loss: 1.2009 - val_acc: 0.4868\n",
      "Epoch 55/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.8983 - acc: 0.5980 - val_loss: 1.2431 - val_acc: 0.5152\n",
      "Epoch 56/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8928 - acc: 0.6046 - val_loss: 1.2345 - val_acc: 0.4980\n",
      "Epoch 57/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.9039 - acc: 0.5854 - val_loss: 1.3312 - val_acc: 0.4909\n",
      "Epoch 58/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.9069 - acc: 0.5927 - val_loss: 1.3028 - val_acc: 0.5071\n",
      "Epoch 59/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8891 - acc: 0.6059 - val_loss: 1.2470 - val_acc: 0.5051\n",
      "Epoch 60/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8648 - acc: 0.6102 - val_loss: 1.2511 - val_acc: 0.5152\n",
      "Epoch 61/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8651 - acc: 0.6071 - val_loss: 1.3042 - val_acc: 0.4868\n",
      "Epoch 62/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8435 - acc: 0.6236 - val_loss: 1.2750 - val_acc: 0.4939\n",
      "Epoch 63/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8774 - acc: 0.6026 - val_loss: 1.2357 - val_acc: 0.4970\n",
      "Epoch 64/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8746 - acc: 0.6016 - val_loss: 1.3751 - val_acc: 0.4676\n",
      "Epoch 65/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8621 - acc: 0.6117 - val_loss: 1.3230 - val_acc: 0.5051\n",
      "Epoch 66/125\n",
      "3948/3948 [==============================] - 1s 190us/step - loss: 0.8587 - acc: 0.6140 - val_loss: 1.2809 - val_acc: 0.4960\n",
      "Epoch 67/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8829 - acc: 0.5970 - val_loss: 1.3211 - val_acc: 0.5010\n",
      "Epoch 68/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8711 - acc: 0.6008 - val_loss: 1.2463 - val_acc: 0.5142\n",
      "Epoch 69/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8520 - acc: 0.6254 - val_loss: 1.3222 - val_acc: 0.4949\n",
      "Epoch 70/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8468 - acc: 0.6183 - val_loss: 1.3166 - val_acc: 0.5081\n",
      "Epoch 71/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8228 - acc: 0.6312 - val_loss: 1.4498 - val_acc: 0.4899\n",
      "Epoch 72/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8427 - acc: 0.6190 - val_loss: 1.4262 - val_acc: 0.4929\n",
      "Epoch 73/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8494 - acc: 0.6079 - val_loss: 1.2978 - val_acc: 0.5132\n",
      "Epoch 74/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.8203 - acc: 0.6307 - val_loss: 1.3594 - val_acc: 0.5091\n",
      "Epoch 75/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8144 - acc: 0.6456 - val_loss: 1.4191 - val_acc: 0.5061\n",
      "Epoch 76/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8366 - acc: 0.6221 - val_loss: 1.3163 - val_acc: 0.5030\n",
      "Epoch 77/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8268 - acc: 0.6358 - val_loss: 1.3763 - val_acc: 0.4919\n",
      "Epoch 78/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.8386 - acc: 0.6170 - val_loss: 1.5486 - val_acc: 0.4919\n",
      "Epoch 79/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.8423 - acc: 0.6208 - val_loss: 1.4132 - val_acc: 0.4787\n",
      "Epoch 80/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8060 - acc: 0.6340 - val_loss: 1.4685 - val_acc: 0.5081\n",
      "Epoch 81/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.8170 - acc: 0.6216 - val_loss: 1.3523 - val_acc: 0.5152\n",
      "Epoch 82/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.8270 - acc: 0.6180 - val_loss: 1.4022 - val_acc: 0.4828\n",
      "Epoch 83/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.8002 - acc: 0.6401 - val_loss: 1.3726 - val_acc: 0.5020\n",
      "Epoch 84/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.7859 - acc: 0.6434 - val_loss: 1.3535 - val_acc: 0.4939\n",
      "Epoch 85/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.7702 - acc: 0.6565 - val_loss: 1.4051 - val_acc: 0.5142\n",
      "Epoch 86/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7670 - acc: 0.6548 - val_loss: 1.3551 - val_acc: 0.5152\n",
      "Epoch 87/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7794 - acc: 0.6588 - val_loss: 1.3792 - val_acc: 0.5111\n",
      "Epoch 88/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7829 - acc: 0.6467 - val_loss: 1.4979 - val_acc: 0.5132\n",
      "Epoch 89/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7926 - acc: 0.6482 - val_loss: 1.3400 - val_acc: 0.5162\n",
      "Epoch 90/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7652 - acc: 0.6558 - val_loss: 1.5383 - val_acc: 0.4828\n",
      "Epoch 91/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7851 - acc: 0.6487 - val_loss: 1.3881 - val_acc: 0.4838\n",
      "Epoch 92/125\n",
      "3948/3948 [==============================] - 1s 191us/step - loss: 0.7920 - acc: 0.6446 - val_loss: 1.3856 - val_acc: 0.4980\n",
      "Epoch 93/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7947 - acc: 0.6345 - val_loss: 1.4414 - val_acc: 0.5101\n",
      "Epoch 94/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7720 - acc: 0.6601 - val_loss: 1.4805 - val_acc: 0.5233\n",
      "Epoch 95/125\n",
      "3948/3948 [==============================] - 1s 197us/step - loss: 0.7469 - acc: 0.6626 - val_loss: 1.6209 - val_acc: 0.5010\n",
      "Epoch 96/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7502 - acc: 0.6535 - val_loss: 1.4862 - val_acc: 0.5152\n",
      "Epoch 97/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7510 - acc: 0.6553 - val_loss: 1.5267 - val_acc: 0.5010\n",
      "Epoch 98/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7313 - acc: 0.6753 - val_loss: 1.6081 - val_acc: 0.5051\n",
      "Epoch 99/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7805 - acc: 0.6507 - val_loss: 1.4660 - val_acc: 0.4848\n",
      "Epoch 100/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7811 - acc: 0.6492 - val_loss: 1.5708 - val_acc: 0.5182\n",
      "Epoch 101/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7438 - acc: 0.6750 - val_loss: 1.5815 - val_acc: 0.4929\n",
      "Epoch 102/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7111 - acc: 0.6750 - val_loss: 1.5034 - val_acc: 0.4929\n",
      "Epoch 103/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7142 - acc: 0.6783 - val_loss: 1.4610 - val_acc: 0.4818\n",
      "Epoch 104/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7320 - acc: 0.6748 - val_loss: 1.5399 - val_acc: 0.4949\n",
      "Epoch 105/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7115 - acc: 0.6811 - val_loss: 1.4851 - val_acc: 0.5253\n",
      "Epoch 106/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7310 - acc: 0.6763 - val_loss: 1.5491 - val_acc: 0.5142\n",
      "Epoch 107/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7308 - acc: 0.6791 - val_loss: 1.5205 - val_acc: 0.5202\n",
      "Epoch 108/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7115 - acc: 0.6801 - val_loss: 1.5494 - val_acc: 0.5051\n",
      "Epoch 109/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7322 - acc: 0.6601 - val_loss: 1.5925 - val_acc: 0.5071\n",
      "Epoch 110/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7238 - acc: 0.6803 - val_loss: 1.6090 - val_acc: 0.5020\n",
      "Epoch 111/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.6925 - acc: 0.6862 - val_loss: 1.8582 - val_acc: 0.5202\n",
      "Epoch 112/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7194 - acc: 0.6662 - val_loss: 1.6863 - val_acc: 0.4798\n",
      "Epoch 113/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7144 - acc: 0.6748 - val_loss: 1.6602 - val_acc: 0.5081\n",
      "Epoch 114/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7381 - acc: 0.6641 - val_loss: 1.5917 - val_acc: 0.5142\n",
      "Epoch 115/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7039 - acc: 0.6796 - val_loss: 1.8753 - val_acc: 0.4727\n",
      "Epoch 116/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7086 - acc: 0.6882 - val_loss: 1.6134 - val_acc: 0.4858\n",
      "Epoch 117/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7129 - acc: 0.6793 - val_loss: 1.6632 - val_acc: 0.4949\n",
      "Epoch 118/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7325 - acc: 0.6727 - val_loss: 1.5542 - val_acc: 0.4960\n",
      "Epoch 119/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7121 - acc: 0.6816 - val_loss: 1.5424 - val_acc: 0.4970\n",
      "Epoch 120/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.6979 - acc: 0.6836 - val_loss: 1.5903 - val_acc: 0.4960\n",
      "Epoch 121/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7170 - acc: 0.6793 - val_loss: 1.5892 - val_acc: 0.5213\n",
      "Epoch 122/125\n",
      "3948/3948 [==============================] - 1s 192us/step - loss: 0.7125 - acc: 0.6887 - val_loss: 1.6430 - val_acc: 0.4939\n",
      "Epoch 123/125\n",
      "3948/3948 [==============================] - 1s 195us/step - loss: 0.7221 - acc: 0.6727 - val_loss: 1.7707 - val_acc: 0.4828\n",
      "Epoch 124/125\n",
      "3948/3948 [==============================] - 1s 194us/step - loss: 0.7006 - acc: 0.6869 - val_loss: 1.6332 - val_acc: 0.5192\n",
      "Epoch 125/125\n",
      "3948/3948 [==============================] - 1s 193us/step - loss: 0.7322 - acc: 0.6624 - val_loss: 1.6319 - val_acc: 0.4808\n"
     ]
    }
   ],
   "source": [
    "hist = model_speech.fit(x_train_long, Y, \n",
    "                 batch_size=batch_size, nb_epoch=125, verbose=1, shuffle = True, \n",
    "                 validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, padding=\"same\", strides=(2, 2), input_shape=(200, 189,...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_32 (Flatten)         (None, 4250)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1024)              4353024   \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 5,009,152\n",
      "Trainable params: 5,009,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_9 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 12,138,000\n",
      "Trainable params: 12,138,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:57: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "\n",
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(125, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_mocap.add(Dropout(0.2))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/60\n",
      "3948/3948 [==============================] - 16s 4ms/step - loss: 2.0962 - acc: 0.3361 - val_loss: 1.3285 - val_acc: 0.4231\n",
      "Epoch 2/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 1.1580 - acc: 0.4620 - val_loss: 1.1801 - val_acc: 0.4646\n",
      "Epoch 3/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 1.0002 - acc: 0.5646 - val_loss: 1.0507 - val_acc: 0.5719\n",
      "Epoch 4/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.8115 - acc: 0.6677 - val_loss: 1.2063 - val_acc: 0.5789\n",
      "Epoch 5/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.6466 - acc: 0.7419 - val_loss: 0.9470 - val_acc: 0.6731\n",
      "Epoch 6/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.5015 - acc: 0.8055 - val_loss: 0.9451 - val_acc: 0.6660\n",
      "Epoch 7/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.4209 - acc: 0.8419 - val_loss: 1.0361 - val_acc: 0.6721\n",
      "Epoch 8/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3792 - acc: 0.8566 - val_loss: 1.1091 - val_acc: 0.6619\n",
      "Epoch 9/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3212 - acc: 0.8850 - val_loss: 1.3061 - val_acc: 0.6549\n",
      "Epoch 10/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2962 - acc: 0.8924 - val_loss: 1.1959 - val_acc: 0.6721\n",
      "Epoch 11/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2477 - acc: 0.9060 - val_loss: 1.4108 - val_acc: 0.6883\n",
      "Epoch 12/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.2171 - acc: 0.9258 - val_loss: 1.3338 - val_acc: 0.6822\n",
      "Epoch 13/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1869 - acc: 0.9334 - val_loss: 1.4184 - val_acc: 0.6589\n",
      "Epoch 14/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1985 - acc: 0.9248 - val_loss: 1.3713 - val_acc: 0.6609\n",
      "Epoch 15/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1859 - acc: 0.9364 - val_loss: 1.3870 - val_acc: 0.6670\n",
      "Epoch 16/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1977 - acc: 0.9253 - val_loss: 1.3044 - val_acc: 0.6761\n",
      "Epoch 17/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1616 - acc: 0.9402 - val_loss: 1.5377 - val_acc: 0.6559\n",
      "Epoch 18/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1647 - acc: 0.9400 - val_loss: 1.7415 - val_acc: 0.6670\n",
      "Epoch 19/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1750 - acc: 0.9324 - val_loss: 1.6931 - val_acc: 0.6741\n",
      "Epoch 20/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1511 - acc: 0.9443 - val_loss: 1.5775 - val_acc: 0.6761\n",
      "Epoch 21/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1401 - acc: 0.9463 - val_loss: 1.7453 - val_acc: 0.6781\n",
      "Epoch 22/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1414 - acc: 0.9438 - val_loss: 2.0856 - val_acc: 0.6670\n",
      "Epoch 23/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1493 - acc: 0.9460 - val_loss: 1.7485 - val_acc: 0.6640\n",
      "Epoch 24/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1377 - acc: 0.9476 - val_loss: 1.6458 - val_acc: 0.6761\n",
      "Epoch 25/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1413 - acc: 0.9478 - val_loss: 1.8265 - val_acc: 0.6822\n",
      "Epoch 26/60\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.1118 - acc: 0.9592 - val_loss: 1.8624 - val_acc: 0.6751\n",
      "Epoch 27/60\n",
      "1664/3948 [===========>..................] - ETA: 7s - loss: 0.1570 - acc: 0.9429"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-2e6ce76b7012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train_long,x_train_mocap], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_long,x_train_mocap], Y, \n",
    "                 batch_size=batch_size, nb_epoch=60, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
