{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Microphone (Realtek(R) Audio)', 'hostApi': 0, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Output', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 3, 'structVersion': 2, 'name': 'Speakers (Realtek(R) Audio)', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 4, 'structVersion': 2, 'name': 'BenQ GW2480 (Intel(R) Display A', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 5, 'structVersion': 2, 'name': 'Primary Sound Capture Driver', 'hostApi': 1, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 6, 'structVersion': 2, 'name': 'Microphone (Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.12, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.24, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 44100.0}\n",
      "{'index': 7, 'structVersion': 2, 'name': 'Primary Sound Driver', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 8, 'structVersion': 2, 'name': 'Speakers (Realtek(R) Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 9, 'structVersion': 2, 'name': 'BenQ GW2480 (Intel(R) Display Audio)', 'hostApi': 1, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.12, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.24, 'defaultSampleRate': 44100.0}\n",
      "{'index': 10, 'structVersion': 2, 'name': 'BenQ GW2480 (Intel(R) Display Audio)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 11, 'structVersion': 2, 'name': 'Speakers (Realtek(R) Audio)', 'hostApi': 3, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.0, 'defaultLowOutputLatency': 0.003, 'defaultHighInputLatency': 0.0, 'defaultHighOutputLatency': 0.01, 'defaultSampleRate': 48000.0}\n",
      "{'index': 12, 'structVersion': 2, 'name': 'Microphone (Realtek(R) Audio)', 'hostApi': 3, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.0013333, 'defaultLowOutputLatency': 0.0, 'defaultHighInputLatency': 0.01, 'defaultHighOutputLatency': 0.0, 'defaultSampleRate': 48000.0}\n",
      "{'index': 13, 'structVersion': 2, 'name': 'Speakers (Realtek HD Audio output)', 'hostApi': 4, 'maxInputChannels': 0, 'maxOutputChannels': 8, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 14, 'structVersion': 2, 'name': 'Microphone 1 (Realtek HD Audio Mic input with SST)', 'hostApi': 4, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 15, 'structVersion': 2, 'name': 'Microphone 2 (Realtek HD Audio Mic input with SST)', 'hostApi': 4, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 16000.0}\n",
      "{'index': 16, 'structVersion': 2, 'name': 'Microphone 3 (Realtek HD Audio Mic input with SST)', 'hostApi': 4, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 16000.0}\n",
      "{'index': 17, 'structVersion': 2, 'name': 'Stereo Mix (Realtek HD Audio Stereo input)', 'hostApi': 4, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 48000.0}\n",
      "{'index': 18, 'structVersion': 2, 'name': 'Headphones ()', 'hostApi': 4, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 44100.0}\n",
      "{'index': 19, 'structVersion': 2, 'name': 'Output (Intel(R) Display Audio Output 4.1)', 'hostApi': 4, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.04, 'defaultHighOutputLatency': 0.04, 'defaultSampleRate': 44100.0}\n",
      "{'index': 20, 'structVersion': 2, 'name': 'Headset (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(AUKEY EP-T10))', 'hostApi': 4, 'maxInputChannels': 0, 'maxOutputChannels': 1, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n",
      "{'index': 21, 'structVersion': 2, 'name': 'Headset (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\\r\\n;(AUKEY EP-T10))', 'hostApi': 4, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.08533333333333333, 'defaultHighOutputLatency': 0.08533333333333333, 'defaultSampleRate': 8000.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "# from keras.layers import LSTM, Input, Flatten, Merge, Bidirectional\n",
    "from keras.layers import LSTM, Input, Flatten, Bidirectional\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from features import *\n",
    "from helper import *\n",
    "import pyaudio\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# use this backend to display in separate Tk window\n",
    "%matplotlib tk\n",
    "\n",
    "# constants\n",
    "\n",
    "TIME_SEC = 1\n",
    "RATE = 44100                 # samples per second\n",
    "CHUNK = 44100 * TIME_SEC #1024 * 20 #int(44100 / TIME_SEC)             # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Microsoft Sound Mapper - Input, MME (2 in, 0 out)\n",
      ">  1 Microphone (Realtek(R) Audio), MME (2 in, 0 out)\n",
      "   2 Microsoft Sound Mapper - Output, MME (0 in, 2 out)\n",
      "<  3 Speakers (Realtek(R) Audio), MME (0 in, 2 out)\n",
      "   4 BenQ GW2480 (Intel(R) Display A, MME (0 in, 2 out)\n",
      "   5 Primary Sound Capture Driver, Windows DirectSound (2 in, 0 out)\n",
      "   6 Microphone (Realtek(R) Audio), Windows DirectSound (2 in, 0 out)\n",
      "   7 Primary Sound Driver, Windows DirectSound (0 in, 2 out)\n",
      "   8 Speakers (Realtek(R) Audio), Windows DirectSound (0 in, 2 out)\n",
      "   9 BenQ GW2480 (Intel(R) Display Audio), Windows DirectSound (0 in, 2 out)\n",
      "  10 BenQ GW2480 (Intel(R) Display Audio), Windows WASAPI (0 in, 2 out)\n",
      "  11 Speakers (Realtek(R) Audio), Windows WASAPI (0 in, 2 out)\n",
      "  12 Microphone (Realtek(R) Audio), Windows WASAPI (2 in, 0 out)\n",
      "  13 Speakers (Realtek HD Audio output), Windows WDM-KS (0 in, 8 out)\n",
      "  14 Microphone 1 (Realtek HD Audio Mic input with SST), Windows WDM-KS (2 in, 0 out)\n",
      "  15 Microphone 2 (Realtek HD Audio Mic input with SST), Windows WDM-KS (4 in, 0 out)\n",
      "  16 Microphone 3 (Realtek HD Audio Mic input with SST), Windows WDM-KS (4 in, 0 out)\n",
      "  17 Stereo Mix (Realtek HD Audio Stereo input), Windows WDM-KS (2 in, 0 out)\n",
      "  18 Headphones (), Windows WDM-KS (0 in, 2 out)\n",
      "  19 Output (Intel(R) Display Audio Output 4.1), Windows WDM-KS (0 in, 2 out)\n",
      "  20 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\r\n",
      ";(AUKEY EP-T10)), Windows WDM-KS (0 in, 1 out)\n",
      "  21 Headset (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\r\n",
      ";(AUKEY EP-T10)), Windows WDM-KS (1 in, 0 out)\n",
      "starting stream declaration\n"
     ]
    }
   ],
   "source": [
    "# create matplotlib figure and axes\n",
    "#fig, ax = plt.subplots(1, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "import sounddevice as sd\n",
    "print(sd.query_devices())\n",
    "\n",
    "print(\"starting stream declaration\")\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    "    input_device_index = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n"
     ]
    }
   ],
   "source": [
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)\n",
    "fig , ax = plt.subplots()\n",
    "# create a line object with random data\n",
    "#line, = ax.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# basic formatting for the axes\n",
    "ax.set_title('Emotion Prediction')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Confidence')\n",
    "# ax.set_ylim(0, 255)\n",
    "# ax.set_xlim(0, 2 * CHUNK)\n",
    "# plt.setp(ax, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "ax.plot([0], label=\"Anger\", color='r')\n",
    "ax.plot([0], label=\"Excited\", color='y')\n",
    "ax.plot([0], label=\"Neutral\", color='g')\n",
    "ax.plot([0], label=\"Sad\", color='b')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# show the plot\n",
    "plt.show(block=False)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# set up model\n",
    "model = load_model(\"C:/Uni Shit/EECS 4088/IEMOCAP-Emotion-Detection/data/Trained_models/2_layer_LSTM.pickle\")\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "df_pred_wav = pd.DataFrame(columns=cols)\n",
    "data_prev = []\n",
    "graph_window = 15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-c6737984e494>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[1;31m# binary data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[0mdata_new\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstream\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mCHUNK\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;31m#convert data to integers, make np array, then offset it by 127\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\CAP\\lib\\site-packages\\pyaudio.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, num_frames, exception_on_overflow)\u001B[0m\n\u001B[0;32m    606\u001B[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001B[0;32m    607\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 608\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mpa\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_stream\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stream\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_frames\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexception_on_overflow\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    610\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_read_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(\"starting loop\")\n",
    "while (True):\n",
    "    \n",
    "    # binary data\n",
    "    data_new = stream.read(CHUNK)\n",
    "\n",
    "    #convert data to integers, make np array, then offset it by 127\n",
    "    data_new = struct.unpack(str(2 * CHUNK) + 'B', data_new)\n",
    "\n",
    "    data_int = np.append(data_prev, data_new)\n",
    "\n",
    "    # Generate features from data\n",
    "    st_features = calculate_features(data_int, RATE, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "\n",
    "    # reshape input from (34, 100) to (1, 100, 34)\n",
    "    st_features = np.array([st_features.T])\n",
    "\n",
    "    # predict on model\n",
    "    wav_test_results = model.predict(st_features)\n",
    "\n",
    "    df_pred_wav = df_pred_wav.append({cols[0]:wav_test_results[0][0],\n",
    "                        cols[1]:wav_test_results[0][1],\n",
    "                        cols[2]:wav_test_results[0][2],\n",
    "                        cols[3]:wav_test_results[0][3]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    df_pred_wav_view = df_pred_wav[df_pred_wav.shape[0] - graph_window : ]\n",
    "\n",
    "    #plt.cla()\n",
    "\n",
    "    ax.axhline(y=0.5, color='r', linestyle='--')\n",
    "    ax.plot(df_pred_wav_view['ang'], label=\"Anger\", color='r')\n",
    "    ax.plot(df_pred_wav_view['exc'], label=\"Excited\", color='y')\n",
    "    ax.plot(df_pred_wav_view['neu'], label=\"Neutral\", color='g')\n",
    "    ax.plot(df_pred_wav_view['sad'], label=\"Sad\", color='b')\n",
    "\n",
    "    # # create np array and offset by 128\n",
    "#     data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    \n",
    "#     line.set_ydata(data_np)\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "        \n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "\n",
    "    data_prev = data_new\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop stream (6)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "wf.close()\n",
    "\n",
    "# close PyAudio (7)\n",
    "p.terminate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define callback (2)\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    data = wf.readframes(frame_count)\n",
    "    # data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    with open(LOG_PATH + \"log_file.txt\", \"a\") as f:\n",
    "            f.write(str(data) + \"\\n\")\n",
    "\n",
    "    return (data, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up model\n",
    "model = load_model(\"C:/Uni Shit/EECS 4088/IEMOCAP-Emotion-Detection/data/Trained_models/2_layer_LSTM.pickle\")\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "df_pred_wav = pd.DataFrame(columns=cols)\n",
    "data_prev = []\n",
    "graph_window = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"starting loop\")\n",
    "while (True):\n",
    "    \n",
    "    # binary data\n",
    "    data_new = stream.read(CHUNK)\n",
    "\n",
    "    #convert data to integers, make np array, then offset it by 127\n",
    "    data_new = struct.unpack(str(2 * CHUNK) + 'B', data_new)\n",
    "\n",
    "    #calculate the threshold\n",
    "\n",
    "    data_int = np.append(data_prev, data_new)\n",
    "\n",
    "    # Generate features from data\n",
    "    st_features = calculate_features(data_int, RATE, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "\n",
    "    # reshape input from (34, 100) to (1, 100, 34)\n",
    "    st_features = np.array([st_features.T])\n",
    "\n",
    "    # predict on model\n",
    "    wav_test_results = model.predict(st_features)\n",
    "\n",
    "    df_pred_wav = df_pred_wav.append({cols[0]:wav_test_results[0][0],\n",
    "                        cols[1]:wav_test_results[0][1],\n",
    "                        cols[2]:wav_test_results[0][2],\n",
    "                        cols[3]:wav_test_results[0][3]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    df_pred_wav_view = df_pred_wav[df_pred_wav.shape[0] - graph_window : ]\n",
    "\n",
    "    #plt.cla()\n",
    "\n",
    "    ax.axhline(y=0.5, color='r', linestyle='--')\n",
    "    ax.plot(df_pred_wav_view['ang'], label=\"Anger\", color='r')\n",
    "    ax.plot(df_pred_wav_view['exc'], label=\"Excited\", color='y')\n",
    "    ax.plot(df_pred_wav_view['neu'], label=\"Neutral\", color='g')\n",
    "    ax.plot(df_pred_wav_view['sad'], label=\"Sad\", color='b')\n",
    "\n",
    "    # # create np array and offset by 128\n",
    "#     data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    \n",
    "#     line.set_ydata(data_np)\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "        \n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "\n",
    "    data_prev = data_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop stream (6)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "wf.close()\n",
    "\n",
    "# close PyAudio (7)\n",
    "p.terminate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define callback (2)\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    data = wf.readframes(frame_count)\n",
    "    # data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    with open(LOG_PATH + \"log_file.txt\", \"a\") as f:\n",
    "            f.write(str(data) + \"\\n\")\n",
    "\n",
    "    return (data, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wf = wave.open(WAV_PATH, 'rb')\n",
    "\n",
    "# instantiate PyAudio (1)\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# open stream using callback (3)\n",
    "stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                channels=wf.getnchannels(),\n",
    "                rate=wf.getframerate(),\n",
    "                input = True,\n",
    "                stream_callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# start the stream (4)\n",
    "stream.start_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# stop stream (6)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "wf.close()\n",
    "\n",
    "# close PyAudio (7)\n",
    "p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}