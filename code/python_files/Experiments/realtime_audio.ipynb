{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "# from keras.layers import LSTM, Input, Flatten, Merge, Bidirectional\n",
    "from keras.layers import LSTM, Input, Flatten, Bidirectional\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from features import *\n",
    "from helper import *\n",
    "import pyaudio\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# use this backend to display in separate Tk window\n",
    "%matplotlib tk\n",
    "\n",
    "# constants\n",
    "\n",
    "TIME_SEC = 1\n",
    "RATE = 44100                 # samples per second\n",
    "CHUNK = 44100 * TIME_SEC     # 1024 * 20 #int(44100 / TIME_SEC)             # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "\n",
    "\n",
    "# p = pyaudio.PyAudio()\n",
    "# for i in range(p.get_device_count()):\n",
    "#     print(p.get_device_info_by_index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting stram decleration\n"
     ]
    }
   ],
   "source": [
    "# create matplotlib figure and axes\n",
    "#fig, ax = plt.subplots(1, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "print(\"starting stram decleration\")\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK,\n",
    "    input_device_index = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# set up model\n",
    "model = load_model(\"Trained_models/2_layer_LSTM.pickle\")\n",
    "cols = ['ang', 'exc', 'neu', 'sad']\n",
    "df_pred_wav = pd.DataFrame(columns=cols)\n",
    "data_prev = []\n",
    "graph_window = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stream started\n"
     ]
    }
   ],
   "source": [
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)\n",
    "fig , ax = plt.subplots()\n",
    "# create a line object with random data\n",
    "#line, = ax.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# basic formatting for the axes\n",
    "ax.set_title('Emotion Prediction')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Confidence')\n",
    "# ax.set_ylim(0, 255)\n",
    "# ax.set_xlim(0, 2 * CHUNK)\n",
    "# plt.setp(ax, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "ax.plot([0], label=\"Anger\", color='r')\n",
    "ax.plot([0], label=\"Excited\", color='y')\n",
    "ax.plot([0], label=\"Neutral\", color='g')\n",
    "ax.plot([0], label=\"Sad\", color='b')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# show the plot\n",
    "plt.show(block=False)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n",
      "stream stopped\n",
      "average frame rate = 1 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "print(\"starting loop\")\n",
    "while (True):\n",
    "    \n",
    "    # binary data\n",
    "    data_new = stream.read(CHUNK)\n",
    "\n",
    "    #convert data to integers, make np array, then offset it by 127\n",
    "    data_new = struct.unpack(str(2 * CHUNK) + 'B', data_new)\n",
    "\n",
    "    #data_int = np.append(data_prev, data_new)\n",
    "    data_int = data_new\n",
    "\n",
    "    # Generate features from data\n",
    "    st_features = calculate_features(data_int, RATE, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "\n",
    "    # reshape input from (34, 100) to (1, 100, 34)\n",
    "    st_features = np.array([st_features.T])\n",
    "\n",
    "    # predict on model\n",
    "    wav_test_results = model.predict(st_features)\n",
    "\n",
    "    df_pred_wav = df_pred_wav.append({cols[0]:wav_test_results[0][0],\n",
    "                        cols[1]:wav_test_results[0][1],\n",
    "                        cols[2]:wav_test_results[0][2],\n",
    "                        cols[3]:wav_test_results[0][3]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    df_pred_wav_view = df_pred_wav.tail(graph_window)\n",
    "    df_pred_wav_view.reset_index(drop=True, inplace=True)\n",
    "    plt.cla()\n",
    "\n",
    "    ax.axhline(y=0.5, color='r', linestyle='--')\n",
    "    ax.plot(df_pred_wav_view['ang'], label=\"Anger\", color='r')\n",
    "    ax.plot(df_pred_wav_view['exc'], label=\"Excited\", color='y')\n",
    "    ax.plot(df_pred_wav_view['neu'], label=\"Neutral\", color='g')\n",
    "    ax.plot(df_pred_wav_view['sad'], label=\"Sad\", color='b')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    # # create np array and offset by 128\n",
    "#     data_np = np.array(data_int, dtype='b')[::2] + 128\n",
    "    \n",
    "#     line.set_ydata(data_np)\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "        \n",
    "        # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "\n",
    "    data_prev = data_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stop stream (6)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "wf.close()\n",
    "\n",
    "# close PyAudio (7)\n",
    "p.terminate()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}