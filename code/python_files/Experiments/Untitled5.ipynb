{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /home/samarth/emotion_recognition-master/code/utilities/../../data/ses\n",
      "path_to_features              /home/samarth/emotion_recognition-master/code/utilities/../../data/fea\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <class 'numpy.int8'>, 2: <class 'numpy.int16'>, 4: <class 'numpy.i\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 80\n",
    "\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(params.path_to_data + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "\n",
    "for ses_mod in data2:\n",
    "    text.append(ses_mod['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(text)\n",
    "x_train_text = []\n",
    "\n",
    "x_train_text = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2736 unique tokens\n",
      "/home/samarth/emotion_recognition-master/code/utilities/../../data/sessions/../glove.42B.300d.txt\n",
      "G Word embeddings: 1917494\n",
      "G Null word embeddings: 90\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = params.path_to_data + '../glove.42B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               4096256   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,278,288\n",
      "Trainable params: 5,278,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model.summary()\n",
    "model.save(params.path_to_data + '/../'+'text_model.h5')\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3691 - acc: 0.3366Epoch 00001: val_acc improved from -inf to 0.36842, saving model to text_model_weights-01-0.37.hdf5\n",
      "3948/3948 [==============================] - 6s 2ms/step - loss: 1.3691 - acc: 0.3361 - val_loss: 1.3648 - val_acc: 0.3684\n",
      "Epoch 2/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3343 - acc: 0.3591Epoch 00002: val_acc improved from 0.36842 to 0.43522, saving model to text_model_weights-02-0.44.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 1.3333 - acc: 0.3607 - val_loss: 1.2545 - val_acc: 0.4352\n",
      "Epoch 3/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1741 - acc: 0.4851Epoch 00003: val_acc improved from 0.43522 to 0.54049, saving model to text_model_weights-03-0.54.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 1.1745 - acc: 0.4856 - val_loss: 1.0856 - val_acc: 0.5405\n",
      "Epoch 4/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8981 - acc: 0.6452Epoch 00004: val_acc improved from 0.54049 to 0.56680, saving model to text_model_weights-04-0.57.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.8973 - acc: 0.6459 - val_loss: 1.0764 - val_acc: 0.5668\n",
      "Epoch 5/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6835 - acc: 0.7392Epoch 00005: val_acc improved from 0.56680 to 0.60526, saving model to text_model_weights-05-0.61.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.6847 - acc: 0.7391 - val_loss: 1.0267 - val_acc: 0.6053\n",
      "Epoch 6/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5492 - acc: 0.7894Epoch 00006: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.5524 - acc: 0.7893 - val_loss: 1.1023 - val_acc: 0.6053\n",
      "Epoch 7/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8330Epoch 00007: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.4580 - acc: 0.8321 - val_loss: 1.1987 - val_acc: 0.5789\n",
      "Epoch 8/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.3864 - acc: 0.8504Epoch 00008: val_acc improved from 0.60526 to 0.64575, saving model to text_model_weights-08-0.65.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3876 - acc: 0.8495 - val_loss: 1.2423 - val_acc: 0.6457\n",
      "Epoch 9/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.3397 - acc: 0.8765Epoch 00009: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3393 - acc: 0.8761 - val_loss: 1.4405 - val_acc: 0.5931\n",
      "Epoch 10/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.8814Epoch 00010: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.3127 - acc: 0.8810 - val_loss: 1.3101 - val_acc: 0.6387\n",
      "Epoch 11/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2607 - acc: 0.8998Epoch 00011: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2594 - acc: 0.9005 - val_loss: 1.5038 - val_acc: 0.6184\n",
      "Epoch 12/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2489 - acc: 0.9050Epoch 00012: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2504 - acc: 0.9043 - val_loss: 1.4293 - val_acc: 0.6447\n",
      "Epoch 13/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9011Epoch 00013: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2601 - acc: 0.9012 - val_loss: 1.3870 - val_acc: 0.6346\n",
      "Epoch 14/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9168Epoch 00014: val_acc improved from 0.64575 to 0.65081, saving model to text_model_weights-14-0.65.hdf5\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2276 - acc: 0.9159 - val_loss: 1.4799 - val_acc: 0.6508\n",
      "Epoch 15/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9232Epoch 00015: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2130 - acc: 0.9230 - val_loss: 1.6903 - val_acc: 0.6215\n",
      "Epoch 16/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9211Epoch 00016: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2016 - acc: 0.9205 - val_loss: 1.7695 - val_acc: 0.6508\n",
      "Epoch 17/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9201Epoch 00017: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.2022 - acc: 0.9192 - val_loss: 1.8935 - val_acc: 0.6164\n",
      "Epoch 18/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9273Epoch 00018: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1885 - acc: 0.9268 - val_loss: 1.6693 - val_acc: 0.6164\n",
      "Epoch 19/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9278Epoch 00019: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1775 - acc: 0.9278 - val_loss: 1.7281 - val_acc: 0.6296\n",
      "Epoch 20/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9260Epoch 00020: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1836 - acc: 0.9255 - val_loss: 1.8814 - val_acc: 0.6356\n",
      "Epoch 21/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9314Epoch 00021: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1754 - acc: 0.9303 - val_loss: 1.7926 - val_acc: 0.6427\n",
      "Epoch 22/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9334Epoch 00022: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1564 - acc: 0.9329 - val_loss: 2.2367 - val_acc: 0.6204\n",
      "Epoch 23/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9273Epoch 00023: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1747 - acc: 0.9278 - val_loss: 1.7712 - val_acc: 0.6508\n",
      "Epoch 24/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9175Epoch 00024: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1937 - acc: 0.9174 - val_loss: 1.9781 - val_acc: 0.6184\n",
      "Epoch 25/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9296Epoch 00025: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1718 - acc: 0.9298 - val_loss: 2.0959 - val_acc: 0.6306\n",
      "Epoch 26/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9306Epoch 00026: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1762 - acc: 0.9314 - val_loss: 1.8732 - val_acc: 0.6194\n",
      "Epoch 27/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1607 - acc: 0.9321Epoch 00027: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1607 - acc: 0.9319 - val_loss: 2.0377 - val_acc: 0.6204\n",
      "Epoch 28/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9247Epoch 00028: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1759 - acc: 0.9248 - val_loss: 2.0228 - val_acc: 0.6245\n",
      "Epoch 29/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9298Epoch 00029: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1635 - acc: 0.9301 - val_loss: 1.9777 - val_acc: 0.6215\n",
      "Epoch 30/30\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9252Epoch 00030: val_acc did not improve\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1741 - acc: 0.9248 - val_loss: 2.1015 - val_acc: 0.6306\n"
     ]
    }
   ],
   "source": [
    "filepath=\"text_model_weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "hist = model.fit(x_train_text, Y, shuffle=True,\n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2, callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4096256   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,278,288\n",
      "Trainable params: 5,278,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(params.path_to_data + '/../'+'text_model.h5')\n",
    "model.load_weights('text_model_weights-07-0.66.hdf5')\n",
    "model.summary()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 189, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mocap = []\n",
    "from sklearn.preprocessing import normalize\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train_mocap.append( x_mocap )\n",
    "    \n",
    "x_train_mocap = np.array(x_train_mocap)\n",
    "x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n",
    "x_train_mocap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, input_shape=(200, 189,..., strides=(2, 2), padding=\"same\")`\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "model_mocap.add(Activation('relu')) \n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Dense(4))\n",
    "model_mocap.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_mocap.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_mocap.summary()\n",
    "model_mocap.save(params.path_to_data + '/../'+'mocap_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 2.5026 - acc: 0.3053Epoch 00001: val_acc improved from -inf to 0.36943, saving model to mocap_model_weights-01-0.37.hdf5\n",
      "3948/3948 [==============================] - 9s 2ms/step - loss: 2.4900 - acc: 0.3062 - val_loss: 1.3679 - val_acc: 0.3694\n",
      "Epoch 2/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3732 - acc: 0.3397Epoch 00002: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3732 - acc: 0.3397 - val_loss: 1.3681 - val_acc: 0.3694\n",
      "Epoch 3/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3666 - acc: 0.3402Epoch 00003: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3665 - acc: 0.3399 - val_loss: 1.3618 - val_acc: 0.3694\n",
      "Epoch 4/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3617 - acc: 0.3412Epoch 00004: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3618 - acc: 0.3412 - val_loss: 1.3485 - val_acc: 0.3694\n",
      "Epoch 5/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3472 - acc: 0.3394Epoch 00005: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3464 - acc: 0.3412 - val_loss: 1.3312 - val_acc: 0.3694\n",
      "Epoch 6/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.3160 - acc: 0.3663Epoch 00006: val_acc improved from 0.36943 to 0.49899, saving model to mocap_model_weights-06-0.50.hdf5\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.3163 - acc: 0.3678 - val_loss: 1.2131 - val_acc: 0.4990\n",
      "Epoch 7/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.2577 - acc: 0.3968Epoch 00007: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2577 - acc: 0.3967 - val_loss: 1.2562 - val_acc: 0.4980\n",
      "Epoch 8/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.2223 - acc: 0.4101Epoch 00008: val_acc improved from 0.49899 to 0.50709, saving model to mocap_model_weights-08-0.51.hdf5\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2235 - acc: 0.4096 - val_loss: 1.2345 - val_acc: 0.5071\n",
      "Epoch 9/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.2228 - acc: 0.4165Epoch 00009: val_acc improved from 0.50709 to 0.51215, saving model to mocap_model_weights-09-0.51.hdf5\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.2231 - acc: 0.4159 - val_loss: 1.1642 - val_acc: 0.5121\n",
      "Epoch 10/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1879 - acc: 0.4293Epoch 00010: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1892 - acc: 0.4283 - val_loss: 1.2428 - val_acc: 0.5051\n",
      "Epoch 11/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1888 - acc: 0.4401Epoch 00011: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1901 - acc: 0.4377 - val_loss: 1.3054 - val_acc: 0.5030\n",
      "Epoch 12/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1851 - acc: 0.4285Epoch 00012: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1839 - acc: 0.4286 - val_loss: 1.7007 - val_acc: 0.4291\n",
      "Epoch 13/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.4608Epoch 00013: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1572 - acc: 0.4610 - val_loss: 1.6976 - val_acc: 0.4028\n",
      "Epoch 14/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1604 - acc: 0.4462Epoch 00014: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1600 - acc: 0.4466 - val_loss: 1.8746 - val_acc: 0.4281\n",
      "Epoch 15/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1529 - acc: 0.4644Epoch 00015: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1531 - acc: 0.4643 - val_loss: 1.8333 - val_acc: 0.4322\n",
      "Epoch 16/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1306 - acc: 0.4690Epoch 00016: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1323 - acc: 0.4681 - val_loss: 1.4965 - val_acc: 0.4231\n",
      "Epoch 17/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1317 - acc: 0.4690Epoch 00017: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1301 - acc: 0.4699 - val_loss: 1.7899 - val_acc: 0.3806\n",
      "Epoch 18/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1236 - acc: 0.4810Epoch 00018: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1217 - acc: 0.4815 - val_loss: 1.5582 - val_acc: 0.4383\n",
      "Epoch 19/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.1105 - acc: 0.4939Epoch 00019: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.1109 - acc: 0.4939 - val_loss: 1.2940 - val_acc: 0.4484\n",
      "Epoch 20/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0969 - acc: 0.5077Epoch 00020: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0976 - acc: 0.5076 - val_loss: 1.4265 - val_acc: 0.4221\n",
      "Epoch 21/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0839 - acc: 0.5051Epoch 00021: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0824 - acc: 0.5051 - val_loss: 1.8040 - val_acc: 0.4190\n",
      "Epoch 22/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0612 - acc: 0.5166Epoch 00022: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0617 - acc: 0.5157 - val_loss: 1.5365 - val_acc: 0.4200\n",
      "Epoch 23/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0583 - acc: 0.5272Epoch 00023: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0586 - acc: 0.5276 - val_loss: 1.5130 - val_acc: 0.4615\n",
      "Epoch 24/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0522 - acc: 0.5310Epoch 00024: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0538 - acc: 0.5289 - val_loss: 1.9040 - val_acc: 0.4636\n",
      "Epoch 25/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0404 - acc: 0.5323Epoch 00025: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0387 - acc: 0.5332 - val_loss: 1.8745 - val_acc: 0.4079\n",
      "Epoch 26/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0333 - acc: 0.5384Epoch 00026: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0327 - acc: 0.5382 - val_loss: 1.6465 - val_acc: 0.4322\n",
      "Epoch 27/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 1.0153 - acc: 0.5428Epoch 00027: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 1.0159 - acc: 0.5415 - val_loss: 1.8463 - val_acc: 0.4514\n",
      "Epoch 28/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9920 - acc: 0.5517Epoch 00028: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9922 - acc: 0.5512 - val_loss: 2.0181 - val_acc: 0.4251\n",
      "Epoch 29/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9954 - acc: 0.5540Epoch 00029: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9969 - acc: 0.5537 - val_loss: 2.4801 - val_acc: 0.3968\n",
      "Epoch 30/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9762 - acc: 0.5525Epoch 00030: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9755 - acc: 0.5522 - val_loss: 2.0022 - val_acc: 0.4281\n",
      "Epoch 31/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9907 - acc: 0.5471Epoch 00031: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9927 - acc: 0.5453 - val_loss: 1.8102 - val_acc: 0.4099\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9534 - acc: 0.5581Epoch 00032: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9545 - acc: 0.5585 - val_loss: 1.8052 - val_acc: 0.4170\n",
      "Epoch 33/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9592 - acc: 0.5628Epoch 00033: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9584 - acc: 0.5631 - val_loss: 1.6114 - val_acc: 0.4393\n",
      "Epoch 34/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9505 - acc: 0.5710Epoch 00034: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9514 - acc: 0.5704 - val_loss: 1.8041 - val_acc: 0.4190\n",
      "Epoch 35/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9359 - acc: 0.5848Epoch 00035: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9357 - acc: 0.5849 - val_loss: 1.7027 - val_acc: 0.4676\n",
      "Epoch 36/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.9335 - acc: 0.5891Epoch 00036: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.9335 - acc: 0.5897 - val_loss: 1.8748 - val_acc: 0.4332\n",
      "Epoch 37/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8990 - acc: 0.6071Epoch 00037: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8970 - acc: 0.6082 - val_loss: 2.0558 - val_acc: 0.4383\n",
      "Epoch 38/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8970 - acc: 0.6089Epoch 00038: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8975 - acc: 0.6079 - val_loss: 1.9984 - val_acc: 0.4534\n",
      "Epoch 39/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8781 - acc: 0.6112Epoch 00039: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8780 - acc: 0.6117 - val_loss: 2.4244 - val_acc: 0.4079\n",
      "Epoch 40/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8585 - acc: 0.6235Epoch 00040: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8587 - acc: 0.6239 - val_loss: 2.0614 - val_acc: 0.4545\n",
      "Epoch 41/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8374 - acc: 0.6232Epoch 00041: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8385 - acc: 0.6226 - val_loss: 2.3837 - val_acc: 0.4271\n",
      "Epoch 42/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8355 - acc: 0.6401Epoch 00042: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8353 - acc: 0.6396 - val_loss: 2.0845 - val_acc: 0.4494\n",
      "Epoch 43/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8109 - acc: 0.6506Epoch 00043: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8089 - acc: 0.6522 - val_loss: 2.6716 - val_acc: 0.4626\n",
      "Epoch 44/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8114 - acc: 0.6429Epoch 00044: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8122 - acc: 0.6424 - val_loss: 2.4320 - val_acc: 0.4818\n",
      "Epoch 45/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8100 - acc: 0.6486Epoch 00045: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8110 - acc: 0.6474 - val_loss: 2.0670 - val_acc: 0.4453\n",
      "Epoch 46/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.8017 - acc: 0.6539Epoch 00046: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.8016 - acc: 0.6532 - val_loss: 2.3603 - val_acc: 0.4170\n",
      "Epoch 47/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7864 - acc: 0.6668Epoch 00047: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7860 - acc: 0.6662 - val_loss: 2.4884 - val_acc: 0.4555\n",
      "Epoch 48/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7942 - acc: 0.6598Epoch 00048: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7940 - acc: 0.6588 - val_loss: 2.5458 - val_acc: 0.4737\n",
      "Epoch 49/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7600 - acc: 0.6691Epoch 00049: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7622 - acc: 0.6682 - val_loss: 3.0861 - val_acc: 0.4757\n",
      "Epoch 50/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7468 - acc: 0.6778Epoch 00050: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7464 - acc: 0.6788 - val_loss: 2.7770 - val_acc: 0.4352\n",
      "Epoch 51/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7412 - acc: 0.6890Epoch 00051: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7438 - acc: 0.6872 - val_loss: 2.6447 - val_acc: 0.4545\n",
      "Epoch 52/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7252 - acc: 0.6895Epoch 00052: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7246 - acc: 0.6895 - val_loss: 2.9542 - val_acc: 0.4534\n",
      "Epoch 53/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7205 - acc: 0.6980Epoch 00053: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7214 - acc: 0.6973 - val_loss: 3.2512 - val_acc: 0.4464\n",
      "Epoch 54/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7120 - acc: 0.7049Epoch 00054: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7116 - acc: 0.7052 - val_loss: 2.8056 - val_acc: 0.4443\n",
      "Epoch 55/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7372 - acc: 0.6908Epoch 00055: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7379 - acc: 0.6912 - val_loss: 2.4611 - val_acc: 0.4626\n",
      "Epoch 56/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7146 - acc: 0.7013Epoch 00056: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7138 - acc: 0.7009 - val_loss: 3.2965 - val_acc: 0.4150\n",
      "Epoch 57/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.7024 - acc: 0.7016Epoch 00057: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.7028 - acc: 0.7019 - val_loss: 3.1351 - val_acc: 0.4433\n",
      "Epoch 58/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6786 - acc: 0.7180Epoch 00058: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6789 - acc: 0.7183 - val_loss: 2.9343 - val_acc: 0.4777\n",
      "Epoch 59/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.7239Epoch 00059: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6458 - acc: 0.7242 - val_loss: 3.0422 - val_acc: 0.4291\n",
      "Epoch 60/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6996 - acc: 0.7026Epoch 00060: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6992 - acc: 0.7034 - val_loss: 2.6779 - val_acc: 0.4211\n",
      "Epoch 61/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6549 - acc: 0.7190Epoch 00061: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6550 - acc: 0.7186 - val_loss: 2.8688 - val_acc: 0.4453\n",
      "Epoch 62/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6463 - acc: 0.7310Epoch 00062: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6470 - acc: 0.7310 - val_loss: 3.5941 - val_acc: 0.4626\n",
      "Epoch 63/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6359 - acc: 0.7323Epoch 00063: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6353 - acc: 0.7328 - val_loss: 2.7745 - val_acc: 0.4433\n",
      "Epoch 64/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6552 - acc: 0.7246Epoch 00064: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6536 - acc: 0.7254 - val_loss: 3.3744 - val_acc: 0.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6365 - acc: 0.7339Epoch 00065: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6353 - acc: 0.7356 - val_loss: 2.9719 - val_acc: 0.4211\n",
      "Epoch 66/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5993 - acc: 0.7546Epoch 00066: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5984 - acc: 0.7546 - val_loss: 3.5495 - val_acc: 0.4383\n",
      "Epoch 67/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.6147 - acc: 0.7454Epoch 00067: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.6168 - acc: 0.7452 - val_loss: 3.0257 - val_acc: 0.4565\n",
      "Epoch 68/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5916 - acc: 0.7462Epoch 00068: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5929 - acc: 0.7452 - val_loss: 3.5591 - val_acc: 0.4494\n",
      "Epoch 69/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5701 - acc: 0.7600Epoch 00069: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5714 - acc: 0.7606 - val_loss: 3.3374 - val_acc: 0.4524\n",
      "Epoch 70/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5595 - acc: 0.7636Epoch 00070: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5592 - acc: 0.7632 - val_loss: 4.1578 - val_acc: 0.4332\n",
      "Epoch 71/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5487 - acc: 0.7733Epoch 00071: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5487 - acc: 0.7730 - val_loss: 3.8185 - val_acc: 0.4626\n",
      "Epoch 72/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5586 - acc: 0.7687Epoch 00072: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5577 - acc: 0.7685 - val_loss: 3.1236 - val_acc: 0.4302\n",
      "Epoch 73/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5536 - acc: 0.7774Epoch 00073: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5522 - acc: 0.7784 - val_loss: 3.6827 - val_acc: 0.4484\n",
      "Epoch 74/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5609 - acc: 0.7602Epoch 00074: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5612 - acc: 0.7594 - val_loss: 3.6935 - val_acc: 0.4706\n",
      "Epoch 75/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.7866Epoch 00075: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5244 - acc: 0.7847 - val_loss: 3.6577 - val_acc: 0.4433\n",
      "Epoch 76/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.7661Epoch 00076: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5553 - acc: 0.7665 - val_loss: 3.7730 - val_acc: 0.4615\n",
      "Epoch 77/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5400 - acc: 0.7710Epoch 00077: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5379 - acc: 0.7715 - val_loss: 3.5945 - val_acc: 0.4362\n",
      "Epoch 78/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5224 - acc: 0.7851Epoch 00078: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5242 - acc: 0.7842 - val_loss: 3.3826 - val_acc: 0.4545\n",
      "Epoch 79/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.7853Epoch 00079: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5120 - acc: 0.7829 - val_loss: 4.5219 - val_acc: 0.4656\n",
      "Epoch 80/80\n",
      "3904/3948 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.7884Epoch 00080: val_acc did not improve\n",
      "3948/3948 [==============================] - 8s 2ms/step - loss: 0.5360 - acc: 0.7890 - val_loss: 4.1123 - val_acc: 0.4362\n"
     ]
    }
   ],
   "source": [
    "filepath=\"mocap_model_weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "hist = model_mocap.fit(x_train_mocap, Y, shuffle=True,\n",
    "                 batch_size=batch_size, nb_epoch=80, verbose=1, \n",
    "                 validation_split=0.2, callbacks= callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               4096256   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,278,288\n",
      "Trainable params: 5,278,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "modelt = load_model(params.path_to_data + '/../'+'text_model.h5')\n",
    "modelt.load_weights('text_model_weights-14-0.65.hdf5')\n",
    "modelt.summary()\n",
    "modelt.layers.pop()\n",
    "modelt.layers.pop()\n",
    "modelt.layers.pop()\n",
    "modelt.layers.pop()\n",
    "modelt.summary()\n",
    "\n",
    "modelm = load_model(params.path_to_data + '/../'+'mocap_model.h5')\n",
    "modelm.load_weights('mocap_model_weights-09-0.51.hdf5')\n",
    "modelm.summary()\n",
    "modelm.layers.pop()\n",
    "modelm.layers.pop()\n",
    "modelm.layers.pop()\n",
    "modelm.layers.pop()\n",
    "modelm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([modelt, modelm], mode='concat'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 14s 3ms/step - loss: 0.9253 - acc: 0.8336 - val_loss: 0.9665 - val_acc: 0.6356\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.4494 - acc: 0.8797 - val_loss: 1.0410 - val_acc: 0.6194\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 13s 3ms/step - loss: 0.3283 - acc: 0.9005 - val_loss: 1.2678 - val_acc: 0.5962\n",
      "Epoch 4/30\n",
      "1280/3948 [========>.....................] - ETA: 8s - loss: 0.3149 - acc: 0.9016"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2852a1a33dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train_mocap], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m                             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_mocap], Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
